{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb6ddce1-8cd0-4fc2-b995-22a5abbefc19",
   "metadata": {},
   "source": [
    "# load the packages and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc15ad8f-3634-4c33-be7b-15d1c530cd06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import xarray as xr\n",
    "import h5py\n",
    "from scipy.io import loadmat\n",
    "import matplotlib as mpl\n",
    "import time\n",
    "import gsw\n",
    "from matplotlib.colors import TwoSlopeNorm\n",
    "\n",
    "# import existing python files\n",
    "plt.rcParams['figure.figsize'] = (10,4)\n",
    "\n",
    "# add rdmds reading functions to path\n",
    "sys.path.append(\"/home/mmurakami/MITgcm/MITgcm_c68r/MITgcm-checkpoint68r/utils/python/MITgcmutils/MITgcmutils/\") # go to parent dir\n",
    "from mds import *\n",
    "\n",
    "# add the other files\n",
    "sys.path.append(\"/home/mmurakami/crios_backups/an_helper_functions\")\n",
    "from read_binary import *\n",
    "from calc_UV_conv_1face import calc_UV_conv_1face\n",
    "from calc_mskmean_T_mod import calc_mskmean_T_mod\n",
    "from mk3D_mod import mk3D_mod\n",
    "from aste_helper_funcs import *\n",
    "from timing_functions import *           # ts2dte, get_fnames, etc.\n",
    "from binning import *                    # bin_array, create_mesh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a8cbffb-739b-43b0-9db8-315abf784d61",
   "metadata": {},
   "source": [
    "# load the grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2015777-19ac-4c49-abb3-6995998d66e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define basin we want\n",
    "path = \"/home/mmurakami/crios_backups/ASTE_270/offline_binning/sample_images/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad682946-ee19-4aba-88b6-07edf0f86043",
   "metadata": {},
   "outputs": [],
   "source": [
    "dirroot = \"/scratch2/atnguyen/aste_270x450x180/\"\n",
    "dirrun = \"/scratch/atnguyen/aste_270x450x180/OFFICIAL_ASTE_R1_Sep2019/\"\n",
    "dirIn = dirrun + \"diags/BUDG/\"\n",
    "dirDiags = dirrun + \"diags/\"\n",
    "dirState = dirDiags + \"STATE/\"\n",
    "dirGrid = dirroot + \"GRID_real8/\"\n",
    "dirgridnb = dirroot + \"GRID_noblank/\"\n",
    "dirgridw = dirroot + \"GRID_wet/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4eac9bdb-b14b-4544-9109-6ce72a8dc17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigaste = True\n",
    "\n",
    "if bigaste:\n",
    "    nx = 270\n",
    "    ncut1 = 450\n",
    "    ncut2 = 180\n",
    "else:\n",
    "    nx = 90\n",
    "    ncut1 = 150\n",
    "    ncut2 = 60\n",
    "    \n",
    "ny = 2*ncut1+nx+ncut2\n",
    "nz = 50\n",
    "nfx = np.array([nx, 0 , nx, ncut2 ,ncut1])\n",
    "nfy = np.array([ncut1, 0 , nx, nx, nx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db66f5f7-a87d-40d0-98f2-c19fb1991bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save myParms from An hard-coding\n",
    "save_budg_3d = 0\n",
    "save_budg_2d = 1\n",
    "save_budg_scalar = 0\n",
    "save_budg_lev = 0\n",
    "\n",
    "strbudg = 'Salt'\n",
    "kBudget = 1\n",
    "test3d = True\n",
    "plot_fig = 1\n",
    "# kz = [[1, 5], [6, 10], [11, 19], [20, 23]]\n",
    "\n",
    "myparms = {\n",
    "    'yearFirst': 1979,\n",
    "    'yearLast': 1979,\n",
    "    'yearInAv': [1979, 1979],\n",
    "    'timeStep': 3600,\n",
    "    'iceModel': 1,\n",
    "    'useRFWF': 1,\n",
    "    'useNLFS': 4,\n",
    "    'rStar': 2,\n",
    "    'rhoconst': 1029,\n",
    "    'rhoconstFresh': 1000,\n",
    "    'rcp': 1029 * 3994,    # reference seawater specific heat capacity (1029 kg/m^3) * (3994 J/kg K) = J/(m^3*degC)\n",
    "    'rhoi': 910,\n",
    "    'rhosn': 330,\n",
    "    'flami': 334000,\n",
    "    'flamb': 2500000,\n",
    "    'SIsal0': 4,\n",
    "    'diagsAreMonthly': 0,\n",
    "    'diagsAreAnnual': 0,\n",
    "    'recInAve': [1, 2],\n",
    "    'SaltPlumeHeatFlux': 0,  # Not sure what this is\n",
    "    'SEAICEheatConsFix': 0,\n",
    "    'conserveTr': 0,\n",
    "    'seaice_variable_salinity_flag': 0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cab09480-e2b6-45ef-89e1-8f4be99623ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get time-steps:\n",
    "flist = [f for f in os.listdir(dirIn) if f.startswith('budg2d_snap_set1.') and f.endswith('.data')]\n",
    "idot = flist[0].index('.')\n",
    "idot = [idot+1, flist[0][idot+1:].index('.')+idot+1]\n",
    "idot = np.asarray(idot,dtype=int)\n",
    "\n",
    "mygrid = {\n",
    "    'dirGrid': dirGrid,\n",
    "    'nFaces': 1,\n",
    "    'fileFormat': 'compact',\n",
    "    'memoryLimit': 2,\n",
    "    'ioSize': [nx*ny, 1],\n",
    "    'facesSize': [ny, nx],\n",
    "    'facesExpand': [ny, nx],\n",
    "    'missVal': 0,\n",
    "}\n",
    "\n",
    "fldstr2d = ['XC','YC','XG','YG','RAC','Depth','DXG','DYG','DXC','DYC']\n",
    "fldstr3d = ['hFacC','hFacW','hFacS','mskC','mskS','mskW']\n",
    "fldstr3dp = ['hFacC','hFacW','hFacS','maskCtrlC','maskCtrlS','maskCtrlW']\n",
    "fldstr1d = ['RC','RF','DRC','DRF']\n",
    "\n",
    "for fld in fldstr1d:\n",
    "    mygrid[fld] = np.squeeze(rdmds(os.path.join(dirGrid, fld)))\n",
    "\n",
    "for fld in fldstr3d:\n",
    "    temp = rdmds(os.path.join(dirGrid, fldstr3dp[fldstr3d.index(fld)]))\n",
    "    mygrid[fld] = temp.reshape(nz, ny, nx)\n",
    "\n",
    "for fld in fldstr2d:\n",
    "    temp = rdmds(os.path.join(dirGrid, fld))\n",
    "    mygrid[fld] = temp.reshape(ny, nx)\n",
    "\n",
    "mygrid['mskC'][mygrid['mskC'] == 0] = np.nan\n",
    "\n",
    "areaW, areaS, Vol = [], [], []\n",
    "for k in range(nz):\n",
    "    areaW.append(mygrid['DYG'] * mygrid['DRF'][k])\n",
    "    areaS.append(mygrid['DXG'] * mygrid['DRF'][k])\n",
    "    Vol.append(mygrid['RAC'] * mygrid['DRF'][k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "28f79224-6598-45e8-b823-039fbbaabf5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50,) (50, 1350, 270)\n"
     ]
    }
   ],
   "source": [
    "# block out obcs\n",
    "# np tile I think operates the same as repmat in MATLAB\n",
    "RAC = mygrid['RAC']\n",
    "RAC3 = np.tile(RAC,(nz,1,1))\n",
    "\n",
    "hfC = mygrid['hFacC']\n",
    "DD = mygrid['Depth']\n",
    "dxg = mygrid['DXG']\n",
    "dyg = mygrid['DYG']\n",
    "dxg3d = np.tile(dxg,(nz,1,1))\n",
    "dyg3d = np.tile(dyg,(nz,1,1))\n",
    "\n",
    "print(mygrid['DRF'].shape,np.zeros((nz, ny, nx)).shape)\n",
    "drf3d = mk3D_mod(mygrid['DRF'], np.zeros((nz, ny, nx)))\n",
    "DD3d = mk3D_mod(DD,np.zeros((nz, ny, nx)))\n",
    "\n",
    "hfC[hfC == 0] = np.nan\n",
    "hfC1 = hfC[0, :, :]\n",
    "hfC1[hfC1 == 0] = np.nan\n",
    "\n",
    "RACg = RAC * hfC1\n",
    "hfC1p = np.copy(hfC1)\n",
    "\n",
    "hfC1p[:, nx-1] = np.nan\n",
    "hfC1p[ny-1,:] = np.nan\n",
    "RACgp = RAC * hfC1p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1ce5504a-9e0b-4c79-b616-1a4010ac0b52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hf1 (1350, 270)\n"
     ]
    }
   ],
   "source": [
    "#mygrid['hFacC'][mygrid['hFacC'] > 0] = 1\n",
    "mygrid['hFacC'][mygrid['hFacC'] == 0] = np.nan\n",
    "hf1 = mygrid['hFacC'][0] # top layer in z\n",
    "\n",
    "print(\"hf1\",hf1.shape)\n",
    "\n",
    "hf1 = get_aste_tracer(hf1, nfx, nfy)\n",
    "# check with hardcoding on this for mini or big aste\n",
    "if nx == 90:\n",
    "    hf1[:,281,:] = np.nan\n",
    "    hf1[:,7,:] = np.nan\n",
    "    hf1[:,86,122] = np.nan\n",
    "elif nx == 270:\n",
    "    hf1[:,844,:] = np.nan\n",
    "    hf1[:,23,:] = np.nan\n",
    "    hf1[:,365,260:261] = np.nan\n",
    "\n",
    "hf1 = aste_tracer2compact(hf1,nfx,nfy)\n",
    "hf = mygrid[\"hFacC\"]\n",
    "hf = hf * np.tile(hf1,(nz, 1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "df8bb26e-8ca2-4a95-bcde-cd24b01daa41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 1350, 270)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# copy basin listing from lookat_layers\n",
    "fileprefix = \"/scratch/pillarh/aste_270x450x180/\"\n",
    "extBasin='run_template/input_maskTransport/'\n",
    "filename = fileprefix + extBasin + \"GATE_transports_v3_osnap.mat\"\n",
    "if nx == 270:\n",
    "    inf = loadmat(filename)\n",
    "    mskBasin = (inf[\"mskBasin\"])\n",
    "\n",
    "mskBasin = mskBasin.T               # python adjustment\n",
    "\n",
    "# this is now different syntax than the other file\n",
    "strb=np.array(['CanadaB','ChukchiS','MakarovB','AmundsenB','NansenB','BeringS','BarentsS','GINs','CAA',\n",
    "               'SPG','LabSea','NPac','NAtlantic','AtlS30'])\n",
    "\n",
    "mskBasin[mskBasin==50] =6\n",
    "mskBasin[mskBasin==200]=7\n",
    "mskBasin[mskBasin==300]=8\n",
    "mskBasin[mskBasin==400]=9\n",
    "mskBasin[mskBasin==500]=9\n",
    "mskBasin[mskBasin==600]=10\n",
    "mskBasin[mskBasin==700]=11\n",
    "mskBasin[mskBasin==-1]=12\n",
    "mskBasin[mskBasin==-100]=13\n",
    "latNA = 30\n",
    "lonNA = -82\n",
    "condition_13 = (mskBasin == 0) & (mygrid['YC'] > latNA) & (mygrid['XC'] > lonNA) & (hf1.reshape((ny,nx)) > 0)\n",
    "mskBasin[condition_13] = 13\n",
    "condition_14 = (mskBasin == 0) & (hf1.reshape((ny,nx)) > 0)\n",
    "mskBasin[condition_14] = 14\n",
    "\n",
    "mskBasin = mskBasin * hf1\n",
    "mskBasin = mskBasin[0,:,:]   # change indexing for  python\n",
    "mskBasin -= 1\n",
    "\n",
    "# create mskBasin3D to also add to the dataset\n",
    "mskBasin3D = np.tile(mskBasin[np.newaxis,:,:],(nz,1,1))\n",
    "mskBasin3D.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0b4023eb-be4b-4b9e-8360-92b2b5857d86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "364500\n"
     ]
    }
   ],
   "source": [
    "# read one basin or whole ASTE\n",
    "whole = False\n",
    "if not whole:\n",
    "    iB = 6    # example read from BarentsSea\n",
    "    \n",
    "# mymsk below defines as all Arctic down to Fram Strait and BSO but not GINs Seas\n",
    "mymsk = mskBasin.copy()\n",
    "\n",
    "# Create a boolean mask for elements that are 6 or less\n",
    "# mask = mymsk <7\n",
    "if whole:\n",
    "    mask = (mymsk < 5) | (mymsk==6) \n",
    "else:\n",
    "    mask = mymsk == 6\n",
    "\n",
    "# Set elements that are greater than 6 to np.nan\n",
    "mymsk[mask] = 1\n",
    "mymsk[~mask] = np.nan\n",
    "\n",
    "test = get_aste_tracer(mymsk,nfx,nfy)[0]\n",
    "test[:,:270] = np.nan\n",
    "mymsk = test\n",
    "\n",
    "mymsk = aste_tracer2compact(mymsk,nfx,nfy)[0]\n",
    "\n",
    "# Get the number of points where mskBasin is 6 or less\n",
    "npoints = np.count_nonzero(mymsk)  # Count the number of True values in the mask\n",
    "print(npoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7a67a58b-9146-4076-b78e-c5847cd7ed60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 1350, 270)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mymsk3 = np.tile(mymsk[np.newaxis,:,:],(nz,1,1)) * mygrid['hFacC']\n",
    "mymsk3.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc4f7e9-0161-4c94-a875-ddd5f331bc6c",
   "metadata": {},
   "source": [
    "# timesteps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "51b00d5f-b355-47f4-94af-5ad286fd8a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an array of the time steps we want to read\n",
    "# use ts2dte to get december 2014\n",
    "# first make an array of filenames\n",
    "dt_aste = 600\n",
    "startyr = 2002\n",
    "endyr = 2019\n",
    "\n",
    "# all the filenames in the system\n",
    "fnames = get_fnames(dt_aste,startyr,endyr)\n",
    "\n",
    "# ocean and ice\n",
    "AB_gT=0\n",
    "AB_gS=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dbdcad04-8d3a-4643-b80e-9f02d3e46c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# years = list(np.arange(2003,2018,1))  # 15 year period\n",
    "years = [2014,2015]\n",
    "years = [str(i) for i in years]\n",
    "years = np.array(years)\n",
    "# years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "749aa26a-7bc0-44cb-bb6c-8aef5711b0f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# write the datetimes for the later period\n",
    "times = {}\n",
    "\n",
    "for year in years:\n",
    "    times[year] = np.arange(1,13,1)   # write all the months for this example 5-year period\n",
    "\n",
    "tsstr,datetimes = get_tsteps(times,fnames,dt_aste,startyr,1,1)\n",
    "tsstr.shape\n",
    "datetimes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b56e9dd4-1571-44d6-ace8-308141ee50a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13,)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for one year\n",
    "tsstr = tsstr[:13]\n",
    "datetimes = datetimes[:13]\n",
    "datetimes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5eaeabcc-3fe3-470e-a9c8-1c6411ff02aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12,)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 'datetimes' is a list of datetime objects\n",
    "dt = [(datetimes[i+1] - datetimes[i]).total_seconds() for i in range(len(datetimes) - 1)]\n",
    "dt = np.array(dt)\n",
    "dt.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91db750f-36dc-4ab1-b93f-ba894de3648e",
   "metadata": {},
   "source": [
    "# create the J terms\n",
    "\n",
    "In general, when we create the time-mean for these terms we are interested in the mean weighted by depth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a21f6691-e230-4b8b-824d-d03a0f058289",
   "metadata": {},
   "source": [
    "### For salt\n",
    "\n",
    "We need to find a way to do this more efficiently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0ee7ec2e-bc47-49e7-897a-4d15a81b8c5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12, 50, 1350, 270)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read thetadr\n",
    "file_name = 'budg3d_snap_set2'\n",
    "meta_budg3d_snap_set2 = parsemeta(dirIn + file_name + \".\" + tsstr[0] + \".meta\")\n",
    "fldlist = np.array(meta_budg3d_snap_set2[\"fldList\"])\n",
    "varnames = np.array([\"SALTDR\"])\n",
    "recs = np.array([])\n",
    "for var in varnames:\n",
    "    irec = np.where(fldlist == var)\n",
    "    recs = np.append(recs, irec[0][0])\n",
    "\n",
    "\n",
    "SALTDR = np.full((len(tsstr),nz,ny,nx),np.nan)\n",
    "for i in range(len(tsstr)):\n",
    "    thisSALTDR,its,meta = rdmds(os.path.join(dirIn, file_name),int(tsstr[i]),returnmeta=True,rec=recs[0])\n",
    "    thisSALTDR = thisSALTDR.reshape(nz,ny,nx)\n",
    "    SALTDR[i] = thisSALTDR\n",
    "\n",
    "SALTDR =  (SALTDR[1:, :, :,:] - SALTDR[:-1, :,:, :]) / dt[:,np.newaxis,np.newaxis,np.newaxis]    # PSU.m/s\n",
    "SALTDR.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "05aab7be-6f48-4b03-9ae6-9fd33299233e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmptend = myparms['rhoconst'] * (SALTDR - AB_gS) * np.tile(mk3D_mod(RAC,SALTDR[0])[np.newaxis,:,:,:],(SALTDR.shape[0],1,1,1))    # kg/m^3 * PSU.m/s * m^2 = g/s\n",
    "budgO = {}\n",
    "budgO['saltfluxes'] = {}\n",
    "budgI = {}\n",
    "budgI['saltfluxes'] = {}\n",
    "budgOI = {}\n",
    "\n",
    "# ocean\n",
    "budgO['saltfluxes']['tend'] = tmptend\n",
    "budgO['salttend'] = np.nansum(tmptend,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "991f9674-341b-4820-863f-7e0c0fc77a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "del SALTDR,tmptend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1787f3ac-12b7-4fe8-98c5-d38ad58ae408",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read adv and dfe\n",
    "file_name = \"budg3d_hflux_set2\"\n",
    "meta_budg3d_hflux_set2 = parsemeta(dirIn + file_name + \".\" + tsstr[0] + \".meta\")\n",
    "fldlist = np.array(meta_budg3d_hflux_set2[\"fldList\"])\n",
    "varnames = np.array([\"ADVx_SLT\",\"ADVy_SLT\",\"DFxE_SLT\",\"DFyE_SLT\"])\n",
    "recs = np.array([])\n",
    "for var in varnames:\n",
    "    irec = np.where(fldlist == var)\n",
    "    recs = np.append(recs, irec[0][0])\n",
    "\n",
    "# do this onle for datetimes[1:] so we can set it in the file\n",
    "saltfluxeshconv = np.zeros((len(tsstr)-1,nz,ny,nx))\n",
    "advfluxeshconv = np.zeros((len(tsstr)-1,nz,ny,nx))\n",
    "dffluxeshconv = np.zeros((len(tsstr)-1,nz,ny,nx))\n",
    "                     \n",
    "for t in range(len(tsstr[1:])):\n",
    "    t2 = int(tsstr[t + 1])\n",
    "    # read the files\n",
    "    ADVx_SLT,its,meta = rdmds(os.path.join(dirIn, file_name),t2,returnmeta=True,rec=recs[0])\n",
    "    ADVy_SLT,its,meta = rdmds(os.path.join(dirIn, file_name),t2,returnmeta=True,rec=recs[1])\n",
    "    DFxE_SLT,its,meta = rdmds(os.path.join(dirIn, file_name),t2,returnmeta=True,rec=recs[2])\n",
    "    DFyE_SLT,its,meta = rdmds(os.path.join(dirIn, file_name),t2,returnmeta=True,rec=recs[3])\n",
    "    \n",
    "    tmpUo = myparms['rhoconst'] * (ADVx_SLT + DFxE_SLT)\n",
    "    tmpVo = myparms['rhoconst'] * (ADVy_SLT + DFyE_SLT)\n",
    "    \n",
    "    # reshape and get the faces\n",
    "    tmpUo = tmpUo.reshape(nz,ny,nx)\n",
    "    tmpVo = tmpVo.reshape(nz,ny,nx)\n",
    "    tmpUo = get_aste_faces(tmpUo,nfx,nfy)              \n",
    "    tmpVo = get_aste_faces(tmpVo,nfx,nfy)\n",
    "\n",
    "    # set in the larger array\n",
    "    saltfluxeshconv[t] = calc_UV_conv_mod(nfx,nfy,tmpUo,tmpVo)\n",
    "\n",
    "\n",
    "    # also do for adv and df\n",
    "    tmpUo = get_aste_faces(ADVx_SLT.reshape(nz,ny,nx),nfx,nfy)\n",
    "    tmpVo = get_aste_faces(ADVy_SLT.reshape(nz,ny,nx),nfx,nfy)\n",
    "    advfluxeshconv[t] = calc_UV_conv_mod(nfx,nfy,tmpUo,tmpVo) * myparms['rhoconst'] #g/s\n",
    "\n",
    "    tmpUo = get_aste_faces(DFxE_SLT.reshape(nz,ny,nx),nfx,nfy)\n",
    "    tmpVo = get_aste_faces(DFyE_SLT.reshape(nz,ny,nx),nfx,nfy)\n",
    "    dffluxeshconv[t] = calc_UV_conv_mod(nfx,nfy,tmpUo,tmpVo) * myparms['rhoconst'] #g/s\n",
    "\n",
    "\n",
    "budgO['saltfluxes']['hconv'] = saltfluxeshconv\n",
    "budgO['saltfluxes']['ADV_hconv'] = advfluxeshconv\n",
    "budgO['saltfluxes']['DF_hconv'] = dffluxeshconv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c128ecdf-2eec-4381-8f99-f6d653677673",
   "metadata": {},
   "outputs": [],
   "source": [
    "del ADVx_SLT, ADVy_SLT, DFxE_SLT, DFyE_SLT\n",
    "del saltfluxeshconv,advfluxeshconv,dffluxeshconv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b633903b-3aea-4c04-9283-94a907e5acfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read fluxes\n",
    "file_name = 'budg2d_zflux_set1'\n",
    "meta_budg2d_zflux_set1 = parsemeta(dirIn + file_name + \".\" + tsstr[0] + \".meta\")\n",
    "fldlist = np.array(meta_budg2d_zflux_set1[\"fldList\"])\n",
    "varnames = np.array([\"oceSPflx\",\"SFLUX\",'oceFWflx','SIatmFW'])   # add in other terms to look at balance\n",
    "recs = np.array([])\n",
    "for var in varnames:\n",
    "    irec = np.where(fldlist == var)\n",
    "    recs = np.append(recs, irec[0][0])\n",
    "\n",
    "# read all the files\n",
    "oceSPflx = np.zeros((len(tsstr)-1,ny,nx))\n",
    "SFLUX = np.zeros((len(tsstr)-1,ny,nx))\n",
    "oceFWflx = np.zeros((len(tsstr)-1,ny,nx))\n",
    "SIatmFW = np.zeros((len(tsstr)-1,ny,nx))\n",
    "\n",
    "# loop and add to list\n",
    "for t in range(len(tsstr[1:])):\n",
    "    t2 = int(tsstr[t+1])  # +1 so we can read end of budg time steps\n",
    "    \n",
    "    tmpoceSPflx,its,meta = rdmds(os.path.join(dirIn, file_name),t2,returnmeta=True,rec=recs[0])   # g/m^2/s\n",
    "    tmpSFLUX,its,meta = rdmds(os.path.join(dirIn, file_name),t2,returnmeta=True,rec=recs[1])      # g/m^2/s\n",
    "    tmpoceFWflx,its,meta = rdmds(os.path.join(dirIn, file_name),t2,returnmeta=True,rec=recs[2])   # kg/m^2/s\n",
    "    tmpSIatmFW,its,meta = rdmds(os.path.join(dirIn, file_name),t2,returnmeta=True,rec=recs[3])    # kg/m^2/s\n",
    "\n",
    "    tmpoceSPflx = tmpoceSPflx.reshape(ny,nx)\n",
    "    tmpSFLUX = tmpSFLUX.reshape(ny,nx)\n",
    "    tmpoceFWflx = tmpoceFWflx.reshape(ny,nx)\n",
    "    tmpSIatmFW = tmpSIatmFW.reshape(ny,nx)\n",
    "\n",
    "    # add to bigger array\n",
    "    oceSPflx[t] = tmpoceSPflx\n",
    "    SFLUX[t] = tmpSFLUX\n",
    "    oceFWflx[t] = tmpoceFWflx\n",
    "    SIatmFW[t] = tmpSIatmFW\n",
    "\n",
    "# array to store all the files\n",
    "oceSflux = np.zeros((len(tsstr)-1,ny,nx))\n",
    "WSLTMASS = np.zeros((len(tsstr)-1,ny,nx))\n",
    "SRELAX = np.zeros((len(tsstr)-1,ny,nx))\n",
    "\n",
    "# read relax and salt mass\n",
    "file_name = \"budg2d_zflux_set2\"\n",
    "meta_budg2d_zflux_set2 = parsemeta(dirIn + file_name + \".\" + tsstr[0] + \".meta\")\n",
    "fldlist = np.array(meta_budg2d_zflux_set2[\"fldList\"])\n",
    "varnames = np.array([\"oceSflux\",\"WSLTMASS\",\"SRELAX\"])\n",
    "recs = np.array([])\n",
    "for var in varnames:\n",
    "    irec = np.where(fldlist == var)\n",
    "    if len(irec[0]) > 0:\n",
    "        recs = np.append(recs, irec[0][0])\n",
    "\n",
    "# loop and add to list\n",
    "for t in range(len(tsstr[1:])):\n",
    "    t2 = int(tsstr[t+1])\n",
    "\n",
    "    tmpoceSflux,its,meta = rdmds(os.path.join(dirIn, file_name),t2,returnmeta=True,rec=recs[0])\n",
    "    tmpWSLTMASS,its,meta = rdmds(os.path.join(dirIn, file_name),t2,returnmeta=True,rec=recs[1])\n",
    "    tmpSRELAX,its,meta = rdmds(os.path.join(dirIn, file_name),t2,returnmeta=True,rec=recs[1])\n",
    "    tmpoceSflux = tmpoceSflux.reshape(ny,nx)\n",
    "    tmpWSLTMASS = tmpWSLTMASS.reshape(ny,nx)\n",
    "    tmpSRELAX = tmpSRELAX.reshape(ny,nx)\n",
    "\n",
    "    # add to bigger array\n",
    "    oceSflux[t] = tmpoceSflux\n",
    "    WSLTMASS[t] = tmpWSLTMASS\n",
    "    SRELAX[t] = tmpSRELAX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd4aae2-ca63-48af-b5ba-b2fce6bb7952",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read kpp tend and from 3d zflux\n",
    "file_name = \"budg3d_kpptend_set1\"\n",
    "meta_budg3d_kpptend_set1 = parsemeta(dirIn + file_name + \".\" + tsstr[0] + \".meta\")\n",
    "fldlist = np.array(meta_budg3d_kpptend_set1[\"fldList\"])\n",
    "varnames = np.array([\"oceSPtnd\",\"KPPg_SLT\"])\n",
    "recs = np.array([])\n",
    "for var in varnames:\n",
    "    irec = np.where(fldlist == var)\n",
    "    if len(irec[0]) > 0:\n",
    "        recs = np.append(recs, irec[0][0])\n",
    "\n",
    "oceSPtnd = np.zeros((len(tsstr)-1,nz,ny,nx))\n",
    "KPPg_SLT = np.zeros((len(tsstr)-1,nz,ny,nx))\n",
    "\n",
    "# loop and add to list\n",
    "for t in range(len(tsstr[1:])):\n",
    "    t2 = int(tsstr[t+1])  # +1 so we can read end of budg time steps\n",
    "\n",
    "    tmpoceSPtnd,its,meta = rdmds(os.path.join(dirIn, file_name),t2,returnmeta=True,rec=recs[0])\n",
    "    tmpKPPg_SLT,its,meta = rdmds(os.path.join(dirIn, file_name),t2,returnmeta=True,rec=recs[1])\n",
    "    tmpoceSPtnd = tmpoceSPtnd.reshape(nz,ny,nx)\n",
    "    tmpKPPg_SLT = tmpKPPg_SLT.reshape(nz,ny,nx)\n",
    "\n",
    "    oceSPtnd[t] = tmpoceSPtnd\n",
    "    KPPg_SLT[t] = tmpKPPg_SLT\n",
    "\n",
    "\n",
    "# now 3d zfluxes\n",
    "file_name = \"budg3d_zflux_set2\"\n",
    "meta_budg3d_zflux_set2 = parsemeta(dirIn + file_name + \".\" + tsstr[0] + \".meta\")\n",
    "fldlist = np.array(meta_budg3d_zflux_set2[\"fldList\"])\n",
    "varnames = np.array([\"ADVr_SLT\",\"DFrE_SLT\",\"DFrI_SLT\"])\n",
    "recs = np.array([])\n",
    "for var in varnames:\n",
    "    irec = np.where(fldlist == var)\n",
    "    recs = np.append(recs, irec[0][0])\n",
    "\n",
    "# do same time-reading\n",
    "ADVr_SLT = np.zeros((len(tsstr)-1,nz,ny,nx))\n",
    "DFrE_SLT = np.zeros((len(tsstr)-1,nz,ny,nx))\n",
    "DFrI_SLT = np.zeros((len(tsstr)-1,nz,ny,nx))\n",
    "\n",
    "# loop and add to list\n",
    "for t in range(len(tsstr[1:])):\n",
    "    t2 = int(tsstr[t+1])  # +1 so we can read end of budg time steps\n",
    "\n",
    "    tmpADVr_SLT,its,meta = rdmds(os.path.join(dirIn, file_name),t2,returnmeta=True,rec=recs[0])\n",
    "    tmpDFrE_SLT,its,meta = rdmds(os.path.join(dirIn, file_name),t2,returnmeta=True,rec=recs[1])\n",
    "    tmpDFrI_SLT,its,meta = rdmds(os.path.join(dirIn, file_name),t2,returnmeta=True,rec=recs[2])\n",
    "    tmpADVr_SLT = tmpADVr_SLT.reshape(nz,ny,nx)\n",
    "    tmpDFrE_SLT = tmpDFrE_SLT.reshape(nz,ny,nx)\n",
    "    tmpDFrI_SLT = tmpDFrI_SLT.reshape(nz,ny,nx)\n",
    "\n",
    "    # add to bigger array\n",
    "    ADVr_SLT[t] = tmpADVr_SLT\n",
    "    DFrE_SLT[t] = tmpDFrE_SLT\n",
    "    DFrI_SLT[t] = tmpDFrI_SLT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20308115-81e8-4945-8a5e-66e23bd06089",
   "metadata": {},
   "outputs": [],
   "source": [
    "if myparms[\"useRFWF\"]==0 or myparms['useNLFS']==0:\n",
    "    print('do nothing')\n",
    "else:\n",
    "    oceSflux = 0 * oceSflux\n",
    "\n",
    "if myparms['useNLFS'] == 0:\n",
    "    print('do nothing, already read above')\n",
    "else:\n",
    "    WSLTMASS=0*WSLTMASS\n",
    "\n",
    "budgO['saltzconv'] = SFLUX + oceSPflx                  # W/m^2\n",
    "zconv_top_salt = (SFLUX + oceSPflx) * RAC               # g/s\n",
    "budgI['saltzconv'] = -budgO['saltzconv'] + SRELAX\n",
    "\n",
    "if myparms['useNLFS']==0:\n",
    "    budgO['saltzconv'] = budgO['saltzconv'] - myparms['rhoconst']*WSLTMASS\n",
    "\n",
    "if myparms['useRFWF']==0 or myparms['useNLFS']==0:\n",
    "    budgI['saltzconv']=-oceSflux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3252fad2-792d-49a7-96ac-c50f2c4844ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tester to look at shapes\n",
    "\n",
    "\n",
    "nr = mygrid['RC'].shape[0]\n",
    "# break trWtop down into smaller terms\n",
    "trWtopADV = -(ADVr_SLT)*myparms['rhoconst']           # g/s\n",
    "trWtopDF = -(DFrE_SLT+DFrI_SLT)*myparms['rhoconst']   # g/s\n",
    "trWtopKPP = -(KPPg_SLT)*myparms['rhoconst']           # g/s\n",
    "trWtop = trWtopADV + trWtopDF + trWtopKPP             # g/s "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11964441-e00e-4e5a-9225-698355d76d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "nr = mygrid['RC'].shape[0]\n",
    "# break trWtop down into smaller terms\n",
    "trWtopADV = -(ADVr_SLT)*myparms['rhoconst']           # g/s\n",
    "trWtopDF = -(DFrE_SLT+DFrI_SLT)*myparms['rhoconst']   # g/s\n",
    "trWtopKPP = -(KPPg_SLT)*myparms['rhoconst']           # g/s\n",
    "trWtop = trWtopADV + trWtopDF + trWtopKPP             # g/s \n",
    "\n",
    "print(trWtop.shape)\n",
    "sptop = np.tile(oceSPflx[:,np.newaxis,:,:],(1,nz,1,1)) - np.cumsum(oceSPtnd, axis=1)        # we include this in our zconv_top term\n",
    "sptop = sptop * np.tile(RAC3[np.newaxis,:,:,:],(len(tsstr)-1,1,1,1))        # g/s\n",
    "\n",
    "trWtop[:,1:,:,:] = trWtop[:,1:,:,:] + sptop[:,:-1,:,:]\n",
    "trWtop[:,0,:,:] = budgO['saltzconv'] * RAC    # g/s top layer is surface flux\n",
    "\n",
    "trWbot = np.zeros_like(trWtop)\n",
    "trWbot[:,:-1,:,:] = trWtop[:,1:,:,:]\n",
    "trWbot[:,-1,:,:] = 0\n",
    "\n",
    "budgO['saltfluxes']['trWtop'] = trWtop     # g/s\n",
    "budgO['saltfluxes']['trWbot'] = trWbot     # g/s\n",
    "\n",
    "budgI['saltfluxes']['trWtop'] = -RAC*0\n",
    "budgI['saltfluxes']['trWbot'] = budgO['saltfluxes']['trWtop'][:,0,:,:]  # surface because ice\n",
    "\n",
    "budgO['saltfluxes']['zconv'] = budgO['saltfluxes']['trWtop'] - budgO['saltfluxes']['trWbot']\n",
    "budgO['saltzconv'] = np.tile(RAC[np.newaxis,:,:],(len(tsstr)-1,1,1)) * budgO['saltzconv']   # g/s\n",
    "budgI['saltzconv'] = np.tile(RAC[np.newaxis,:,:],(len(tsstr)-1,1,1)) * budgI['saltzconv']   # g/s\n",
    "budgOI['saltzconv'] = budgO['saltzconv'] + budgI['saltzconv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87acfd8e-fb3d-4421-896e-97122ee348bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "del trWtop,trWbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59419990-00e6-4784-9690-93137cea3906",
   "metadata": {},
   "outputs": [],
   "source": [
    "# do vertical convergence for ADV and DF terms\n",
    "tmpadv = np.full((len(tsstr)-1,nz,ny,nx),np.nan)\n",
    "tmpadv[:,:-1,:,:] = (trWtopADV[:,:-1] - trWtopADV[:,1:])              # for surface thru seafloor\n",
    "\n",
    "Sconv = budgO['saltfluxes']['ADV_hconv'] + tmpadv\n",
    "budgO['saltfluxes']['ADV_Sconv'] = Sconv             # g/s, this is the advective arrow of S for a cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "909422bd-45cd-40f4-b161-d3cf8fd45fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# do vertical convergence for ADV and DF terms\n",
    "tmpdf = np.full((len(tsstr)-1,nz,ny,nx),np.nan)\n",
    "tmpdf[:,:-1,:,:] = (trWtopDF[:,:-1] - trWtopDF[:,1:])              # for surface thru seafloor\n",
    "\n",
    "dfSconv = budgO['saltfluxes']['DF_hconv'] + tmpdf\n",
    "budgO['saltfluxes']['DF_Sconv'] = dfSconv             # g/s, this is the diffusive arrow of T for a cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370d3303-f016-49bc-b924-3bf95a631e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmpkpp = np.full((len(tsstr)-1,nz,ny,nx),np.nan)\n",
    "tmpkpp[:,:-1,:,:] = trWtopKPP[:,:-1] - trWtopKPP[:,1:]\n",
    "budgO['saltfluxes']['KPP_Sconv'] = tmpkpp        # no horizontal component for this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ea4408-b760-4821-8167-3fc9c3963bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete all the files from the salt budget\n",
    "del tmpkpp, dfSconv,tmpdf,tmpadv,Sconv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df15c671-ebd1-45f0-ba79-fe532becb596",
   "metadata": {},
   "source": [
    "### For heat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279d38a0-573b-4d8e-931f-560b3fd53760",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start with the tendency\n",
    "# read thetadr\n",
    "file_name = 'budg3d_snap_set2'\n",
    "meta_budg3d_snap_set2 = parsemeta(dirIn + file_name + \".\" + tsstr[0] + \".meta\")\n",
    "fldlist = np.array(meta_budg3d_snap_set2[\"fldList\"])\n",
    "varnames = np.array([\"THETADR\"])\n",
    "recs = np.array([])\n",
    "for var in varnames:\n",
    "    irec = np.where(fldlist == var)\n",
    "    recs = np.append(recs, irec[0][0])\n",
    "\n",
    "THETADR = np.full((len(tsstr),nz,ny,nx),np.nan)\n",
    "for i in range(len(tsstr)):\n",
    "    thisTHETADR,its,meta = rdmds(os.path.join(dirIn, file_name),int(tsstr[i]),returnmeta=True,rec=recs[0])\n",
    "    thisTHETADR = thisTHETADR.reshape(nz,ny,nx)\n",
    "    THETADR[i] = thisTHETADR\n",
    "\n",
    "THETADR =  (THETADR[1:, :, :,:] - THETADR[:-1, :,:, :]) / dt[:,np.newaxis,np.newaxis,np.newaxis]    # PSU.m/s    # degC.m/s\n",
    "THETADR.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbfed303-bfef-471f-b9e1-29bd204bfc41",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmptend=myparms['rcp']*(THETADR-AB_gT)* np.tile(RAC[np.newaxis,np.newaxis,:,:],(len(tsstr)-1,nz,1,1))  # J/m^3.degC * degC.m/s * m^2 = J/s\n",
    "budgO = {}\n",
    "budgI = {}\n",
    "budgO['heatfluxes'] = {}\n",
    "budgI['heatfluxes'] = {}\n",
    "\n",
    "budgO['heatfluxes']['tend'] = tmptend     # J/s\n",
    "\n",
    "budgO['heattend'] = np.nansum(tmptend,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5452bc8a-7fd7-4344-acae-003f8f0f3274",
   "metadata": {},
   "outputs": [],
   "source": [
    "del THETADR, tmptend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffeff405-31a6-41b4-a162-c0c4a4c99718",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the files\n",
    "file_name = 'budg2d_zflux_set1'\n",
    "meta_budg2d_zflux_set1 = parsemeta(dirIn + file_name + \".\" + tsstr[0] + \".meta\")\n",
    "fldlist = np.array(meta_budg2d_zflux_set1[\"fldList\"])\n",
    "varnames = np.array([\"TFLUX\",\"oceQsw\",\"SItflux\"])\n",
    "recs = np.array([])\n",
    "for var in varnames:\n",
    "    irec = np.where(fldlist == var)\n",
    "    recs = np.append(recs, irec[0][0])\n",
    "\n",
    "TFLUX = np.zeros((len(tsstr)-1,ny,nx))\n",
    "oceQsw = np.zeros((len(tsstr)-1,ny,nx))\n",
    "SItflux = np.zeros((len(tsstr)-1,ny,nx))\n",
    "# loop and add to list\n",
    "for t in range(len(tsstr[1:])):\n",
    "    t2 = int(tsstr[t+1])  # +1 so we can read end of budg time steps\n",
    "    tmpTFLUX,its,meta = rdmds(os.path.join(dirIn, file_name),t2,returnmeta=True,rec=recs[0])\n",
    "    tmpoceQsw,its,meta = rdmds(os.path.join(dirIn, file_name),t2,returnmeta=True,rec=recs[1])\n",
    "    tmpSItflux,its,meta = rdmds(os.path.join(dirIn, file_name),t2,returnmeta=True,rec=recs[2])\n",
    "    TFLUX[t] = tmpTFLUX.reshape(ny,nx)\n",
    "    oceQsw[t] = tmpoceQsw.reshape(ny,nx)\n",
    "    SItflux[t] = tmpSItflux.reshape(ny,nx)\n",
    "\n",
    "# note: the following works provided that the first 3 terms are definitely there\n",
    "file_name = \"budg2d_zflux_set2\"\n",
    "meta_budg2d_zflux_set2 = parsemeta(dirIn + file_name + \".\" + tsstr[0] + \".meta\")\n",
    "fldlist = np.array(meta_budg2d_zflux_set2[\"fldList\"])\n",
    "varnames = np.array([\"oceQnet\",\"WTHMASS\",\"SIaaflux\",\"TRELAX\"])\n",
    "recs = np.array([])\n",
    "for var in varnames:\n",
    "    irec = np.where(fldlist == var)\n",
    "    recs = np.append(recs, irec[0][0])\n",
    "# read the files in a loop to get all timesteps\n",
    "oceQnet = np.zeros((len(tsstr)-1,ny,nx))\n",
    "WTHMASS = np.zeros((len(tsstr)-1,ny,nx))\n",
    "SIaaflux = np.zeros((len(tsstr)-1,ny,nx))\n",
    "TRELAX = np.zeros((len(tsstr)-1,ny,nx))\n",
    "for t in range(len(tsstr[1:])):\n",
    "    t2 = int(tsstr[t+1])\n",
    "    tmpoceQnet,its,meta = rdmds(os.path.join(dirIn, file_name),t2,returnmeta=True,rec=recs[0])\n",
    "    tmpWTHMASS,its,meta = rdmds(os.path.join(dirIn, file_name),t2,returnmeta=True,rec=recs[1])\n",
    "    tmpSIaaflux,its,meta = rdmds(os.path.join(dirIn, file_name),t2,returnmeta=True,rec=recs[2])\n",
    "    tmpTRELAX,its,meta = rdmds(os.path.join(dirIn, file_name),t2,returnmeta=True,rec=recs[3])\n",
    "    oceQnet[t] = tmpoceQnet.reshape(ny,nx)\n",
    "    WTHMASS[t] = tmpWTHMASS.reshape(ny,nx)\n",
    "    SIaaflux[t] = tmpSIaaflux.reshape(ny,nx)\n",
    "    TRELAX[t] = tmpTRELAX.reshape(ny,nx)\n",
    "\n",
    "# note: will not work if these are defined, fix for future steps\n",
    "varnames = np.array([\"TRELAX\",\"SIabflux\",\"SIacflux\",\"SIeprflx\",\"SIfldflx\"])\n",
    "recs = np.array([])\n",
    "for var in varnames:\n",
    "    irec = np.where(fldlist == var)\n",
    "    if len(irec[0]) > 0:\n",
    "        recs = np.append(recs, irec[0][0])\n",
    "# if len(recs) == 0:\n",
    "SIabflux = np.zeros((len(tsstr)-1,ny, nx))\n",
    "SIacflux = np.zeros((len(tsstr)-1,ny, nx))\n",
    "SIeprflx = np.zeros((len(tsstr)-1,ny, nx))\n",
    "SIfldflx = np.zeros((len(tsstr)-1,ny, nx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae37c21-5f54-4b01-aba2-70faaf6e8d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "if myparms['useNLFS'] == 0:\n",
    "    print('do nothing, already read above')\n",
    "else:\n",
    "    WTHMASS=0*WTHMASS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abbdbb90-7540-458b-98f6-8b03fdcca608",
   "metadata": {},
   "outputs": [],
   "source": [
    "geothFlux = 0\n",
    "\n",
    "if myparms['SaltPlumeHeatFlux']:\n",
    "    print(1)\n",
    "else:\n",
    "    SPforcT1=0*np.ones((len(tsstr)-1,ny,nx))\n",
    "    oceEPtnd=0*np.ones((len(tsstr)-1,nz,ny,nx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837afd4c-bbe3-4ae6-b2ec-ea7676bd4856",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read kpp tend and from 3d zflux\n",
    "file_name = \"budg3d_kpptend_set1\"\n",
    "meta_budg3d_kpptend_set1 = parsemeta(dirIn + file_name + \".\" + tsstr[0] + \".meta\")\n",
    "fldlist = np.array(meta_budg3d_kpptend_set1[\"fldList\"])\n",
    "varnames = np.array([\"KPPg_TH\"])\n",
    "recs = np.array([])\n",
    "for var in varnames:\n",
    "    irec = np.where(fldlist == var)\n",
    "    recs = np.append(recs, irec[0][0])\n",
    "# loop through and add to the list\n",
    "KPPg_TH = np.zeros((len(tsstr)-1,nz,ny,nx))\n",
    "for t in range(len(tsstr[1:])):\n",
    "    t2 = int(tsstr[t+1])\n",
    "    tmpKPPg_TH,its,meta = rdmds(os.path.join(dirIn, file_name),t2,returnmeta=True,rec=recs[0])\n",
    "    KPPg_TH[t] = tmpKPPg_TH.reshape(nz,ny,nx)\n",
    "\n",
    "# now 3d zfluxes\n",
    "file_name = \"budg3d_zflux_set2\"\n",
    "meta_budg3d_zflux_set2 = parsemeta(dirIn + file_name + \".\" + tsstr[0] + \".meta\")\n",
    "fldlist = np.array(meta_budg3d_zflux_set2[\"fldList\"])\n",
    "varnames = np.array([\"ADVr_TH\",\"DFrE_TH\",\"DFrI_TH\"])\n",
    "recs = np.array([])\n",
    "for var in varnames:\n",
    "    irec = np.where(fldlist == var)\n",
    "    recs = np.append(recs, irec[0][0])\n",
    "# loop through the time steps and add\n",
    "ADVr_TH = np.zeros((len(tsstr)-1,nz,ny,nx))\n",
    "DFrE_TH = np.zeros((len(tsstr)-1,nz,ny,nx))\n",
    "DFrI_TH = np.zeros((len(tsstr)-1,nz,ny,nx))\n",
    "for t in range(len(tsstr[1:])):\n",
    "    t2 = int(tsstr[t+1])\n",
    "\n",
    "    tmpADVr_TH,its,meta = rdmds(os.path.join(dirIn, file_name),t2,returnmeta=True,rec=recs[0])\n",
    "    tmpDFrE_TH,its,meta = rdmds(os.path.join(dirIn, file_name),t2,returnmeta=True,rec=recs[1])\n",
    "    tmpDFrI_TH,its,meta = rdmds(os.path.join(dirIn, file_name),t2,returnmeta=True,rec=recs[2])\n",
    "    ADVr_TH[t] = tmpADVr_TH.reshape(nz,ny,nx)\n",
    "    DFrE_TH[t] = tmpDFrE_TH.reshape(nz,ny,nx)\n",
    "    DFrI_TH[t] = tmpDFrI_TH.reshape(nz,ny,nx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3414b89f-aed4-47e9-8f9e-1511029678ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "budgO['heatzconv']=TFLUX+geothFlux+SPforcT1                           # W/m^2 = J/m^2/s\n",
    "zconv_top_heat = TFLUX  * RAC     # W/m^2 * m^2 = J/s\n",
    "budgI['heatzconv']=-(SItflux+TFLUX-TRELAX+SPforcT1)\n",
    "\n",
    "if myparms['useNLFS']==0:\n",
    "    budgO['heatzconv']=budgO['heatzconv']-myparms['rcp']*WTHMASS[:,:,:]     # degC.m/s * J/m^3degC = J/m^2.s\n",
    "\n",
    "budgI['heatzconv']=budgI['heatzconv']-SIabflux+SIacflux+SIeprflx\n",
    "if(myparms['SEAICEheatConsFix']==0):\n",
    "    budgI['heatzconv']=budgI['heatzconv']+SIaaflux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c3042ee-fb0b-49df-8598-abdfc9c51bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "del TFLUX,SPforcT1,WTHMASS,SIabflux,SIacflux,SIeprflx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f1764c-85b6-4bf4-a577-2968116332ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "nr = mygrid['RC'].shape[0]\n",
    "trWtopADV = -(ADVr_TH) * myparms['rcp']         # J/s\n",
    "trWtopDF = -(DFrE_TH+DFrI_TH) * myparms['rcp']  # J/s\n",
    "trWtopKPP = -(KPPg_TH) * myparms['rcp']         # J/s\n",
    "trWtop = trWtopADV + trWtopDF + trWtopKPP       # J/s\n",
    "dd = mygrid['RF'][:-1]\n",
    "swfrac = 0.62*np.exp(dd/0.6)+(1-0.62)*np.exp(dd/20)\n",
    "swfrac[dd < -200] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c6a33d-dd98-47d6-8286-f5a67790179a",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = (np.tile(RAC[np.newaxis,:,:],(len(tsstr)-1,1,1)) * oceQsw)\n",
    "b = np.tile(swfrac[np.newaxis,:,np.newaxis,np.newaxis],(len(tsstr)-1,1,ny,nx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc91974-dc71-442e-98bd-b66f8e501499",
   "metadata": {},
   "outputs": [],
   "source": [
    "swtop = b * np.tile(a[:,np.newaxis,:,:],(1,nz,1,1))   # J/s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e433d121-15f7-49b3-90fa-ede1a91da2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(swtop.shape,trWtop.shape)\n",
    "\n",
    "mskC=np.tile(mygrid['mskC'][np.newaxis,:,:,:],(len(tsstr)-1,1,1,1))\n",
    "print(mskC.shape)\n",
    "swtop[np.isnan(mskC)]=0\n",
    "trWtop=trWtop+swtop  # 323"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd85ac16-ca82-4636-a0f5-d210266c75c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "trWtop[:,0,:,:]=budgO['heatzconv']*np.tile(RAC[np.newaxis,:,:],(len(tsstr)-1,1,1))\n",
    "trWbot = np.zeros_like(trWtop)\n",
    "trWbot[:,:-1,:,:]=trWtop[:,1:,:,:]\n",
    "\n",
    "budgO[\"heatfluxes\"][\"trWtop\"] = trWtop\n",
    "budgO[\"heatfluxes\"][\"trWbot\"] = trWbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0aede14-bf02-4357-b148-c2fbbebbb350",
   "metadata": {},
   "outputs": [],
   "source": [
    "del trWtop,trWbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9e3a0d-12a1-45ba-92b2-7a34007eeac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "budgI[\"heatfluxes\"][\"trWtop\"] = -np.tile(RAC[np.newaxis,:,:],(len(tsstr)-1,1,1)) * (budgI[\"heatzconv\"] + budgO[\"heatzconv\"])\n",
    "budgI[\"heatfluxes\"][\"trWbot\"] = -np.tile(RAC[np.newaxis,:,:],(len(tsstr)-1,1,1)) * budgO[\"heatzconv\"]\n",
    "budgO['heatfluxes']['zconv']=budgO['heatfluxes']['trWtop']-budgO['heatfluxes']['trWbot']\n",
    "\n",
    "budgO['heatzconv'] = np.tile(RAC[np.newaxis,:,:],(len(tsstr)-1,1,1))*budgO['heatzconv']  # J/s\n",
    "budgI['heatzconv']=np.tile(RAC[np.newaxis,:,:],(len(tsstr)-1,1,1))*budgI['heatzconv']    # J/s\n",
    "# budgOI['heatzconv']=budgO['heatzconv']+budgI['heatzconv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af087af8-4d8d-4a97-a997-964687acbedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read adv and dfe\n",
    "file_name = \"budg3d_hflux_set2\"\n",
    "meta_budg3d_hflux_set2 = parsemeta(dirIn + file_name + \".\" + tsstr[0] + \".meta\")\n",
    "fldlist = np.array(meta_budg3d_hflux_set2[\"fldList\"])\n",
    "varnames = np.array([\"ADVx_TH\",\"ADVy_TH\",\"DFxE_TH\",\"DFyE_TH\"])\n",
    "recs = np.array([])\n",
    "for var in varnames:\n",
    "    irec = np.where(fldlist == var)\n",
    "    recs = np.append(recs, irec[0][0])\n",
    "\n",
    "# do this onle for datetimes[1:] so we can set it in the file\n",
    "heatfluxeshconv = np.zeros((len(tsstr)-1,nz,ny,nx))\n",
    "advfluxeshconv = np.zeros((len(tsstr)-1,nz,ny,nx))\n",
    "dffluxeshconv = np.zeros((len(tsstr)-1,nz,ny,nx))\n",
    "                     \n",
    "for t in range(len(tsstr[1:])):\n",
    "    print(t)\n",
    "    t2 = int(tsstr[t + 1])\n",
    "    # read the files\n",
    "    ADVx_TH,its,meta = rdmds(os.path.join(dirIn, file_name),t2,returnmeta=True,rec=recs[0])\n",
    "    ADVy_TH,its,meta = rdmds(os.path.join(dirIn, file_name),t2,returnmeta=True,rec=recs[1])\n",
    "    DFxE_TH,its,meta = rdmds(os.path.join(dirIn, file_name),t2,returnmeta=True,rec=recs[2])\n",
    "    DFyE_TH,its,meta = rdmds(os.path.join(dirIn, file_name),t2,returnmeta=True,rec=recs[3])\n",
    "\n",
    "    tmpUo = myparms['rcp'] * (ADVx_TH + DFxE_TH)\n",
    "    tmpVo = myparms['rcp'] * (ADVy_TH + DFyE_TH)\n",
    "    tmpUo = tmpUo.reshape(nz,ny,nx)\n",
    "    tmpVo = tmpVo.reshape(nz,ny,nx)\n",
    "    \n",
    "    # reshape and get the faces\n",
    "    tmpUo = get_aste_faces(tmpUo,nfx,nfy)              \n",
    "    tmpVo = get_aste_faces(tmpVo,nfx,nfy)\n",
    "\n",
    "    # set in the larger array\n",
    "    heatfluxeshconv[t] = calc_UV_conv_mod(nfx,nfy,tmpUo,tmpVo)\n",
    "\n",
    "    # also do for adv and df\n",
    "    tmpUo = get_aste_faces(ADVx_TH.reshape(nz,ny,nx),nfx,nfy)\n",
    "    tmpVo = get_aste_faces(ADVy_TH.reshape(nz,ny,nx),nfx,nfy)\n",
    "    advfluxeshconv[t] = calc_UV_conv_mod(nfx,nfy,tmpUo,tmpVo) * myparms['rcp']          #J/s\n",
    "\n",
    "    tmpUo = get_aste_faces(DFxE_TH.reshape(nz,ny,nx),nfx,nfy)\n",
    "    tmpVo = get_aste_faces(DFyE_TH.reshape(nz,ny,nx),nfx,nfy)\n",
    "    dffluxeshconv[t] = calc_UV_conv_mod(nfx,nfy,tmpUo,tmpVo) * myparms['rcp']      #J/s\n",
    "\n",
    "budgO['heatfluxes']['hconv'] = heatfluxeshconv\n",
    "budgO['heatfluxes']['ADV_hconv'] = advfluxeshconv\n",
    "budgO['heatfluxes']['DF_hconv'] = dffluxeshconv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc2f6262-3e79-4985-9fd7-bdd4553bd52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "del heatfluxeshconv,advfluxeshconv,dffluxeshconv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4009064-b188-4720-8a5b-a755616b9f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# do vertical convergence for ADV and DF terms\n",
    "tmpadv = np.full((len(tsstr)-1,nz,ny,nx),np.nan)\n",
    "tmpadv[:,:-1,:,:] = (trWtopADV[:,:-1] - trWtopADV[:,1:])              # for surface thru seafloor\n",
    "\n",
    "Tconv = budgO['heatfluxes']['ADV_hconv'] + tmpadv\n",
    "budgO['heatfluxes']['ADV_Tconv'] = Tconv                            # J/s, this is the advective arrow of T for a cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7703e2d-8fb2-4068-9620-1628d9c74c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "del Tconv,tmpadv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6718995-a140-425c-b750-fc6ac5ec024f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# do vertical convergence for ADV and DF terms\n",
    "tmpdf = np.full((len(tsstr)-1,nz,ny,nx),np.nan)\n",
    "tmpdf[:,:-1,:,:] = (trWtopDF[:,:-1] - trWtopDF[:,1:])              # for surface thru seafloor\n",
    "\n",
    "dfTconv = budgO['heatfluxes']['DF_hconv'] + tmpdf\n",
    "budgO['heatfluxes']['DF_Tconv'] = dfTconv      # J/s, this is the diffusive arrow of T for a cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "622ed710-2960-421f-b1b4-5149d40ba0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "del dfTconv,tmpdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0168560a-8d29-490d-83de-5e67697ec048",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmpkpp = np.full((len(tsstr)-1,nz,ny,nx),np.nan)\n",
    "tmpkpp[:,:-1,:,:] = trWtopKPP[:,:-1] - trWtopKPP[:,1:]\n",
    "budgO['heatfluxes']['KPP_Tconv'] = tmpkpp        # no horizontal component for this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce9b5c7-b2a6-405b-a4c5-a20a74b79968",
   "metadata": {},
   "outputs": [],
   "source": [
    "del tmpkpp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "672b743a-bfa3-480d-b303-7a8d144c6366",
   "metadata": {},
   "source": [
    "# create an example time series OF SALT for a given set of points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e9eb6e8-5ed4-43cd-848f-845a35ef893f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the bins of TS data\n",
    "# try new T bins where different sizes\n",
    "refined_section = np.linspace(-3,8,93)\n",
    "coarse_section = np.linspace(8,15,21,endpoint=False)\n",
    "binsTH_edges = np.concatenate((refined_section,coarse_section[1:]))\n",
    "binsTH_centers = (binsTH_edges[:-1] + binsTH_edges[1:])/2\n",
    "nT = binsTH_edges.shape[0]-1\n",
    "\n",
    "# do bi-sectional form for S\n",
    "coarse_section = np.linspace(0, 28, 30, endpoint=False)\n",
    "refined_section = np.linspace(28, 40, 83)\n",
    "binsSLT_edges = np.concatenate((coarse_section, refined_section))\n",
    "binsSLT_centers = (binsSLT_edges[:-1] + binsSLT_edges[1:])/2\n",
    "nS = binsSLT_edges.shape[0]-1\n",
    "\n",
    "Tbin,Sbin = np.meshgrid(binsTH_edges,binsSLT_edges)\n",
    "Tbincent,Sbincent = np.meshgrid(binsTH_centers,binsSLT_centers)\n",
    "\n",
    "binwidthT = binsTH_edges[1:] - binsTH_edges[:-1]\n",
    "binwidthS = binsSLT_edges[1:] - binsSLT_edges[:-1]\n",
    "dT,dS = np.meshgrid(binwidthT,binwidthS)\n",
    "dT = dT.reshape(112,112,1)\n",
    "dS = dS.reshape(112,112,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f64aed3-7214-4bb2-b742-118e10793ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read theta and salt averages from the t2 timestep (average)\n",
    "file_name = \"state_3d_set1\"\n",
    "meta_budg3d_kpptend_set1 = parsemeta(dirState + file_name + \".\" + tsstr[0] + \".meta\")\n",
    "fldlist = np.array(meta_budg3d_kpptend_set1[\"fldList\"])\n",
    "varnames = np.array([\"THETA\",\"SALT\"])\n",
    "recs = np.array([])\n",
    "for var in varnames:\n",
    "    irec = np.where(fldlist == var)\n",
    "    recs = np.append(recs, irec[0][0])\n",
    "\n",
    "\n",
    "THETA = np.zeros((len(tsstr)-1,nz,ny,nx))\n",
    "SALT = np.zeros((len(tsstr)-1,nz,ny,nx))\n",
    "binned_theta = np.zeros((len(tsstr)-1,nz,ny,nx))\n",
    "binned_salt = np.zeros((len(tsstr)-1,nz,ny,nx))\n",
    "\n",
    "# loop and add to list\n",
    "for t in range(len(tsstr[1:])):\n",
    "    t2 = int(tsstr[t+1])  # +1 so we can read end of budg time steps\n",
    "\n",
    "    tmpTHETA,its,meta = rdmds(os.path.join(dirState, file_name),t2,returnmeta=True,rec=recs[0])\n",
    "    tmpSALT,its,meta = rdmds(os.path.join(dirState, file_name),t2,returnmeta=True,rec=recs[1])\n",
    "    tmpTHETA = tmpTHETA.reshape(nz,ny,nx)\n",
    "    tmpSALT = tmpSALT.reshape(nz,ny,nx)\n",
    "\n",
    "    # set in larger array\n",
    "    THETA[t] = tmpTHETA\n",
    "    SALT[t] = tmpSALT\n",
    "\n",
    "    # bin for temp\n",
    "    tmpbinned_theta = bin_array(tmpTHETA,binsTH_edges)\n",
    "    tmpbinned_theta = tmpbinned_theta.astype(float)\n",
    "    tmpbinned_theta[tmpbinned_theta == nT] = np.nan\n",
    "    binned_theta[t] = tmpbinned_theta\n",
    "\n",
    "    # also for salt\n",
    "    tmpbinned_salt = bin_array(tmpSALT,binsSLT_edges)\n",
    "    tmpbinned_salt = tmpbinned_salt.astype(float)\n",
    "    tmpbinned_salt[tmpbinned_salt == nS] = np.nan\n",
    "    binned_salt[t] = tmpbinned_salt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca9ded68-5d39-427c-a3d7-97c639350992",
   "metadata": {},
   "outputs": [],
   "source": [
    "del THETA,SALT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d10d6716-5d88-4fcb-bbf3-fc4986db2dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# also make arrays of the binned_theta and binned_salt widths\n",
    "default_value = 0\n",
    "binwidthT_map = np.full_like(binned_theta, default_value, dtype=np.float64)\n",
    "valid_mask = ~np.isnan(binned_theta)\n",
    "binwidthT_map[valid_mask] = binwidthT[binned_theta[valid_mask].astype(int)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c993bea9-be87-426a-b9b1-86433189ff59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for salt\n",
    "binwidthS_map = np.full_like(binned_theta, default_value, dtype=np.float64)\n",
    "binwidthS_map[valid_mask] = binwidthS[binned_salt[valid_mask].astype(int)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45e9c871-ac35-4551-a8f1-5270abab2b90",
   "metadata": {},
   "source": [
    "# create points, the example points at the surface in the Barents Sea, so we can do a time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c28f3058-f5ec-4867-8947-dd4e35693eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pt = np.array([[50,540,0],\n",
    "               [100,500,0]])      # first is an extreme point, second is a more \"normal\" or midrange point for 03/2014\n",
    "\n",
    "x = pt[0][0]\n",
    "y = pt[0][1]\n",
    "z = pt[0][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51571f83-bfa1-4f0b-8e35-0e61fa659877",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get some example points for the basin\n",
    "\n",
    "y_indices, x_indices = np.meshgrid(np.arange(ny), np.arange(nx), indexing='ij')\n",
    "condition = (mskBasin == iB)\n",
    "\n",
    "x_points = x_indices[condition]\n",
    "y_points = y_indices[condition]\n",
    "\n",
    "# # Combine the x and y points into a single array of shape (npoints, 2)\n",
    "points = np.vstack((y_points, x_points)).T\n",
    "points.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe5ad8a-bdb6-4e78-acd2-2deef35921b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop through the time steps to grab the value\n",
    "JtermsS = np.zeros((len(tsstr)-1,5,nS,nT))\n",
    "\n",
    "JtendSfull = np.array([])\n",
    "JADVSfull = np.array([])\n",
    "JDFSfull = np.array([])\n",
    "JKPPSfull = np.array([])\n",
    "JsurfSfull = np.array([])\n",
    "\n",
    "for t in range(len(tsstr)-1):\n",
    "    \n",
    "    # grab the info on the vectors for each\n",
    "    aS = budgO['saltfluxes']['tend'][t]\n",
    "    bS = budgO['saltfluxes']['ADV_Sconv'][t]\n",
    "    cS = budgO['saltfluxes']['DF_Sconv'][t]\n",
    "    dS = budgO['saltfluxes']['KPP_Sconv'][t]\n",
    "    eS = zconv_top_salt[t].reshape(1,ny,nx)\n",
    "    fS = sptop[t]\n",
    "\n",
    "    # for each y,x point in the time steps, integrate the J terms to find total transformation\n",
    "\n",
    "    # get indices for bins\n",
    "    \n",
    "    # save the J terms here as maps\n",
    "    JtendS = (aS[0])*mymsk / myparms['rhoconst'] / binwidthT_map[t][0] / binwidthS_map[t][0] * 1e-6             # Sv/degC\n",
    "    JADVS = (bS[0])*mymsk / myparms['rhoconst'] / binwidthT_map[t][0] / binwidthS_map[t][0] * 1e-6              # Sv/degC\n",
    "    JDFS = (cS[0])*mymsk / myparms['rhoconst'] / binwidthT_map[t][0] / binwidthS_map[t][0] * 1e-6               # Sv/degC\n",
    "    JKPPS = (dS[0])*mymsk / myparms['rhoconst'] / binwidthT_map[t][0] / binwidthS_map[t][0] * 1e-6              # Sv/degC\n",
    "    JsurfS= (eS[0] - fS[0])*mymsk / myparms['rhoconst'] / binwidthT_map[t][0] / binwidthS_map[t][0] * 1e-6  # Sv/degC\n",
    "\n",
    "    # get the integrated version of the values in each map\n",
    "    JtendSsum = 0\n",
    "    JADVSsum = 0\n",
    "    JDFSsum = 0\n",
    "    JKPPSsum = 0\n",
    "    JsurfSsum = 0\n",
    "\n",
    "    # loop and get the value at each y,x set\n",
    "    for pt in points:\n",
    "        y,x = pt[0],pt[1]\n",
    "        JtendSsum += JtendS[y,x]\n",
    "        JADVSsum += JADVS[y,x]\n",
    "        JDFSsum += JDFS[y,x]\n",
    "        JKPPSsum += JKPPS[y,x]\n",
    "        JsurfSsum += JsurfS[y,x]\n",
    "\n",
    "    JtendSfull = np.append(JtendSfull,JtendSsum)\n",
    "    JADVSfull = np.append(JADVSfull,JADVSsum)\n",
    "    JDFSfull = np.append(JDFSfull,JDFSsum)\n",
    "    JKPPSfull = np.append(JKPPSfull,JKPPSsum)\n",
    "    JsurfSfull = np.append(JsurfSfull,JsurfSsum)\n",
    "\n",
    "    #print(\"residual: \",aS[0,y,x]- bS[0,y,x] - cS[0,y,x] - dS[0,y,x] - eS[0,y,x] + fS[0,y,x], \" g/s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb10fc4b-fef4-4ca7-8372-815191e4e79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we can look at a time series of each of the J terms for salt at this given cell in a given year\n",
    "\n",
    "fig = plt.figure(figsize=(10,9))\n",
    "plt.suptitle((\"Surface Ocean Salt Tend 2014\"))\n",
    "\n",
    "plt.subplots_adjust(hspace=0.6)  # bigger hspace -- more vertical space\n",
    "\n",
    "ax = plt.subplot(611)\n",
    "ax.plot(datetimes[:-1],JtendSfull)\n",
    "ax.set_title(\"salt tend\")\n",
    "ax.grid()\n",
    "ax.set_ylabel(\"Sv/degC\")\n",
    "\n",
    "ax = plt.subplot(612)\n",
    "ax.plot(datetimes[:-1],JADVSfull)\n",
    "ax.set_title(\"ADV salt tend\")\n",
    "ax.grid()\n",
    "ax.set_ylabel(\"Sv/degC\")\n",
    "\n",
    "ax = plt.subplot(613)\n",
    "ax.plot(datetimes[:-1],JDFSfull)\n",
    "ax.set_title(\"DF salt tend\")\n",
    "ax.grid()\n",
    "ax.set_ylabel(\"Sv/degC\")\n",
    "\n",
    "ax = plt.subplot(614)\n",
    "ax.plot(datetimes[:-1],JKPPSfull)\n",
    "ax.set_title(\"KPP salt tend\")\n",
    "ax.grid()\n",
    "ax.set_ylabel(\"Sv/degC\")\n",
    "\n",
    "ax = plt.subplot(615)\n",
    "ax.plot(datetimes[:-1],JsurfSfull)\n",
    "ax.set_title(\"surf salt tend\")\n",
    "ax.grid()\n",
    "ax.set_ylabel(\"Sv/degC\")\n",
    "\n",
    "ax = plt.subplot(616)\n",
    "ax.plot(datetimes[:-1],(JADVSfull+JDFSfull+JKPPSfull+JsurfSfull))\n",
    "ax.set_title(\"tend from terms\")\n",
    "ax.grid()\n",
    "ax.set_ylabel(\"Sv/degC\")\n",
    "\n",
    "plt.savefig(path + \"surface_salt_timeseries2014.png\",dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d440607e-d012-452f-8028-bb3e1334f4ba",
   "metadata": {},
   "source": [
    "# do the same J terms breakdown for theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d068ed0b-f501-4058-a240-2cf521d22d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "JtermsT = np.zeros((len(tsstr)-1,5,nS,nT))\n",
    "\n",
    "JtendTfull = np.array([])\n",
    "JADVTfull = np.array([])\n",
    "JDFTfull = np.array([])\n",
    "JKPPTfull = np.array([])\n",
    "JsurfTfull = np.array([])\n",
    "\n",
    "for t in range(len(tsstr)-1):\n",
    "    \n",
    "    # show the vectors for each\n",
    "    aT = budgO['heatfluxes']['tend'][t]\n",
    "    bT = budgO['heatfluxes']['ADV_Tconv'][t]\n",
    "    cT = budgO['heatfluxes']['DF_Tconv'][t]\n",
    "    dT = budgO['heatfluxes']['KPP_Tconv'][t]\n",
    "    eT = zconv_top_heat[t].reshape(1,ny,nx)\n",
    "    fT = swtop[t]\n",
    "\n",
    "    # get indices for bins\n",
    "\n",
    "    #aa = np.zeros((nz, 1))\n",
    "    #n = 0\n",
    "    #aa[:, n] = (aT[:, y, x] - bT[:, y, x] - cT[:, y, x] - dT[:, y, x])\n",
    "    #aa[1:-1, n] += (fT[2:,y,x] - fT[1:-1,y,x])    # for swtop we want the difference between the top and bottom\n",
    "    #aa[0, n] += fT[1,y,x]\n",
    "    #aa[0, n] -= zconv_top_heat[t][y, x]      # subtract the TFLUX at the surface only\n",
    "\n",
    "    # save the J terms for here for the single point   \n",
    "    JtendT = (aT[0]) / myparms['rcp'] / binwidthT_map[t][0] / binwidthS_map[t][0] * 1e-6             # Sv/PSU\n",
    "    JADVT = (bT[0]) / myparms['rcp'] / binwidthT_map[t][0] / binwidthS_map[t][0] * 1e-6              # Sv/PSU\n",
    "    JDFT = (cT[0]) / myparms['rcp'] / binwidthT_map[t][0] / binwidthS_map[t][0] * 1e-6               # Sv/PSU\n",
    "    JKPPT = (dT[0]) / myparms['rcp'] / binwidthT_map[t][0] / binwidthS_map[t][0] * 1e-6              # Sv/PSU\n",
    "    JsurfT = (eT[0] - fT[1]) / myparms['rcp'] / binwidthT_map[t][0] / binwidthS_map[t][0] * 1e-6 # Sv/PSU\n",
    "\n",
    "    JtendTsum = 0\n",
    "    JADVTsum = 0\n",
    "    JDFTsum = 0\n",
    "    JKPPTsum = 0\n",
    "    JsurfTsum = 0\n",
    "\n",
    "\n",
    "    # get the total value\n",
    "    for pt in points:\n",
    "        y,x = pt[0],pt[1]\n",
    "        JtendTsum += JtendT[y,x]\n",
    "        JADVTsum += JADVT[y,x]\n",
    "        JDFTsum += JDFT[y,x]\n",
    "        JKPPTsum += JKPPT[y,x]\n",
    "        JsurfTsum += JsurfT[y,x]\n",
    "\n",
    "    JtendTfull = np.append(JtendTfull,JtendTsum)\n",
    "    JADVTfull = np.append(JADVTfull,JADVTsum)\n",
    "    JDFTfull = np.append(JDFTfull,JDFTsum)\n",
    "    JKPPTfull = np.append(JKPPTfull,JKPPTsum)\n",
    "    JsurfTfull = np.append(JsurfTfull,JsurfTsum)\n",
    "\n",
    "    #print(\"residual: \",aT[0,y,x]- bT[0,y,x] - cT[0,y,x] - dT[0,y,x] - eT[0,y,x] + fT[1,y,x], \" J/s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb46e79-a72e-4e06-ab3b-e3bb8ed30f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we can look at the time series of the salt terms\n",
    "\n",
    "# now we can look at a time series of each of the J terms for salt at this given cell in a given year\n",
    "\n",
    "fig = plt.figure(figsize=(10,9))\n",
    "plt.suptitle((\"Surface Ocean theta Tend 2014\"))\n",
    "\n",
    "plt.subplots_adjust(hspace=0.6)  # bigger hspace -- more vertical space\n",
    "\n",
    "ax = plt.subplot(611)\n",
    "ax.plot(datetimes[:-1],JtendTfull)\n",
    "ax.set_title(\"heat tend\")\n",
    "ax.grid()\n",
    "ax.set_ylabel(\"Sv/PSU\")\n",
    "\n",
    "ax = plt.subplot(612)\n",
    "ax.plot(datetimes[:-1],JADVTfull)\n",
    "ax.set_title(\"ADV theta tend\")\n",
    "ax.grid()\n",
    "ax.set_ylabel(\"Sv/PSU\")\n",
    "\n",
    "ax = plt.subplot(613)\n",
    "ax.plot(datetimes[:-1],JDFTfull)\n",
    "ax.set_title(\"DF theta tend\")\n",
    "ax.grid()\n",
    "ax.set_ylabel(\"Sv/PSU\")\n",
    "\n",
    "ax = plt.subplot(614)\n",
    "ax.plot(datetimes[:-1],JKPPTfull)\n",
    "ax.set_title(\"KPP theta tend\")\n",
    "ax.grid()\n",
    "ax.set_ylabel(\"Sv/PSU\")\n",
    "\n",
    "ax = plt.subplot(615)\n",
    "ax.plot(datetimes[:-1],JsurfTfull)\n",
    "ax.set_title(\"surf theta tend\")\n",
    "ax.grid()\n",
    "ax.set_ylabel(\"Sv/PSU\")\n",
    "\n",
    "ax = plt.subplot(616)\n",
    "ax.plot(datetimes[:-1],(JADVTfull+JDFTfull+JKPPTfull+JsurfTfull))\n",
    "ax.set_title(\"tend from terms\")\n",
    "ax.grid()\n",
    "ax.set_ylabel(\"Sv/PSU\")\n",
    "\n",
    "plt.savefig(path + \"surface_theta_timeseries2014.png\",dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4063027-1558-430f-8df5-bb44c53d4b05",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
