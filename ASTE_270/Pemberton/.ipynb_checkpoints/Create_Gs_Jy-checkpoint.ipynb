{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "decf7d7a-f5e1-4571-b8e7-41c0cf9a068b",
   "metadata": {},
   "source": [
    "# Import packages and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e626610-f51e-499c-86e8-a9e2b77a6bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import xarray as xr\n",
    "import h5py\n",
    "from scipy.io import loadmat\n",
    "import matplotlib as mpl\n",
    "import time\n",
    "import gsw\n",
    "from matplotlib.colors import TwoSlopeNorm\n",
    "\n",
    "# import existing python files\n",
    "plt.rcParams['figure.figsize'] = (10,4)\n",
    "\n",
    "# add rdmds reading functions to path\n",
    "sys.path.append(\"/home/mmurakami/MITgcm/MITgcm_c68r/MITgcm-checkpoint68r/utils/python/MITgcmutils/MITgcmutils/\") # go to parent dir\n",
    "from mds import *\n",
    "\n",
    "# add the other files\n",
    "sys.path.append(\"/home/mmurakami/crios_backups/an_helper_functions\")\n",
    "from read_binary import *\n",
    "from calc_UV_conv_1face import calc_UV_conv_1face\n",
    "from calc_mskmean_T_mod import calc_mskmean_T_mod\n",
    "from mk3D_mod import mk3D_mod\n",
    "from aste_helper_funcs import *\n",
    "from timing_functions import *           # ts2dte, get_fnames, etc.\n",
    "from binning import *                    # bin_array, create_mesh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0397ddcf-d971-4383-bc9d-8b88d723b43c",
   "metadata": {},
   "source": [
    "# Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "acfd2fbb-9046-464e-bd65-308994ae2f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "iB = 6\n",
    "tsnap = 2\n",
    "\n",
    "path = \"/home/mmurakami/crios_backups/ASTE_270/offline_binning/sample_images/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6addff1e-efa7-46b4-ba20-bffaf926be15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50,) (50, 1350, 270)\n",
      "hf1 (1350, 270)\n",
      "(1, 1350, 270)\n"
     ]
    }
   ],
   "source": [
    "dirroot = \"/scratch2/atnguyen/aste_270x450x180/\"\n",
    "dirrun = \"/scratch/atnguyen/aste_270x450x180/OFFICIAL_ASTE_R1_Sep2019/\"\n",
    "dirIn = dirrun + \"diags/BUDG/\"\n",
    "dirDiags = dirrun + \"diags/\"\n",
    "dirState = dirDiags + \"STATE/\"\n",
    "dirGrid = dirroot + \"GRID_real8/\"\n",
    "dirgridnb = dirroot + \"GRID_noblank/\"\n",
    "dirgridw = dirroot + \"GRID_wet/\"\n",
    "dirtrsp = dirDiags + \"TRSP/\"\n",
    "\n",
    "bigaste = True\n",
    "\n",
    "if bigaste:\n",
    "    nx = 270\n",
    "    ncut1 = 450\n",
    "    ncut2 = 180\n",
    "else:\n",
    "    nx = 90\n",
    "    ncut1 = 150\n",
    "    ncut2 = 60\n",
    "    \n",
    "ny = 2*ncut1+nx+ncut2\n",
    "nz = 50\n",
    "nfx = np.array([nx, 0 , nx, ncut2 ,ncut1])\n",
    "nfy = np.array([ncut1, 0 , nx, nx, nx])\n",
    "\n",
    "# save myParms from An hard-coding\n",
    "save_budg_3d = 0\n",
    "save_budg_2d = 1\n",
    "save_budg_scalar = 0\n",
    "save_budg_lev = 0\n",
    "\n",
    "strbudg = 'Mass'\n",
    "kBudget = 1\n",
    "test3d = True\n",
    "plot_fig = 1\n",
    "# kz = [[1, 5], [6, 10], [11, 19], [20, 23]]\n",
    "\n",
    "myparms = {\n",
    "    'yearFirst': 1979,\n",
    "    'yearLast': 1979,\n",
    "    'yearInAv': [1979, 1979],\n",
    "    'timeStep': 3600,\n",
    "    'iceModel': 1,\n",
    "    'useRFWF': 1,\n",
    "    'useNLFS': 4,\n",
    "    'rStar': 2,\n",
    "    'rhoconst': 1029,\n",
    "    'rcp': 1029 * 3994,    # reference seawater specific heat capacity (1029 kg/m^3) * (3994 J/kg K) = J/(m^3*degC)\n",
    "    'rhoi': 910,\n",
    "    'rhosn': 330,\n",
    "    'flami': 334000,\n",
    "    'flamb': 2500000,\n",
    "    'SIsal0': 4,\n",
    "    'diagsAreMonthly': 0,\n",
    "    'diagsAreAnnual': 0,\n",
    "    'recInAve': [1, 2],\n",
    "    'SaltPlumeHeatFlux': 0,  # Not sure what this is\n",
    "    'conserveTr': 0\n",
    "}\n",
    "\n",
    "deltaTime = myparms['timeStep']\n",
    "dt = 86400\n",
    "\n",
    "# get time-steps:\n",
    "flist = [f for f in os.listdir(dirIn) if f.startswith('budg2d_snap_set1.') and f.endswith('.data')]\n",
    "idot = flist[0].index('.')\n",
    "idot = [idot+1, flist[0][idot+1:].index('.')+idot+1]\n",
    "idot = np.asarray(idot,dtype=int)\n",
    "\n",
    "mygrid = {\n",
    "    'dirGrid': dirGrid,\n",
    "    'nFaces': 1,\n",
    "    'fileFormat': 'compact',\n",
    "    'memoryLimit': 2,\n",
    "    'ioSize': [nx*ny, 1],\n",
    "    'facesSize': [ny, nx],\n",
    "    'facesExpand': [ny, nx],\n",
    "    'missVal': 0,\n",
    "}\n",
    "\n",
    "fldstr2d = ['XC','YC','XG','YG','RAC','Depth','DXG','DYG','DXC','DYC']\n",
    "fldstr3d = ['hFacC','hFacW','hFacS','mskC','mskS','mskW']\n",
    "fldstr3dp = ['hFacC','hFacW','hFacS','maskCtrlC','maskCtrlS','maskCtrlW']\n",
    "fldstr1d = ['RC','RF','DRC','DRF']\n",
    "\n",
    "for fld in fldstr1d:\n",
    "    mygrid[fld] = np.squeeze(rdmds(os.path.join(dirGrid, fld)))\n",
    "\n",
    "for fld in fldstr3d:\n",
    "    temp = rdmds(os.path.join(dirGrid, fldstr3dp[fldstr3d.index(fld)]))\n",
    "    mygrid[fld] = temp.reshape(nz, ny, nx)\n",
    "\n",
    "for fld in fldstr2d:\n",
    "    temp = rdmds(os.path.join(dirGrid, fld))\n",
    "    mygrid[fld] = temp.reshape(ny, nx)\n",
    "\n",
    "mygrid['mskC'][mygrid['mskC'] == 0] = np.nan\n",
    "\n",
    "areaW, areaS, Vol = [], [], []\n",
    "for k in range(nz):\n",
    "    areaW.append(mygrid['DYG'] * mygrid['DRF'][k])\n",
    "    areaS.append(mygrid['DXG'] * mygrid['DRF'][k])\n",
    "    Vol.append(mygrid['RAC'] * mygrid['DRF'][k])\n",
    "\n",
    "# block out obcs\n",
    "# np tile I think operates the same as repmat in MATLAB\n",
    "RAC = mygrid['RAC']\n",
    "RAC3 = np.tile(RAC,(nz,1,1))\n",
    "\n",
    "hfC = mygrid['hFacC']\n",
    "DD = mygrid['Depth']\n",
    "dxg = mygrid['DXG']\n",
    "dyg = mygrid['DYG']\n",
    "dxg3d = np.tile(dxg,(nz,1,1))\n",
    "dyg3d = np.tile(dyg,(nz,1,1))\n",
    "\n",
    "print(mygrid['DRF'].shape,np.zeros((nz, ny, nx)).shape)\n",
    "drf3d = mk3D_mod(mygrid['DRF'], np.zeros((nz, ny, nx)))\n",
    "DD3d = mk3D_mod(DD,np.zeros((nz, ny, nx)))\n",
    "\n",
    "hfC[hfC == 0] = np.nan\n",
    "hfC1 = hfC[0, :, :]\n",
    "hfC1[hfC1 == 0] = np.nan\n",
    "\n",
    "RACg = RAC * hfC1\n",
    "hfC1p = np.copy(hfC1)\n",
    "\n",
    "hfC1p[:, nx-1] = np.nan\n",
    "hfC1p[ny-1,:] = np.nan\n",
    "RACgp = RAC * hfC1p\n",
    "\n",
    "# mygrid['hFacC'][mygrid['hFacC'] > 0] = 1\n",
    "mygrid['hFacC'][mygrid['hFacC'] == 0] = np.nan\n",
    "# hFacCpartial = mygrid['hFacC']\n",
    "# mygrid['hFacC'][mygrid['hFacC'] > 0] = 1\n",
    "hf1 = mygrid['hFacC'][0] # top layer in z\n",
    "\n",
    "print(\"hf1\",hf1.shape)\n",
    "\n",
    "hf1 = get_aste_tracer(hf1, nfx, nfy)\n",
    "# check with hardcoding on this for mini or big aste\n",
    "if nx == 90:\n",
    "    hf1[:,281,:] = np.nan\n",
    "    hf1[:,7,:] = np.nan\n",
    "    hf1[:,86,122] = np.nan\n",
    "elif nx == 270:\n",
    "    hf1[:,844,:] = np.nan\n",
    "    hf1[:,23,:] = np.nan\n",
    "    hf1[:,365,260:261] = np.nan\n",
    "\n",
    "hf1 = aste_tracer2compact(hf1,nfx,nfy)\n",
    "print(hf1.shape)\n",
    "hf = mygrid[\"hFacC\"]\n",
    "hf = hf * np.tile(hf1,(nz, 1,1))\n",
    "\n",
    "DRF3d = mk3D_mod(mygrid[\"DRF\"],np.zeros((nz, ny, nx)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66f4944c-929c-4d2d-bb65-6ec55bea6160",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10650\n"
     ]
    }
   ],
   "source": [
    "# copy basin listing from lookat_layers\n",
    "fileprefix = \"/scratch/pillarh/aste_270x450x180/\"\n",
    "extBasin='run_template/input_maskTransport/'\n",
    "filename = fileprefix + extBasin + \"GATE_transports_v3_osnap.mat\"\n",
    "if nx == 270:\n",
    "    inf = loadmat(filename)\n",
    "    mskBasin = (inf[\"mskBasin\"])\n",
    "\n",
    "mskBasin = mskBasin.T               # python adjustment\n",
    "\n",
    "# this is now different syntax than the other file\n",
    "strb=np.array(['CanadaB','ChukchiS','MakarovB','AmundsenB','NansenB','BeringS','BarentsS','GINs','CAA',\n",
    "               'SPG','LabSea','NPac','NAtlantic','AtlS30'])\n",
    "\n",
    "mskBasin[mskBasin==50] =6\n",
    "mskBasin[mskBasin==200]=7\n",
    "mskBasin[mskBasin==300]=8\n",
    "mskBasin[mskBasin==400]=9\n",
    "mskBasin[mskBasin==500]=9\n",
    "mskBasin[mskBasin==600]=10\n",
    "mskBasin[mskBasin==700]=11\n",
    "mskBasin[mskBasin==-1]=12\n",
    "mskBasin[mskBasin==-100]=13\n",
    "latNA = 30\n",
    "lonNA = -82\n",
    "condition_13 = (mskBasin == 0) & (mygrid['YC'] > latNA) & (mygrid['XC'] > lonNA) & (hf1.reshape((ny,nx)) > 0)\n",
    "mskBasin[condition_13] = 13\n",
    "condition_14 = (mskBasin == 0) & (hf1.reshape((ny,nx)) > 0)\n",
    "mskBasin[condition_14] = 14\n",
    "\n",
    "mskBasin = mskBasin * hf1\n",
    "mskBasin = mskBasin[0,:,:]   # change indexing for  python\n",
    "mskBasin -= 1\n",
    "\n",
    "# create mskBasin3D to also add to the dataset\n",
    "mskBasin3D = np.tile(mskBasin[np.newaxis,:,:],(nz,1,1))\n",
    "mskBasin3D.shape\n",
    "\n",
    "# get the number of points in the basin and we can use this as a mask for later\n",
    "mymsk = mskBasin.copy()\n",
    "mymsk[mymsk != iB] = np.nan\n",
    "npoints = len(np.where(mymsk == iB)[0])   # set number of points in the basin to be used later\n",
    "print(npoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f5771df-30a6-4338-bf5c-298f97b4cc74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LwetC2d 146614\n",
      "LwetC 4833023\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 2d\n",
    "inf = h5py.File(dirgridw + 'Index_wet_hfacC_2D.mat')\n",
    "arr = inf['ind'][:]\n",
    "iwetC2d = arr[5,:]\n",
    "iwetC2d = iwetC2d.astype(\"int32\")\n",
    "iwetC2d -= 1\n",
    "LwetC2d = iwetC2d.shape[0]\n",
    "print(\"LwetC2d\",LwetC2d)\n",
    "\n",
    "# 3d\n",
    "inf = h5py.File(dirgridw + \"Index_wet_hfacC.mat\")\n",
    "arr = inf['ind'][:]\n",
    "iwetC = arr[5,:]\n",
    "iwetC = iwetC.astype(\"int32\")\n",
    "LwetC = iwetC.shape[0]\n",
    "print(\"LwetC\",LwetC)\n",
    "\n",
    "hf1flat = np.reshape(hf1,hf1.flatten().shape[0])\n",
    "hf2d = hf1flat[iwetC2d]\n",
    "\n",
    "# hf.shape - z, y, x\n",
    "# hf1.shape - 1, y, x\n",
    "hfflat = np.reshape(hf,hf.flatten().shape[0])\n",
    "hf3d = hfflat[iwetC]\n",
    "\n",
    "# load the gateways\n",
    "fileprefix = \"/scratch/pillarh/aste_270x450x180/\"\n",
    "extBasin='run_template/input_maskTransport/'\n",
    "filename = fileprefix + extBasin + \"GATE_transports_v3_osnap.mat\"\n",
    "if nx == 270:\n",
    "    inf = loadmat(filename)\n",
    "    #mskBasin = (inf[\"mskBasin\"])\n",
    "    ggate  = inf['ggate']\n",
    "    ggate2  = inf['ggate2']\n",
    "    \n",
    "num = 1\n",
    "for i in ggate[0]:\n",
    "    label = i[0][0][0]\n",
    "    # print(num,label)\n",
    "    num += 1\n",
    "print()\n",
    "\n",
    "num = 1\n",
    "for i in ggate2[0]:\n",
    "    label = (i[0][0][-2])\n",
    "    # print(num,label)\n",
    "    num += 1\n",
    "\n",
    "# we have to first make a dictionary\n",
    "gg = {}\n",
    "ggate1 = ggate[0]\n",
    "for mygate in ggate1:\n",
    "    name = mygate[0][0][0][0]\n",
    "    gg[name] = {}\n",
    "    gg[name]['ix'] = mygate[0][0][1][0]\n",
    "    gg[name]['jy'] = mygate[0][0][2][0]\n",
    "    gg[name]['signu'] = mygate[0][0][3][0]\n",
    "    gg[name]['signv'] = mygate[0][0][4][0]\n",
    "    gg[name]['descr'] = mygate[0][0][5][0]\n",
    "\n",
    "gg2 = {}\n",
    "ggate2a = ggate2[0]\n",
    "for mygate in ggate2a:\n",
    "    name = mygate[0][0][4][0]\n",
    "    gg2[name] = {}\n",
    "    gg2[name]['ix'] = mygate[0][0][0][0]\n",
    "    gg2[name]['jy'] = mygate[0][0][1][0]\n",
    "    gg2[name]['signu'] = mygate[0][0][2][0]\n",
    "    gg2[name]['signv'] = mygate[0][0][3][0]\n",
    "    gg2[name]['descr'] = mygate[0][0][5][0]\n",
    "\n",
    "# check with An to see if these are the same values\n",
    "for igate in gg.keys():\n",
    "    L = len(gg[igate]['ix'])\n",
    "    ivalid = np.zeros(L)\n",
    "    ind = np.empty(L)\n",
    "    ind.fill(np.nan)\n",
    "    indwet = np.empty(L)   # same as ind\n",
    "    indwet.fill(np.nan)\n",
    "    for i in range(L):\n",
    "        ind[i] = (gg[igate]['jy'][i] - 1) * nx + gg[igate]['ix'][i]\n",
    "        # It is quite possible some of the [ix,jy] were on land,\n",
    "        # which means it would not show up in iwet2d.full:\n",
    "        ii = np.where(iwetC2d == ind[i])[0]\n",
    "        if len(ii) > 0:\n",
    "            indwet[i] = ii[0]\n",
    "            ivalid[i] = 1\n",
    "        else:\n",
    "            indwet[i] = np.nan\n",
    "\n",
    "    # set it in the dictionary under the basin name\n",
    "    gg[igate]['indwet'] = indwet\n",
    "    gg[igate]['ivalid'] = ivalid\n",
    "\n",
    "# check with An to see if these are the same values\n",
    "for igate in gg2.keys():\n",
    "    L = len(gg2[igate]['ix'])\n",
    "    ivalid = np.zeros(L)\n",
    "    ind = np.empty(L)\n",
    "    ind.fill(np.nan)\n",
    "    indwet = np.empty(L)   # same as ind\n",
    "    indwet.fill(np.nan)\n",
    "    for i in range(L):\n",
    "        ind[i] = (gg2[igate]['jy'][i] - 1) * nx + gg2[igate]['ix'][i]\n",
    "        # It is quite possible some of the [ix,jy] were on land,\n",
    "        # which means it would not show up in iwet2d.full:\n",
    "        ii = np.where(iwetC2d == ind[i])[0]\n",
    "        if len(ii) > 0:\n",
    "            indwet[i] = ii[0]\n",
    "            ivalid[i] = 1\n",
    "        else:\n",
    "            indwet[i] = np.nan\n",
    "\n",
    "    # set it in the dictionary under the basin name\n",
    "    gg2[igate]['indwet'] = indwet\n",
    "    gg2[igate]['ivalid'] = ivalid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "724a8e8a-52d0-4da1-b95b-1e9a24181192",
   "metadata": {},
   "source": [
    "# Read in the transport files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "66c872fb-55dd-4d66-bc00-eabc0b9ccbdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an array of the time steps we want to read\n",
    "# use ts2dte to get december 2014\n",
    "# first make an array of filenames\n",
    "dt = 600 # for the MODEL, not for tendency calculations\n",
    "startyr = 2002\n",
    "endyr = 2019\n",
    "\n",
    "# all the filenames in the system\n",
    "fnames = get_fnames(dt,startyr,endyr)\n",
    "\n",
    "times = {}\n",
    "times[\"2014\"] = np.array([1,2,3,4,5,6,7,8,9,10,11,12])\n",
    "times[\"2015\"] = np.array([1])\n",
    "\n",
    "# the filenames we want for 2014\n",
    "tsstr,datetimes = get_tsteps(times,fnames,dt,startyr,1,1)\n",
    "\n",
    "# ocean and ice\n",
    "AB_gT=0\n",
    "AB_gS=0\n",
    "debug = False\n",
    "ffac = 1\n",
    "\n",
    "dt = np.array([])\n",
    "for i in range(1,len(datetimes)):\n",
    "    dt = np.append(dt,(datetimes[i]-datetimes[i-1]).total_seconds())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec7b5023-764c-4948-bf09-7181cb22db35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we want temperature and salt\n",
    "THETADR = np.full((len(tsstr),nz,ny,nx),np.nan)\n",
    "SALTDR = np.full((len(tsstr),nz,ny,nx),np.nan)\n",
    "\n",
    "for i in range(len(tsstr)):\n",
    "\n",
    "    # read the fldList\n",
    "    file_name = 'budg3d_snap_set2'\n",
    "    meta_budg3d_snap_set2 = parsemeta(dirIn + file_name + \".\" + tsstr[i] + \".meta\")\n",
    "    fldlist = np.array(meta_budg3d_snap_set2[\"fldList\"])\n",
    "    varnames = np.array([\"THETADR\",\"SALTDR\"])\n",
    "    recs = np.array([])\n",
    "    for var in varnames:\n",
    "        irec = np.where(fldlist == var)\n",
    "        recs = np.append(recs, irec[0][0])\n",
    "        \n",
    "    read = [int(tsstr[i])]\n",
    "    \n",
    "    # make sure order we write the variables is the same as the order in varnames, else we read the wrong thing\n",
    "    THETADRi,its,meta = rdmds(os.path.join(dirIn, file_name),read,returnmeta=True,rec=recs[0])  # degC.m\n",
    "    SALTDRi,its,meta = rdmds(os.path.join(dirIn, file_name),read,returnmeta=True,rec=recs[1])  # degC.m\n",
    "\n",
    "    THETADR[i,:,:,:] = np.reshape(THETADRi,(nz,ny,nx))\n",
    "    SALTDR[i,:,:,:] = np.reshape(SALTDRi,(nz,ny,nx))\n",
    "\n",
    "# divide first two and second two by dt\n",
    "theta = np.full((int(len(tsstr)),nz,ny,nx),np.nan)\n",
    "dthetadt = np.full((int(len(tsstr)-1),nz,ny,nx),np.nan)\n",
    "salt = np.full((int(len(tsstr)),nz,ny,nx),np.nan)\n",
    "dsaltdt = np.full((int(len(tsstr)-1),nz,ny,nx),np.nan)\n",
    "\n",
    "for i in range(len(tsstr)):\n",
    "    theta[i,:,:,:] = THETADR[i,:,:,:]/DRF3d/mygrid['hFacC']\n",
    "    salt[i,:,:,:]  = SALTDR[i,:,:,:]/DRF3d/mygrid['hFacC']\n",
    "\n",
    "for i in range(len(tsstr)-1):\n",
    "    dthetadt[i,:,:,:] = (THETADR[i,:,:,:]/DRF3d/mygrid['hFacC'] - THETADR[i-1,:,:,:]/DRF3d/mygrid['hFacC'])/dt[i-1]\n",
    "    dsaltdt[i,:,:,:] = (SALTDR[i,:,:,:]/DRF3d/mygrid['hFacC'] - SALTDR[i-1,:,:,:]/DRF3d/mygrid['hFacC'])/dt[i-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "db520cc5-9f55-425c-bf72-de88c0fdacac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "volume allocation shape (13, 50, 1350, 270)\n",
      "(13, 50, 1350, 270)\n"
     ]
    }
   ],
   "source": [
    "# for mass tendency (m^3/s) - time is not yet included in this block\n",
    "file_name = 'budg2d_snap_set1'\n",
    "\n",
    "# assuming all files are structured the same\n",
    "meta_budg2d_snap_set1 = parsemeta(dirIn + file_name + \".\" + tsstr[0]+ \".meta\")\n",
    "# try to read this with rec\n",
    "fldlist = np.array(meta_budg2d_snap_set1['fldList'])\n",
    "varnames = np.array(['ETAN'])\n",
    "recs = np.array([])\n",
    "for var in varnames:\n",
    "    irec = np.where(fldlist == var)\n",
    "    recs = np.append(recs, irec[0][0])\n",
    "\n",
    "# set for all months\n",
    "vol = np.full((len(tsstr),nz, ny, nx),np.nan)\n",
    "ETANS = np.full((len(tsstr),ny,nx),np.nan)\n",
    "print(\"volume allocation shape\",vol.shape)\n",
    "\n",
    "for t in range(len(tsstr)):\n",
    "    t1 = tsstr[t]\n",
    "    read = [int(t1)]\n",
    "\n",
    "    # make sure order we write the variables is the same as the order in varnames, else we read the wrong thing\n",
    "    ETAN,its,meta = rdmds(os.path.join(dirIn, file_name),read,returnmeta=True,rec=recs[0])\n",
    "\n",
    "    # choose by basin\n",
    "    ETAN = np.reshape(ETAN,(ny,nx)) #* wetmask[0,:,:]\n",
    "\n",
    "    # ocean\n",
    "    if debug:\n",
    "        print(read,its[0],its[1]) # these iteration numbers should be the same as read\n",
    "\n",
    "    # 3D, with rStar:\n",
    "    tmpvol = np.zeros((nz, ny, nx))\n",
    "    if myparms['useNLFS'] < 2 or myparms['rStar'] == 0:        # not this time\n",
    "        tmpvol[0,:, :] = ETAN * myparms['rhoconst'] * RAC\n",
    "        if myparms['useRFWF'] == 0:\n",
    "            tmpvol[0, :, :] = np.zeros((ny, nx))\n",
    "    else:    # 4/22 look at this one\n",
    "        if myparms['useRFWF'] != 0:                                 # we are using this  # check if tmp1 is the same as drf3d!!\n",
    "            tmp1 = mk3D_mod(mygrid['DRF'],hfC) * hfC     # m\n",
    "            tmp2 = tmp1/mk3D_mod(DD,tmp1)                # drf as a fraction of total depth, this allows us to distribute etan between z\n",
    "        else:\n",
    "            tmp2 = drf3d / mk3D_mod(DD, tmp1)\n",
    "\n",
    "        # this is still wrong, we want to subtract the ETAN anomaly from the existing volumes\n",
    "        tmpvol =  (tmp1 + tmp2*mk3D_mod(ETAN, tmp2)) * mk3D_mod(RAC, hfC) * ffac     # volume, m * m^2  = m^3\n",
    "\n",
    "    vol[t,:,:,:] = tmpvol\n",
    "\n",
    "print(vol.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "588dda29-d578-4d64-aebe-b241e8274297",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get velocity fields\n",
    "# read timesteps at index 1 and 3\n",
    "UVELMASS = np.full((int(len(tsstr)-1),nz,ny,nx),np.nan)\n",
    "VVELMASS = np.full((int(len(tsstr)-1),nz,ny,nx),np.nan)\n",
    "ADVx_TH = np.full((int(len(tsstr)-1),nz,ny,nx),np.nan)\n",
    "ADVy_TH = np.full((int(len(tsstr)-1),nz,ny,nx),np.nan)\n",
    "DFxE_TH = np.full((int(len(tsstr)-1),nz,ny,nx),np.nan)\n",
    "DFyE_TH = np.full((int(len(tsstr)-1),nz,ny,nx),np.nan)\n",
    "ADVx_SLT = np.full((int(len(tsstr)-1),nz,ny,nx),np.nan)\n",
    "ADVy_SLT = np.full((int(len(tsstr)-1),nz,ny,nx),np.nan)\n",
    "DFxE_SLT = np.full((int(len(tsstr)-1),nz,ny,nx),np.nan)\n",
    "DFyE_SLT = np.full((int(len(tsstr)-1),nz,ny,nx),np.nan)\n",
    "\n",
    "# read the averages from tsstr[1] and tsstr[3] - averages from March and September\n",
    "# start from 1 because these are averages\n",
    "for i in range(0,len(tsstr)-1):\n",
    "\n",
    "    meta_budg3d_hflux_set2= parsemeta(dirIn + \"budg3d_hflux_set2\" + '.' + tsstr[i+1] + '.meta')\n",
    "    fldlist = np.array(meta_budg3d_hflux_set2['fldList'])\n",
    "    varnames = np.array(['UVELMASS','VVELMASS','ADVx_TH','ADVy_TH','DFxE_TH','DFyE_TH','ADVx_SLT','ADVy_SLT','DFxE_SLT','DFyE_SLT'])\n",
    "    recs = np.array([])\n",
    "    for var in varnames:\n",
    "        irec = np.where(fldlist == var)\n",
    "        recs = np.append(recs, irec[0][0])\n",
    "    UVELMASSi,its,meta = rdmds(dirIn + \"budg3d_hflux_set2\", int(tsstr[i+1]),returnmeta=True,rec = recs[0])     # m/s\n",
    "    VVELMASSi,its,meta = rdmds(dirIn + \"budg3d_hflux_set2\", int(tsstr[i+1]),returnmeta=True,rec = recs[1])     # m/s\n",
    "    ADVx_THi,its,meta = rdmds(dirIn + \"budg3d_hflux_set2\", int(tsstr[i]),returnmeta=True,rec = recs[2])        # degC.m^3/s\n",
    "    ADVy_THi,its,meta = rdmds(dirIn + \"budg3d_hflux_set2\", int(tsstr[i]),returnmeta=True,rec = recs[3])        # degC.m^3/s\n",
    "    DFxE_THi,its,meta = rdmds(dirIn + \"budg3d_hflux_set2\", int(tsstr[i]),returnmeta=True,rec = recs[4])        # degC.m^3/s\n",
    "    DFyE_THi,its,meta = rdmds(dirIn + \"budg3d_hflux_set2\", int(tsstr[i]),returnmeta=True,rec = recs[5])        # degC.m^3/s\n",
    "    ADVx_SLTi,its,meta = rdmds(dirIn + \"budg3d_hflux_set2\", int(tsstr[i]),returnmeta=True,rec = recs[6])       # psu.m^3/s\n",
    "    ADVy_SLTi,its,meta = rdmds(dirIn + \"budg3d_hflux_set2\", int(tsstr[i]),returnmeta=True,rec = recs[7])       # psu.m^3/s\n",
    "    DFxE_SLTi,its,meta = rdmds(dirIn + \"budg3d_hflux_set2\", int(tsstr[i]),returnmeta=True,rec = recs[8])       # psu.m^3/s\n",
    "    DFyE_SLTi,its,meta = rdmds(dirIn + \"budg3d_hflux_set2\", int(tsstr[i]),returnmeta=True,rec = recs[9])       # psu.m^3/s\n",
    "    \n",
    "    # reshaping and fixing up\n",
    "    UVELMASS[i,:,:,:] = UVELMASSi.reshape(nz,ny,nx)\n",
    "    VVELMASS[i,:,:,:] = VVELMASSi.reshape(nz,ny,nx)\n",
    "    ADVx_TH[i,:,:,:] = ADVx_THi.reshape(nz,ny,nx)\n",
    "    ADVy_TH[i,:,:,:] = ADVy_THi.reshape(nz,ny,nx)\n",
    "    DFxE_TH[i,:,:,:] = DFxE_THi.reshape(nz,ny,nx)\n",
    "    DFyE_TH[i,:,:,:] = DFyE_THi.reshape(nz,ny,nx)\n",
    "    ADVx_SLT[i,:,:,:] = ADVx_SLTi.reshape(nz,ny,nx)\n",
    "    ADVy_SLT[i,:,:,:] = ADVy_SLTi.reshape(nz,ny,nx)\n",
    "    DFxE_SLT[i,:,:,:] = DFxE_SLTi.reshape(nz,ny,nx)\n",
    "    DFyE_SLT[i,:,:,:] = DFyE_SLTi.reshape(nz,ny,nx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b30a090f-cc49-42fa-8869-b12b254a0b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read from budg3d_zflux_set2\n",
    "# 'WVELMASS' 'ADVr_TH ' 'DFrE_TH ' 'DFrI_TH ' 'ADVr_SLT' 'DFrE_SLT' 'DFrI_SLT'\n",
    "# get velocity fields\n",
    "# read timesteps at index 1 and 3\n",
    "WVELMASS = np.full((int(len(tsstr)-1),nz,ny,nx),np.nan)\n",
    "ADVr_TH = np.full((int(len(tsstr)-1),nz,ny,nx),np.nan)\n",
    "DFrE_TH = np.full((int(len(tsstr)-1),nz,ny,nx),np.nan)\n",
    "DFrI_TH = np.full((int(len(tsstr)-1),nz,ny,nx),np.nan)\n",
    "ADVr_SLT = np.full((int(len(tsstr)-1),nz,ny,nx),np.nan)\n",
    "DFrE_SLT = np.full((int(len(tsstr)-1),nz,ny,nx),np.nan)\n",
    "DFrI_SLT = np.full((int(len(tsstr)-1),nz,ny,nx),np.nan)\n",
    "\n",
    "meta_budg3d_zflux_set2= parsemeta(dirIn + \"budg3d_zflux_set2\" + '.' + tsstr[i+1] + '.meta')\n",
    "fldlist = np.array(meta_budg3d_zflux_set2['fldList'])\n",
    "varnames = np.array(['WVELMASS','ADVr_TH','DFrE_TH','DFrI_TH','ADVr_SLT','DFrE_SLT','DFrI_SLT'])\n",
    "recs = np.array([])\n",
    "for var in varnames:\n",
    "    irec = np.where(fldlist == var)\n",
    "    recs = np.append(recs, irec[0][0])\n",
    "# read the averages from tsstr[1] and tsstr[3] - averages from March and September\n",
    "# start from 1 because these are averages\n",
    "for i in range(0,len(tsstr)-1):\n",
    "    WVELMASSi,its,meta = rdmds(dirIn + \"budg3d_hflux_set2\", int(tsstr[i+1]),returnmeta=True,rec = recs[0])     # m/s\n",
    "    ADVr_THi,its,meta = rdmds(dirIn + \"budg3d_hflux_set2\", int(tsstr[i+1]),returnmeta=True,rec = recs[1])     # degC/m/s\n",
    "    DFrE_THi,its,meta = rdmds(dirIn + \"budg3d_hflux_set2\", int(tsstr[i]),returnmeta=True,rec = recs[2])        # degC.m^3/s\n",
    "    DFrI_THi,its,meta = rdmds(dirIn + \"budg3d_hflux_set2\", int(tsstr[i]),returnmeta=True,rec = recs[3])        # degC.m^3/s\n",
    "    ADVr_SLTi,its,meta = rdmds(dirIn + \"budg3d_hflux_set2\", int(tsstr[i]),returnmeta=True,rec = recs[4])        # psu.m^3/s\n",
    "    DFrE_SLTi,its,meta = rdmds(dirIn + \"budg3d_hflux_set2\", int(tsstr[i]),returnmeta=True,rec = recs[5])        # psu.m^3/s\n",
    "    DFrI_SLTi,its,meta = rdmds(dirIn + \"budg3d_hflux_set2\", int(tsstr[i]),returnmeta=True,rec = recs[6])       # psu.m^3/s\n",
    "    \n",
    "    # reshaping and fixing up\n",
    "    WVELMASS[i,:,:,:] = WVELMASSi.reshape(nz,ny,nx)\n",
    "    ADVr_TH[i,:,:,:] = ADVr_THi.reshape(nz,ny,nx)\n",
    "    DFrE_TH[i,:,:,:] = DFrE_THi.reshape(nz,ny,nx)\n",
    "    DFrI_TH[i,:,:,:] = DFrI_THi.reshape(nz,ny,nx)\n",
    "    ADVr_SLT[i,:,:,:] = ADVr_SLTi.reshape(nz,ny,nx)\n",
    "    DFrE_SLT[i,:,:,:] = DFrE_SLTi.reshape(nz,ny,nx)\n",
    "    DFrI_SLT[i,:,:,:] = DFrI_SLTi.reshape(nz,ny,nx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "30725bed-4fb9-4ae7-9c94-de8734aaa5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# take means of these for memory storage, can change later\n",
    "UVELMASS = np.nanmean(UVELMASS,axis=0)\n",
    "VVELMASS = np.nanmean(VVELMASS,axis=0)\n",
    "ADVx_TH = np.nanmean(ADVx_TH,axis=0)\n",
    "ADVy_TH = np.nanmean(ADVy_TH,axis=0)\n",
    "DFxE_TH = np.nanmean(DFxE_TH,axis=0)\n",
    "DFyE_TH = np.nanmean(DFyE_TH,axis=0)\n",
    "ADVx_SLT = np.nanmean(ADVx_SLT,axis=0)\n",
    "ADVy_SLT = np.nanmean(ADVy_SLT,axis=0)\n",
    "DFxE_SLT = np.nanmean(DFxE_SLT,axis=0)\n",
    "DFyE_SLT = np.nanmean(DFyE_SLT,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c4adf7f7-ea87-4578-88a2-b9ddab575e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# take means of these for memory storage, can change later\n",
    "WVELMASS = np.nanmean(WVELMASS,axis=0)\n",
    "ADVr_TH = np.nanmean(ADVr_TH,axis=0)\n",
    "DFrE_TH = np.nanmean(DFrE_TH,axis=0)\n",
    "DFrI_TH = np.nanmean(DFrI_TH,axis=0)\n",
    "ADVr_SLT = np.nanmean(ADVr_SLT,axis=0)\n",
    "DFrE_SLT = np.nanmean(DFrE_SLT,axis=0)\n",
    "DFrI_SLT = np.nanmean(DFrI_SLT,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7a8ddc70-e0ed-4b0b-9df6-5adb96be4ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the vectors of u and v without mass weighting\n",
    "Uo = np.full((nz,ny-nfy[0]+1,nfx[0]*2+1),np.nan)\n",
    "Vo = np.full((nz,ny-nfy[0]+1,nfx[0]*2+1),np.nan)\n",
    "ADVx_THo = np.full((nz,ny-nfy[0]+1,nfx[0]*2+1),np.nan)\n",
    "ADVy_THo = np.full((nz,ny-nfy[0]+1,nfx[0]*2+1),np.nan)\n",
    "DFxE_THo = np.full((nz,ny-nfy[0]+1,nfx[0]*2+1),np.nan)\n",
    "DFyE_THo = np.full((nz,ny-nfy[0]+1,nfx[0]*2+1),np.nan)\n",
    "\n",
    "# for i in range((int(len(tsstr)-1))):\n",
    "for i in range((int(len(tsstr)-1))):\n",
    "    # get values from reading before\n",
    "    tmpU = UVELMASS[i]\n",
    "    tmpV = VVELMASS[i]\n",
    "    tmpUadvth = ADVx_TH[i]\n",
    "    tmpVadvth = ADVy_TH[i]\n",
    "    tmpUdfth = DFxE_TH[i]\n",
    "    tmpVdfth = DFyE_TH[i]\n",
    "\n",
    "    # get the vectors defined above\n",
    "    tmpUo,tmpVo = get_aste_vector_face1_3(tmpU,tmpV,nfx,nfy,False)\n",
    "    tmpUadvth,tmpVadvth = get_aste_vector_face1_3(tmpUadvth,tmpVadvth,nfx,nfy,False)\n",
    "    tmpUdfth,tmpVdfth = get_aste_vector_face1_3(tmpUdfth,tmpVdfth,nfx,nfy,False)\n",
    "\n",
    "    # add to larger arrays\n",
    "    Uo[i] = tmpUo\n",
    "    Vo[i] = tmpVo\n",
    "    ADVx_THo[i] = tmpUadvth\n",
    "    ADVy_THo[i] = tmpVadvth\n",
    "    DFxE_THo[i] = tmpUdfth\n",
    "    DFyE_THo[i] = tmpVdfth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3915a3d-a5c5-4829-bd78-b0172beb051f",
   "metadata": {},
   "source": [
    "# Create Gs and Gt\n",
    "\n",
    "In these, the variables should be the terms in m/s that are the layer thicknes due to salt/temp surface forcing, horizontal and vertical diffusivity and advection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f439a74b-57d3-474f-81b4-08edd59bbd36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are just volume flow across a boundary\n",
    "# to get this from ADVr_TH we would divide by the degC term , giving m^3/s, or also divide by RAC to get m/s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0d023715-1d21-47b3-ab9b-c5584a2b5bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "binsTH_edges = np.linspace(-3, 12, 113)\n",
    "binsTH_centers = (binsTH_edges[:-1] + binsTH_edges[1:])/2\n",
    "nT = binsTH_edges.shape[0]-1\n",
    "\n",
    "coarse_section = np.linspace(0, 28, 30, endpoint=False)\n",
    "refined_section = np.linspace(28, 40, 83)\n",
    "binsSLT_edges = np.concatenate((coarse_section, refined_section))\n",
    "binsSLT_centers = (binsSLT_edges[:-1] + binsSLT_edges[1:])/2\n",
    "nS = binsSLT_edges.shape[0]-1\n",
    "\n",
    "Tbin,Sbin = np.meshgrid(binsTH_edges,binsSLT_edges)\n",
    "\n",
    "binwidthT = binsTH_edges[1:] - binsTH_edges[:-1]\n",
    "binwidthS = binsSLT_edges[1:] - binsSLT_edges[:-1]\n",
    "dT,dS = np.meshgrid(binwidthT,binwidthS)\n",
    "dT = dT.reshape(112,112,1)\n",
    "dS = dS.reshape(112,112,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8dcbc6d7-6760-4392-9b4a-b839a51634ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_207779/2849937877.py:3: RuntimeWarning: Mean of empty slice\n",
      "  thetaavg = np.nanmean(theta[:-1],axis=0)\n",
      "/tmp/ipykernel_207779/2849937877.py:4: RuntimeWarning: Mean of empty slice\n",
      "  salinityavg = np.nanmean(salt[:-1],axis=0)\n"
     ]
    }
   ],
   "source": [
    "# first bin the theta and salinity\n",
    "# get averages of salt and theta to test\n",
    "thetaavg = np.nanmean(theta[:-1],axis=0)\n",
    "salinityavg = np.nanmean(salt[:-1],axis=0)\n",
    "\n",
    "# we want to bin theta and salt into the T and S bins\n",
    "binned_theta = bin_array(thetaavg,binsTH_edges)\n",
    "binned_theta = binned_theta.astype(float)\n",
    "binned_theta[binned_theta == nT] = np.nan     # because the binning is setting nan to last value\n",
    "binned_salinity = bin_array(salinityavg,binsSLT_edges)\n",
    "binned_salinity = binned_salinity.astype(float)\n",
    "binned_salinity[binned_salinity == nS] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6eb60bfa-7ded-4d6b-a1c6-dcba2cb19883",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_207779/1384774898.py:1: RuntimeWarning: Mean of empty slice\n",
      "  vol_mean = np.nanmean(vol,axis=0) * mymsk /iB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(50, 1350, 270)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vol_mean = np.nanmean(vol,axis=0) * mymsk /iB\n",
    "vol_mean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a6be172d-cb4d-4b8f-a7ea-94159f72ddbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(63,)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1 = gg['BarentsSeaOpening'][\"ix\"]-1   # 0 \n",
    "y1 = gg['BarentsSeaOpening'][\"jy\"]-1\n",
    "x1[x1 == 162] = 161\n",
    "\n",
    "test = np.full(mskBasin.shape,np.nan)\n",
    "test[y1,x1] = 1\n",
    "\n",
    "gateid = 1\n",
    "gate = \"BarentsSeaOpening\"\n",
    "direction = \"N/S\"  # direction of the cross section - might need to adjust each time\n",
    "# m = 5  # month\n",
    "x_curr,y_curr = x1,y1\n",
    "mygate = np.where(get_aste_tracer(test,nfx,nfy)[0] ==gateid)\n",
    "\n",
    "# plot bathymetry, velocity, temp profile, salt profile, density profile\n",
    "# we need to get the perpendicular flow to the indicated gate\n",
    "# define a function that looks to see if we are going lr or ud for each time\n",
    "# if lr - perpendicular would be ud - y direction, vvelmass\n",
    "# if ud - perpendicular would be lr - x direction, uvelmass\n",
    "def line_orientation(x, y):\n",
    "    orientations = np.array([])\n",
    "\n",
    "    # Iterate through the list of points\n",
    "    for i in range(1, len(x)):\n",
    "        if x[i] == x[i - 1] and y[i] != y[i - 1]:\n",
    "            orientations = np.append(orientations,\"V\") # vertical line add zonal transp\n",
    "        elif y[i] == y[i - 1] and x[i] != x[i - 1]:\n",
    "            orientations = np.append(orientations,\"H\") # horizontal line add meridional transp\n",
    "        else:\n",
    "            orientations = np.append(orientations,\"V\")  # fill na should be for top of vertical line (ie U)\n",
    "\n",
    "    # the last one will be the same as the second to last orientation so we can keep consistent sizing\n",
    "    orientations = np.append(orientations,orientations[-1])\n",
    "\n",
    "    return orientations\n",
    "\n",
    "choose_UV = line_orientation(mygate[1],mygate[0])\n",
    "choose_UV = np.tile(choose_UV,(nz,1))\n",
    "choose_UV[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b337e86f-7130-4a68-b9c9-359093a42faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try to isolate the areas along one gateway\n",
    "gatemask = mygrid['hFacC'][:,y_curr,x_curr]\n",
    "# this will be depth of cell * southern edge (mygrid['DXG']) if horizontal line or * western edge (mygrid['DYG']) if vertical)\n",
    "dxggate = mygrid['DXG'][y_curr,x_curr]\n",
    "dyggate = mygrid['DYG'][y_curr,x_curr]\n",
    "\n",
    "# we make an array of the length of the cells\n",
    "cell_lengths = np.full(choose_UV[0].shape[0],np.nan)\n",
    "for i in range(len(choose_UV[0])):\n",
    "    if choose_UV[0][i] == \"V\":\n",
    "        cell_lengths[i] = dyggate[i] #DYG\n",
    "    elif choose_UV[0][i] == \"H\":\n",
    "        cell_lengths[i] = dxggate[i] #DXG\n",
    "\n",
    "# print(np.nanmin(cell_lengths))\n",
    "cell_lengths = np.tile(cell_lengths,(nz,1))\n",
    "cell_area = cell_lengths * mygrid['DRF'].reshape(nz,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6244d984-3aee-4969-bdc2-d07d68859d66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 63) (50, 63) (50, 63)\n"
     ]
    }
   ],
   "source": [
    "vol_gate = vol_mean[:,y_curr,x_curr]\n",
    "binned_theta_gate = binned_theta[:,y_curr,x_curr]\n",
    "binned_salinity_gate = binned_salinity[:,y_curr,x_curr]\n",
    "print(vol_gate.shape,binned_theta_gate.shape,binned_salinity_gate.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "610b5111-1574-407d-b4b9-0a965db974e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 901, 541)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Uo.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d07890c9-1973-4837-92fb-4d62f0fc23df",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 26\u001b[0m\n\u001b[1;32m      5\u001b[0m fig \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39mfigure()\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# # third subplot - s vs Sv\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# ax = plt.subplot(121)\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# data = perpendicular_vel*cell_area*1e-6\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     23\u001b[0m \n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# fourth subplot - t vs Sv\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m uvelgate \u001b[38;5;241m=\u001b[39m aste_tracer2compact(Uo[\u001b[43mm\u001b[49m],nfx,nfy)\n\u001b[1;32m     27\u001b[0m vvelgate \u001b[38;5;241m=\u001b[39m aste_tracer2compact(Vo[m],nfx,nfy)\n\u001b[1;32m     28\u001b[0m uvelgate \u001b[38;5;241m=\u001b[39m uvelgate[:,y_curr,x_curr]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'm' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x400 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# as an example, we can look at the total advection (sum) in temperature divided by the binsTH\n",
    "# we want to bin the values to create a mesh for each T bin\n",
    "\n",
    "# look at the volume transport across the gate, then advective transport in x and diffusive transport in x\n",
    "fig = plt.figure()\n",
    "\n",
    "# # third subplot - s vs Sv\n",
    "# ax = plt.subplot(121)\n",
    "# data = perpendicular_vel*cell_area*1e-6\n",
    "# tmps = np.zeros(binsSLT_centers.shape)\n",
    "# for i in range (vol_gate.shape[0]):\n",
    "#     for j in range(nz):\n",
    "#         tmpbinsalt = binned_salinity_gate[i,j]\n",
    "#         if not np.isnan(tmpbinsalt):\n",
    "#             tmps[int(tmpbinsalt)] += data[j,i]\n",
    "# ax.plot(binsSLT_centers,tmps)\n",
    "# ax.set_xlim(33.5,35.5)\n",
    "# ax.grid()\n",
    "# ax.set_ylabel(\"Sv\")\n",
    "# ax.set_xlabel(\"PSU\")\n",
    "# ax.set_title(\"Transport across gate\")\n",
    "\n",
    "\n",
    "# fourth subplot - t vs Sv\n",
    "Uo,Vo = Uo[:,:-1,:-1],Vo[:,:-1,:-1]\n",
    "\n",
    "uvelgate = aste_tracer2compact(Uo,nfx,nfy)\n",
    "vvelgate = aste_tracer2compact(Vo,nfx,nfy)\n",
    "uvelgate = uvelgate[:,y_curr,x_curr]\n",
    "vvelgate = vvelgate[:,y_curr,x_curr]\n",
    "perpendicular_vel = np.full(uvelgate.shape,np.nan) #    zeros_like(uvelgate)\n",
    "for i in range(len(choose_UV)):\n",
    "    if choose_UV[i][0] == \"V\":\n",
    "        perpendicular_vel[i] = uvelgate[i]       # flipping the sign of this helps reproduce An plot but this seems wrong??\n",
    "    elif choose_UV[i][0] == \"H\":\n",
    "        #perpendicular_vel[i] = -vvelgate[i]\n",
    "        perpendicular_vel[i] = vvelgate[i]\n",
    "XV,YV= np.meshgrid(indices[::-1],mygrid['RC'])\n",
    "data = perpendicular_vel*cell_area*1e-6\n",
    "\n",
    "ax = plt.subplot(111)\n",
    "tmpt = np.zeros(binsTH_centers.shape)\n",
    "for i in range (vol_gate.shape[0]):\n",
    "    for j in range(nz):\n",
    "        tmpbintheta = binned_theta_gate[i,j]\n",
    "        if not np.isnan(tmpbintheta):\n",
    "            tmpt[int(tmpbintheta)] += data[j,i]\n",
    "\n",
    "ax.plot(binsTH_centers,tmpt)\n",
    "ax.set_xlim(-3,10)\n",
    "ax.grid()\n",
    "ax.set_ylabel(\"Sv\")\n",
    "ax.set_xlabel(\"deg C\")\n",
    "ax.set_title(\"Transport across gate\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bddf011f-5c3e-4a86-bf48-c83b9208cf32",
   "metadata": {},
   "source": [
    "# Create Jy and Jx\n",
    "\n",
    "Jy is normalized by the width of the salt cells so is m/s/PSU. Jx is normalized by with of temp cells so m/s/degC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a54654-4f0d-4493-b31e-850994fd7c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# divide Gs and Gt by the thicknesses in salt (Jy) and temp (Jx)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
