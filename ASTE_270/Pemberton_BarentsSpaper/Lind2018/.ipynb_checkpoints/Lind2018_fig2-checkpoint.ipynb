{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7654ffc6-ad2b-41f7-98e8-80eee84820dd",
   "metadata": {},
   "source": [
    "# intro\n",
    "\n",
    "The purpose of this notebook is to load the masks that we made and replicate figure 2 of the Lind 2018 paper. This will require the temperature and salinity fields of all timesteps, and the masks. For each timestep, we will make a mask of shape time, nz, ny, nx that will identify the 3 layers, then for each of these labels (1: surface layer, 2: Arctic layer, 3: Atlantic layer), we take the average temperature and salinity value of this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad710a87-253d-40c5-8043-91206e3fa63a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import xarray as xr\n",
    "import matplotlib as mpl\n",
    "import time\n",
    "import gsw\n",
    "from matplotlib.colors import TwoSlopeNorm\n",
    "\n",
    "# import existing python files\n",
    "plt.rcParams['figure.figsize'] = (10,4)\n",
    "\n",
    "# add rdmds reading functions to path\n",
    "sys.path.append(\"/home/mmurakami/MITgcm/MITgcm_c68r/MITgcm-checkpoint68r/utils/python/MITgcmutils/MITgcmutils/\") # go to parent dir\n",
    "from mds import *\n",
    "\n",
    "# add the other files\n",
    "sys.path.append(\"/home/mmurakami/crios_backups/an_helper_functions\")\n",
    "from read_binary import *\n",
    "from mk3D_mod import mk3D_mod\n",
    "from aste_helper_funcs import *\n",
    "from timing_functions import *           # ts2dte, get_fnames, etc.\n",
    "\n",
    "# ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1999b4e-c8eb-4805-88a9-a6b8e4a11079",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.dates as mdates\n",
    "import matplotlib.colors as mcolors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a39710ec-32c8-4c3c-a4b2-e6a801646380",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50,) (50, 1350, 270)\n",
      "hf1 (1350, 270)\n",
      "(1, 1350, 270)\n",
      "LwetC2d 146614\n",
      "LwetC 4833023\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%run /home/mmurakami/crios_backups/an_helper_functions/prep_grid.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "474e1c9b-b840-44c3-bf0a-7b8de807774b",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/home/mmurakami/crios_backups/ASTE_270/Pemberton_BarentsSpaper/Lind2018/LindFigures/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6700ddb-6adc-4512-853a-59cf292e3dde",
   "metadata": {},
   "source": [
    "# setup file loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39f802c0-99d2-4060-800c-4354173734d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the files we need to do this\n",
    "# load the timesteps\n",
    "dt_aste = 600\n",
    "startyr = 2002\n",
    "endyr = 2019\n",
    "\n",
    "# all the filenames in the system\n",
    "fnames = get_fnames(dt_aste,startyr,endyr)\n",
    "\n",
    "# ocean and ice\n",
    "AB_gT=0\n",
    "AB_gS=0\n",
    "\n",
    "allyears = np.arange(2003,2018,1)\n",
    "dterm = 10                 # set a terminal depth for freshwater and heat calculations 19:276m   and    10:100m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef069b09-2f0b-4220-b3c2-3332f067233a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "364500\n"
     ]
    }
   ],
   "source": [
    "# load the existing mask of the Barents Sea -- this is what we will work from \n",
    "whole = True\n",
    "if not whole:\n",
    "    iB = 6    # example read from BarentsSea\n",
    "    \n",
    "# mymsk below defines as all Arctic down to Fram Strait and BSO but not GINs Seas\n",
    "mymsk = mskBasin.copy()\n",
    "mask = ~np.isnan(mymsk)\n",
    "mask = mymsk == 6\n",
    "\n",
    "# Set elements that are greater than 6 to np.nan\n",
    "mymsk[mask] = 1\n",
    "mymsk[~mask] = np.nan\n",
    "\n",
    "test = get_aste_tracer(mymsk,nfx,nfy)[0]\n",
    "mymsk = test\n",
    "\n",
    "mymsk = aste_tracer2compact(mymsk,nfx,nfy)[0]\n",
    "\n",
    "# Get the number of points where mskBasin is 6 or less\n",
    "npoints = np.count_nonzero(mymsk)  # Count the number of True values in the mask\n",
    "print(npoints)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f54947-2b96-4d62-a3f4-ca3cac35bb90",
   "metadata": {},
   "source": [
    "# create the timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f13fb2c5-8df7-4d50-9ac8-f4fd8362959e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mymsk = np.load('mask_Lind.npz')\n",
    "mymsk = mymsk['msk1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c044bf86-b865-4160-b6b2-c869fee511b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the layers by temperature\n",
    "    # surface layer: <100 m depth, T maximum\n",
    "    # arctic layer: T minimum\n",
    "    # atlantic layer: T maximum\n",
    "\n",
    "# find the index of each of these at each column depth and then the midpoint will be halfway between them, then we can create the mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "79cd27f7-0ac7-4e80-9291-573d8da6843e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12, 50, 1350, 270)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msktest = np.tile(mymsk[np.newaxis,:,:],(50,1,1))\n",
    "msktest[msktest == 0] = np.nan\n",
    "msk3_a = np.tile(msktest[np.newaxis,:,:,:],(12,1,1,1))\n",
    "msk3_a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e4a534a4-e0ba-4851-8aa3-6a9832fa2ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_ocean_layers(T):\n",
    "    \"\"\"\n",
    "    Identify Surface, Arctic, and Atlantic layers based on temperature extrema\n",
    "    for a dataset with a time dimension.\n",
    "    \n",
    "    Parameters:\n",
    "    T (numpy array): Temperature array of shape (months, nz, ny, nx).\n",
    "\n",
    "    Returns:\n",
    "    dict: Containing depth indices of each layer for each month.\n",
    "    \"\"\"\n",
    "    months, nz, ny, nx = T.shape\n",
    "\n",
    "    # Identify Arctic Layer (T min per month, per (y, x) profile)\n",
    "    z_arctic_idx = np.argmin(T, axis=1)  # Shape: (months, ny, nx)\n",
    "\n",
    "    # Identify Atlantic Layer (T max **only below Arctic Layer**)\n",
    "    atlantic_mask = np.arange(nz)[None, :, None, None] > z_arctic_idx[:, None, :, :]  # Mask below Arctic\n",
    "    T_atlantic_layer = np.where(atlantic_mask, T, -np.inf)  # Ignore above-Arctic temperatures\n",
    "    z_atlantic_idx = np.argmax(T_atlantic_layer, axis=1)  # Find max T below Arctic\n",
    "\n",
    "    # Identify Surface Layer (Max T **above Arctic Layer**, if it exists)\n",
    "    surface_mask = np.arange(nz)[None, :, None, None] < z_arctic_idx[:, None, :, :]  # Mask above Arctic\n",
    "    T_surface_layer = np.where(surface_mask, T, -np.inf)  # Ignore values below Arctic Layer\n",
    "    z_surface_idx = np.argmax(T_surface_layer, axis=1)  # Find max T above Arctic\n",
    "\n",
    "    # Handle cases where no valid surface layer exists (e.g., Arctic Layer is at surface)\n",
    "    z_surface_idx[z_surface_idx >= z_arctic_idx] = 0\n",
    "\n",
    "    print(z_arctic_idx.shape,z_atlantic_idx.shape,z_surface_idx.shape)\n",
    "\n",
    "    # do the midpoints to create the mask\n",
    "    z_surface_arctic_mid = (z_surface_idx + z_arctic_idx) // 2\n",
    "    z_arctic_atlantic_mid = (z_arctic_idx + z_atlantic_idx) // 2\n",
    "    \n",
    "    # Create a mask initialized with zeros\n",
    "    mask = np.zeros((months, nz, ny, nx), dtype=int)\n",
    "\n",
    "    # Expand dimensions to match (months, nz, ny, nx)\n",
    "    depth_levels = np.arange(nz)[None, :, None, None]  # Shape: (1, nz, 1, 1)\n",
    "    z_surface_arctic_mid = z_surface_arctic_mid[:, None, :, :]  # Shape: (months, 1, ny, nx)\n",
    "    z_arctic_atlantic_mid = z_arctic_atlantic_mid[:, None, :, :]  # Shape: (months, 1, ny, nx)\n",
    "\n",
    "    # Assign layer values to mask\n",
    "    mask[depth_levels <= z_surface_arctic_mid] = 1  # Surface Layer\n",
    "    mask[(depth_levels > z_surface_arctic_mid) & (depth_levels <= z_arctic_atlantic_mid)] = 2  # Arctic Layer\n",
    "    mask[depth_levels > z_arctic_atlantic_mid] = 3  # Atlantic Layer\n",
    "\n",
    "    return mask\n",
    "\n",
    "# Example usage:\n",
    "# layers = identify_ocean_layers(THETADR, depths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "41d07170-35d4-49ce-a984-15be496d1d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# T_test = identify_ocean_layers(T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "613dd2b9-5728-4f32-a993-5a2a4e503f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# T_mask = T_test * msk3_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5775bb36-b75d-49e5-9ee2-a05ed625e607",
   "metadata": {},
   "outputs": [],
   "source": [
    "# THETAhere = THETADR * msk3_a * hfC[np.newaxis,:,:,:]\n",
    "# T_maskhere = T_mask * msk3_a * hfC[np.newaxis,:,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "08b355ef-36fd-4709-8c4c-6cf6aa2407fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.pcolormesh(get_aste_tracer(T_maskhere[0],nfx,nfy)[12])\n",
    "# plt.colorbar()\n",
    "# plt.xlim(425,525)\n",
    "# plt.ylim(450,550)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b1a9adcc-0b01-4cef-8b76-1cb3d4595487",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Compute mean temperature for each layer as a test\n",
    "# for i in range(12):\n",
    "    \n",
    "#     mean_surface = np.nanmean((THETAhere[i]/DRF3d/hfC)[T_maskhere[i] == 1])  # Surface Layer (1)\n",
    "#     mean_arctic = np.nanmean((THETAhere[i]/DRF3d/hfC)[T_maskhere[i] == 2])   # Arctic Layer (2)\n",
    "#     mean_atlantic = np.nanmean((THETAhere[i]/DRF3d/hfC)[T_maskhere[i] == 3]) # Atlantic Layer (3)\n",
    "    \n",
    "#     print(f\"Mean Surface Temperature: {mean_surface:.2f}\")\n",
    "#     print(f\"Mean Arctic Temperature: {mean_arctic:.2f}\")\n",
    "#     print(f\"Mean Atlantic Temperature: {mean_atlantic:.2f}\")\n",
    "#     print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c32f0cb-9d9c-438a-ac8e-796025585aed",
   "metadata": {},
   "source": [
    "# Great, now we can compute and plot for both salinity and temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4bf1c76-13bf-4906-aef8-07ac30ddcf6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2003\n",
      "(12, 1350, 270) (12, 1350, 270) (12, 1350, 270)\n",
      "created the indices of the center layers\n",
      "2004\n"
     ]
    }
   ],
   "source": [
    "# do this by looping through the salt and heat -- we want to make an average of these as dept\n",
    "# do indexing in years for the layers\n",
    "iy = 0\n",
    "tavg_surf = np.array([])\n",
    "tavg_arct = np.array([])\n",
    "tavg_atl = np.array([])\n",
    "\n",
    "savg_surf = np.array([])\n",
    "savg_arct = np.array([])\n",
    "savg_atl = np.array([])\n",
    "\n",
    "for year in allyears:\n",
    "    print(year)\n",
    "\n",
    "    # get the datetime values\n",
    "    # years = list(np.arange(2003,2018,1))  # 15 year period\n",
    "    years = list(np.arange(year,year+1,1))\n",
    "    years = [str(i) for i in years]\n",
    "    years = np.array(years)\n",
    "    # write the datetimes for the later period\n",
    "    times = {}\n",
    "    \n",
    "    for year in years:\n",
    "        times[year] = np.arange(1,13,1)   # write all the months for this example 5-year period\n",
    "    \n",
    "    tsstr,datetimes = get_tsteps(times,fnames,dt_aste,startyr,1,1)\n",
    "\n",
    "    ##########################################################################################\n",
    "    # READ the theta/salt values\n",
    "    # we also want salt to do the FW content\n",
    "    # we want temperature and salt\n",
    "    THETADR = np.full((len(tsstr),nz,ny,nx),np.nan)\n",
    "    SALTDR = np.full((len(tsstr),nz,ny,nx),np.nan)\n",
    "    \n",
    "    for i in range(len(tsstr)):\n",
    "    \n",
    "        # read the fldList\n",
    "        file_name = 'budg3d_snap_set2'\n",
    "        meta_budg3d_snap_set2 = parsemeta(dirIn + file_name + \".\" + tsstr[i] + \".meta\")\n",
    "        fldlist = np.array(meta_budg3d_snap_set2[\"fldList\"])\n",
    "        varnames = np.array([\"THETADR\",\"SALTDR\"])\n",
    "        recs = np.array([])\n",
    "        for var in varnames:\n",
    "            irec = np.where(fldlist == var)\n",
    "            recs = np.append(recs, irec[0][0])\n",
    "            \n",
    "        read = [int(tsstr[i])]\n",
    "        \n",
    "        # make sure order we write the variables is the same as the order in varnames, else we read the wrong thing\n",
    "        THETADRi,its,meta = rdmds(os.path.join(dirIn, file_name),read,returnmeta=True,rec=recs[0])  # degC.m\n",
    "        SALTDRi,its,meta = rdmds(os.path.join(dirIn, file_name),read,returnmeta=True,rec=recs[1])  # degC.m\n",
    "    \n",
    "        THETADR[i,:,:,:] = np.reshape(THETADRi,(nz,ny,nx))\n",
    "        SALTDR[i,:,:,:] = np.reshape(SALTDRi,(nz,ny,nx))\n",
    "\n",
    "    ##########################################################################################\n",
    "    # identify the layers\n",
    "    # get the indices of the center value from identify_ocean_layers\n",
    "    T_idx = identify_ocean_layers(THETADR)\n",
    "    print(\"created the indices of the center layers\")\n",
    "\n",
    "    # mask based on the mask we want\n",
    "    msktest = np.tile(msk3[np.newaxis,:,:],(50,1,1))\n",
    "    msktest[msktest == 0] = np.nan\n",
    "    msk3_a = np.tile(msktest[np.newaxis,:,:,:],(12,1,1,1))\n",
    "\n",
    "    THETAhere = THETADR * msk3_a * hfC[np.newaxis,:,:,:]\n",
    "    SALThere = SALTDR * msk3_a * hfC[np.newaxis,:,:,:]\n",
    "    T_maskhere = T_idx * msk3_a * hfC[np.newaxis,:,:,:]\n",
    "\n",
    "    # for each time in tsstr:\n",
    "\n",
    "    for i in range(len(tsstr)):\n",
    "        # get the value\n",
    "        mean_surfaceT = np.nanmean((THETAhere[i]/DRF3d/hfC)[T_maskhere[i] == 1])  # Surface Layer (1)\n",
    "        mean_arcticT = np.nanmean((THETAhere[i]/DRF3d/hfC)[T_maskhere[i] == 2])   # Arctic Layer (2)\n",
    "        mean_atlanticT = np.nanmean((THETAhere[i]/DRF3d/hfC)[T_maskhere[i] == 3]) # Atlantic Layer (3)\n",
    "        mean_surfaceS = np.nanmean((SALThere[i]/DRF3d/hfC)[T_maskhere[i] == 1])  # Surface Layer (1)\n",
    "        mean_arcticS = np.nanmean((SALThere[i]/DRF3d/hfC)[T_maskhere[i] == 2])   # Arctic Layer (2)\n",
    "        mean_atlanticS = np.nanmean((SALThere[i]/DRF3d/hfC)[T_maskhere[i] == 3]) # Atlantic Layer (3)\n",
    "\n",
    "        #print(mean_surfaceT,mean_arcticT,mean_atlanticT,mean_surfaceS,mean_arcticS,mean_atlanticS)\n",
    "    \n",
    "        # append to list\n",
    "        tavg_surf = np.append(tavg_surf,mean_surfaceT)\n",
    "        tavg_arct = np.append(tavg_arct,mean_arcticT)\n",
    "        tavg_atl = np.append(tavg_atl,mean_atlanticT)\n",
    "        \n",
    "        savg_surf = np.append(savg_surf,mean_surfaceS)\n",
    "        savg_arct = np.append(savg_arct,mean_arcticS)\n",
    "        savg_atl = np.append(savg_atl,mean_atlanticS)\n",
    "\n",
    "    iy += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1767d527-d69e-4a1d-bd77-410f1890b4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_steps = np.arange(0, 180, 1)  # X-axis from 0 to 180\n",
    "\n",
    "# Create figure and subplots\n",
    "fig, axes = plt.subplots(nrows=2, ncols=1, figsize=(10, 8), sharex=True)\n",
    "\n",
    "# First subplot: Temperature trends\n",
    "axes[0].plot(time_steps, tavg_surf, label=\"Surface Layer\", color=\"red\", alpha=0.7)\n",
    "axes[0].plot(time_steps, tavg_arct, label=\"Arctic Layer\", color=\"blue\", alpha=0.7)\n",
    "axes[0].plot(time_steps, tavg_atl, label=\"Atlantic Layer\", color=\"green\", alpha=0.7)\n",
    "axes[0].set_ylabel(\"Temperature (Â°C)\")\n",
    "axes[0].set_title(\"Lind section Layer-Averaged Temperature Over Time\")\n",
    "axes[0].legend()\n",
    "axes[0].grid(alpha=0.3)\n",
    "\n",
    "# Second subplot: Salinity trends\n",
    "axes[1].plot(time_steps, savg_surf, label=\"Surface Layer\", color=\"red\", alpha=0.7)\n",
    "axes[1].plot(time_steps, savg_arct, label=\"Arctic Layer\", color=\"blue\", alpha=0.7)\n",
    "axes[1].plot(time_steps, savg_atl, label=\"Atlantic Layer\", color=\"green\", alpha=0.7)\n",
    "axes[1].set_ylabel(\"Salinity (PSU)\")\n",
    "axes[1].set_xlabel(\"Time Steps\")\n",
    "axes[1].set_title(\"Lind section Layer-Averaged Salinity Over Time\")\n",
    "axes[1].legend()\n",
    "axes[1].grid(alpha=0.3)\n",
    "\n",
    "# Adjust spacing between subplots\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(\"Lind_3layers_timeseries.png\",dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23465fad-581f-4ba9-95af-ccbbff4528d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
