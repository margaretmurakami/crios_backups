{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d581425-6ef0-46ad-90d1-e08688f867eb",
   "metadata": {},
   "source": [
    "## Redefine this notebook using face-defined terms\n",
    "\n",
    "Take a pause on this, I want to meet with An/Patrick/Helen before I continue on here.\n",
    "\n",
    "Let's at least try to reproduce the same result with the big ASTE as we did in the miniaste with snaps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21c58a21-ceca-4f51-a387-950a72240780",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "(450, 90)\n",
      "RAC2d (40500,)\n",
      "(100,)\n"
     ]
    }
   ],
   "source": [
    "# auto-reload edited modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys, os\n",
    "sys.path.insert(0, \"/home/mmurakami/crios_backups/an_helper_functions\")\n",
    "\n",
    "# run the script into the curre nt kernel (vars/functions become available)\n",
    "%run -i \"/home/mmurakami/crios_backups/an_helper_functions/prep_grid_aste_90.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8625c404-114b-4416-9b56-e8257ff194a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need to load the miniaste\n",
    "\n",
    "dirroot = \"/scratch3/atnguyen/aste_90x150x60/\"\n",
    "dirgrid = dirroot + \"GRID_real8/\"\n",
    "dirgridnb = dirroot + \"GRID_noblank/\"\n",
    "runstr= \"run_c68v_heffmosm3x_layers_lessmem1_viscAHp5em2_it0000_pk0000000001/\"\n",
    "layers_path = dirroot + runstr\n",
    "extL = \"LAYERS\"\n",
    "dirmask = dirroot + \"run_template/input_maskTransport/\"\n",
    "dirbudg = layers_path + \"diags/BUDG/\"\n",
    "dirdiags = dirbudg\n",
    "dirstate = layers_path + \"diags/STATE/\"\n",
    "dirlayers = layers_path + \"diags/LAYERS/\"\n",
    "dirtrsp = layers_path + \"diags/TRSP/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9227da2c-207b-4412-b3c7-f19cca82bd77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick a random point\n",
    "ix = 5\n",
    "iy = 170\n",
    "iz = 1  # surface point\n",
    "iz = 0 # here we will rerun at 10 for sample_2_3\n",
    "# plt.scatter(ix,iy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d96b2dc-da1e-497d-93bc-6593d52a672e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will define the face THETA to the sides of this column and the face THETA within it\n",
    "# load the ADV terms for the Barents Sea for this singular box -- single box will all be contributing the same\n",
    "# to the same T or S bin, so these will be the same when plotted in T or S space\n",
    "# but we can show this anyways\n",
    "tsstr = np.array([\"0000000002\",\"0000000003\"])\n",
    "t2 = int(tsstr[1]) # for the offline version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ffee4bdf-a8aa-4fa4-a2f9-c1f2884d0bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "t2 = int(tsstr[1])\n",
    "# 'diags/state_3d_set1'\n",
    "# read theta and salt averages from the t2 timestep (average)\n",
    "file_name = \"state_3d_set1\"\n",
    "meta_state_3d_set1 = parsemeta(dirstate + file_name + \".\" + tsstr[0] + \".meta\")\n",
    "fldlist = np.array(meta_state_3d_set1[\"fldList\"])\n",
    "varnames = np.array([\"THETA\",\"SALT\"])\n",
    "recs = np.array([])\n",
    "for var in varnames:\n",
    "    irec = np.where(fldlist == var)\n",
    "    recs = np.append(recs, irec[0][0])\n",
    "THETA,its,meta = rdmds(os.path.join(dirstate, file_name),t2,returnmeta=True,rec=recs[0])\n",
    "SALT,its,meta = rdmds(os.path.join(dirstate, file_name),t2,returnmeta=True,rec=recs[1])\n",
    "\n",
    "THETA = THETA.reshape(nz,ny,nx)\n",
    "SALT = SALT.reshape(nz,ny,nx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a0becd5a-b56f-4005-8fa1-7b99cc4b94fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "tC = THETA[:,iy,ix]\n",
    "tE = (THETA[:,iy,ix+1]+ tC)/2\n",
    "tW = (THETA[:,iy,ix-1] + tC)/2\n",
    "tN = (THETA[:,iy+1,ix] + tC)/2\n",
    "tS = (THETA[:,iy-1,ix] + tC)/2\n",
    "\n",
    "# redefine these use top center theta for top cell\n",
    "tT = np.zeros((nz))\n",
    "tT[0] = tC[0]\n",
    "tT[1:] = (THETA[1:,iy,ix] + THETA[:-1,iy,ix])/2  # these will also function as the bottom temperatures for these cells\n",
    "\n",
    "# print(tC)\n",
    "# print(tE,tW,tN,tS)\n",
    "# print(tT) # great these are also separated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "76286ce9-846b-47d0-8d43-3469986332c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the TS bins\n",
    "# also load the bins again so we have them locally\n",
    "boundsT = np.round(np.squeeze(rdmds(layers_path + \"layers2TH\")).ravel(),1)\n",
    "nT = boundsT.size - 1\n",
    "boundsS = np.round(np.squeeze(rdmds(layers_path + \"layers1SLT\")).ravel(),1)\n",
    "nS = boundsS.size - 1\n",
    "binwidthT = boundsT[1:] - boundsT[:-1]\n",
    "binwidthS = boundsS[1:] - boundsS[:-1]\n",
    "binwidthT1 = 0.5 * (binwidthT[1:] + binwidthT[:-1])  # normalize by these\n",
    "binwidthS1 = 0.5 * (binwidthS[1:] + binwidthS[:-1])\n",
    "binmidT = (boundsT[1:] + boundsT[:-1]) /2    # bin to these\n",
    "binmidS = (boundsS[1:] + boundsS[:-1]) /2\n",
    "nT = nT\n",
    "nS = nS\n",
    "nTm1 = nT-1\n",
    "nSm1 = nS-1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58820aaa-5d72-4135-b5cf-261f4f2394aa",
   "metadata": {},
   "source": [
    "## Load the terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a16dc4b-31e1-4f85-8f62-d96845c2b401",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"budg3d_hflux_set2\"\n",
    "meta_budg3d_hflux_set2 = parsemeta(dirdiags + file_name + \".\" + tsstr[0] + \".meta\")\n",
    "fldlist = np.array(meta_budg3d_hflux_set2[\"fldList\"])\n",
    "varnames = np.array([\"ADVx_TH\",\"ADVy_TH\",\"UVELMASS\",\"VVELMASS\"])\n",
    "recs = np.array([])\n",
    "for var in varnames:\n",
    "    irec = np.where(fldlist == var)\n",
    "    recs = np.append(recs, irec[0][0])\n",
    "ADVx_TH,its,meta = rdmds(os.path.join(dirdiags, file_name),t2,returnmeta=True,rec=recs[0])\n",
    "ADVy_TH,its,meta = rdmds(os.path.join(dirdiags, file_name),t2,returnmeta=True,rec=recs[1])\n",
    "ADVx_TH = ADVx_TH.reshape((nz,ny,nx))\n",
    "ADVy_TH = ADVy_TH.reshape((nz,ny,nx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0f39efc6-973b-48b2-ae91-b5ee2197e24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need DFh, DFr, ADVr\n",
    "\n",
    "## do the advective convergence\n",
    "file_name = \"budg3d_hflux_set2\"\n",
    "meta_budg3d_hflux_set2 = parsemeta(dirdiags + file_name + \".\" + tsstr[0] + \".meta\")\n",
    "fldlist = np.array(meta_budg3d_hflux_set2[\"fldList\"])\n",
    "varnames = np.array([\"DFxE_TH\",\"DFyE_TH\"])\n",
    "recs = np.array([])\n",
    "for var in varnames:\n",
    "    irec = np.where(fldlist == var)\n",
    "    recs = np.append(recs, irec[0][0])\n",
    "DFxE_TH,its,meta = rdmds(os.path.join(dirdiags, file_name),t2,returnmeta=True,rec=recs[0])\n",
    "DFyE_TH,its,meta = rdmds(os.path.join(dirdiags, file_name),t2,returnmeta=True,rec=recs[1])\n",
    "\n",
    "\n",
    "# now 3d zfluxes\n",
    "file_name = \"budg3d_zflux_set1\"\n",
    "meta_budg3d_zflux_set1 = parsemeta(dirdiags + file_name + \".\" + tsstr[0] + \".meta\")\n",
    "fldlist = np.array(meta_budg3d_zflux_set1[\"fldList\"])\n",
    "varnames = np.array([\"DFrE_TH\",\"DFrI_TH\"])\n",
    "recs = np.array([])\n",
    "for var in varnames:\n",
    "    irec = np.where(fldlist == var)\n",
    "    recs = np.append(recs, irec[0][0])\n",
    "DFrE_TH,its,meta = rdmds(os.path.join(dirdiags, file_name),t2,returnmeta=True,rec=recs[0])\n",
    "DFrI_TH,its,meta = rdmds(os.path.join(dirdiags, file_name),t2,returnmeta=True,rec=recs[1])\n",
    "DFrE_TH = DFrE_TH.reshape(nz,ny,nx)\n",
    "DFrI_TH = DFrI_TH.reshape(nz,ny,nx)\n",
    "\n",
    "DF_hconv = calc_UV_conv_mod(nfx, nfy,get_aste_faces(DFxE_TH.reshape(nz, ny, nx), nfx, nfy),get_aste_faces(DFyE_TH.reshape(nz, ny, nx), nfx, nfy))\n",
    "DF_hconv = DF_hconv * hf   # degCÂ·m^3/s at cell centers (matches: ff.DFh = ff.DFh .* hf)\n",
    "DFhT = DF_hconv\n",
    "\n",
    "trWtopDF = -(DFrE_TH+DFrI_TH)\n",
    "\n",
    "DFrT = np.zeros((nz,ny,nx),dtype=float)\n",
    "DFrT[:-1,:,:] = (trWtopDF[:-1] - trWtopDF[1:])\n",
    "\n",
    "# reshape the DF terms\n",
    "trWtopDF = trWtopDF.reshape((nz,ny,nx))\n",
    "DFxE_TH = DFxE_TH.reshape((nz,ny,nx))\n",
    "DFyE_TH = DFyE_TH.reshape((nz,ny,nx))\n",
    "\n",
    "# now 3d zfluxes\n",
    "file_name = \"budg3d_zflux_set1\"\n",
    "meta_budg3d_zflux_set1 = parsemeta(dirdiags + file_name + \".\" + tsstr[0] + \".meta\")\n",
    "fldlist = np.array(meta_budg3d_zflux_set1[\"fldList\"])\n",
    "varnames = np.array([\"ADVr_TH\"])\n",
    "recs = np.array([])\n",
    "for var in varnames:\n",
    "    irec = np.where(fldlist == var)\n",
    "    recs = np.append(recs, irec[0][0])\n",
    "ADVr_TH,its,meta = rdmds(os.path.join(dirdiags, file_name),t2,returnmeta=True,rec=recs[0])\n",
    "ADVr_TH = ADVr_TH.reshape(nz,ny,nx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "29afc1cf-60e5-4b60-8498-ff18b74b74a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to get the surface term, we need J/s and convert to degC.m^3/s\n",
    "file_name = 'budg2d_zflux_set1'\n",
    "meta_budg2d_zflux_set1 = parsemeta(dirdiags + file_name + \".\" + tsstr[0] + \".meta\")\n",
    "fldlist = np.array(meta_budg2d_zflux_set1[\"fldList\"])\n",
    "varnames = np.array([\"TFLUX\",\"oceQsw\",\"SItflux\"])\n",
    "recs = np.array([])\n",
    "for var in varnames:\n",
    "    irec = np.where(fldlist == var)\n",
    "    recs = np.append(recs, irec[0][0])\n",
    "TFLUX,its,meta = rdmds(os.path.join(dirdiags, file_name),t2,returnmeta=True,rec=recs[0])\n",
    "oceQsw,its,meta = rdmds(os.path.join(dirdiags, file_name),t2,returnmeta=True,rec=recs[1])\n",
    "SItflux,its,meta = rdmds(os.path.join(dirdiags, file_name),t2,returnmeta=True,rec=recs[2])\n",
    "TFLUX = TFLUX.reshape(ny,nx)\n",
    "oceQsw = oceQsw.reshape(ny,nx)\n",
    "SItflux = SItflux.reshape(ny,nx)\n",
    "\n",
    "# we need to create zconv_top and swtop\n",
    "dd = mygrid['RF'][:-1]\n",
    "swfrac = 0.62*np.exp(dd/0.6)+(1-0.62)*np.exp(dd/20)\n",
    "swfrac[dd < -200] = 0\n",
    "swtop=mk3D_mod(swfrac,np.zeros((nz,ny,nx)))*mk3D_mod(RAC*oceQsw,np.zeros((nz,ny,nx)))   # J/s\n",
    "\n",
    "# zconvtop_heat is here\n",
    "zconv_top_heat = TFLUX * RAC     # W/m^2 * m^2 = J/s\n",
    "\n",
    "\n",
    "def surface_contrib_JT(zconv_top_heat, swtop, rcp, fill_last=0.0):\n",
    "    \"\"\"\n",
    "    zconv_top_heat: (ny, nx)\n",
    "    swtop:          (nz, ny, nx)\n",
    "    rcp:            scalar\n",
    "    fill_last:      value for bottom slice (k = nz-1), usually 0.0 or np.nan\n",
    "    returns:\n",
    "      JsurfT:       (nz, ny, nx)  # Sv / PSU\n",
    "    \"\"\"\n",
    "    nz, ny, nx = swtop.shape\n",
    "\n",
    "    eT = zconv_top_heat.reshape(1, ny, nx)  # (1,ny,nx) for broadcast\n",
    "\n",
    "    J = np.empty_like(swtop, dtype=float)\n",
    "\n",
    "    # k = 0: (eT - fT[1]) / rcp / dT / dS * 1e-6\n",
    "    J[0] = (eT[0] - swtop[1]) / rcp if np.ndim(binwidthT)==0 else \\\n",
    "           (eT[0] - swtop[1]) / rcp\n",
    "\n",
    "    # 1 .. nz-2: -(fT[k+1]-fT[k]) / rcp / dT / dS * 1e-6\n",
    "    J[1:nz-1] = -(swtop[2:nz] - swtop[1:nz-1]) / rcp\n",
    "\n",
    "    # bottom slice (k = nz-1): no k+1; choose your boundary convention\n",
    "    J[-1] = fill_last\n",
    "    return J\n",
    "\n",
    "Ft_surftest = surface_contrib_JT(zconv_top_heat,swtop,myparms['rcp'])    # this is in degC.m^3/s\n",
    "\n",
    "# read kpp tend and from 3d zflux\n",
    "file_name = \"budg3d_kpptend_set1\"\n",
    "meta_budg3d_kpptend_set1 = parsemeta(dirdiags + file_name + \".\" + tsstr[0] + \".meta\")\n",
    "fldlist = np.array(meta_budg3d_kpptend_set1[\"fldList\"])\n",
    "varnames = np.array([\"KPPg_TH\"])\n",
    "recs = np.array([])\n",
    "for var in varnames:\n",
    "    irec = np.where(fldlist == var)\n",
    "    recs = np.append(recs, irec[0][0])\n",
    "KPPg_TH,its,meta = rdmds(os.path.join(dirdiags, file_name),t2,returnmeta=True,rec=recs[0])\n",
    "KPPg_TH = KPPg_TH.reshape(nz,ny,nx)\n",
    "\n",
    "# do the vertical convergence for KPP\n",
    "trWtopKPP = -(KPPg_TH)         # degC.m^3/s\n",
    "\n",
    "tmpkpp = np.full((nz,ny,nx),np.nan)\n",
    "tmpkpp[:-1,:,:] = trWtopKPP[:-1] - trWtopKPP[1:]\n",
    "\n",
    "\n",
    "# load the tend from the get_Jterms and plot this\n",
    "file_name = 'budg3d_snap_set2'\n",
    "meta_budg3d_snap_set2 = parsemeta(dirdiags + file_name + \".\" + tsstr[0] + \".meta\")\n",
    "fldlist = np.array(meta_budg3d_snap_set2[\"fldList\"])\n",
    "varnames = np.array([\"THETADR\"])\n",
    "recs = np.array([])\n",
    "for var in varnames:\n",
    "    irec = np.where(fldlist == var)\n",
    "    recs = np.append(recs, irec[0][0])\n",
    "\n",
    "THETADR = np.full((len(tsstr),nz,ny,nx),np.nan)\n",
    "for i in range(len(tsstr)):\n",
    "    thisTHETADR,its,meta = rdmds(os.path.join(dirdiags, file_name),int(tsstr[i]),returnmeta=True,rec=recs[0])\n",
    "    thisTHETADR = thisTHETADR.reshape(nz,ny,nx)\n",
    "    THETADR[i] = thisTHETADR\n",
    "\n",
    "dt = 1800\n",
    "\n",
    "THETADR =  (THETADR[1, :, :,:] - THETADR[0, :,:, :]) / dt    # degC.m/\n",
    "AB_gT = 0\n",
    "tmptend=(THETADR-AB_gT)*mk3D_mod(RAC,THETADR)   # degC.m/s * m^2 = degC.m^3/s\n",
    "tmptend = tmptend                          # degC.m^3/s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a354d1f-699c-492e-8353-3664438adae2",
   "metadata": {},
   "source": [
    "## get the bins at the temperatures we defined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "11626410-cebf-4ecf-b639-6a14363f6707",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---- build theta_edges from bin midpoints if needed\n",
    "binmidT = np.asarray(binmidT)\n",
    "theta_edges = np.empty(binmidT.size + 1)\n",
    "theta_edges[1:-1] = 0.5 * (binmidT[1:] + binmidT[:-1])\n",
    "theta_edges[0]    = binmidT[0]  - 0.5 * (binmidT[1] - binmidT[0])\n",
    "theta_edges[-1]   = binmidT[-1] + 0.5 * (binmidT[-1] - binmidT[-2])\n",
    "nTm1 = len(theta_edges) - 1  # number of bins\n",
    "\n",
    "# ---- face temperatures (nz,)\n",
    "tC = THETA[:, iy, ix]  # cell center\n",
    "\n",
    "tE = 0.5 * (THETA[:, iy, ix+1] + tC)\n",
    "tW = 0.5 * (THETA[:, iy, ix-1] + tC)\n",
    "tN = 0.5 * (THETA[:, iy+1, ix] + tC)\n",
    "tS = 0.5 * (THETA[:, iy-1, ix] + tC)\n",
    "\n",
    "# vertical faces: top and bottom temperatures for each cell\n",
    "tTop = np.empty_like(tC)\n",
    "tBot = np.empty_like(tC)\n",
    "\n",
    "tTop[0]  = tC[0]                                  # no cell above\n",
    "tTop[1:] = 0.5 * (THETA[1:, iy, ix] + THETA[:-1, iy, ix])\n",
    "\n",
    "tBot[:-1] = 0.5 * (THETA[1:, iy, ix] + THETA[:-1, iy, ix])\n",
    "tBot[-1]  = tC[-1]                                 # no cell below\n",
    "\n",
    "# stack to (6, nz) in order [E, W, N, S, Top, Bottom]\n",
    "allT = np.stack([tC,tE, tW, tN, tS, tTop, tBot], axis=0)\n",
    "\n",
    "# ---- bin indices (6, nz) in 0..nTm1-1, or -1 if out of range\n",
    "iT_all = np.digitize(allT, theta_edges) - 1\n",
    "iT_all[(iT_all < 0) | (iT_all >= nTm1)] = -1\n",
    "\n",
    "iT_C, iT_E, iT_W, iT_N, iT_S, iT_T, iT_B = iT_all  # each is shape (nz,)\n",
    "\n",
    "def add_to_bin(G_T, idx, val):\n",
    "    if 0 <= idx < G_T.size:\n",
    "        G_T[idx] += val\n",
    "\n",
    "G_terms_all = np.zeros((9,nTm1))  # center, east, west, north, south\n",
    "for k in range(nz):\n",
    "    G_terms_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ef0084dd-397a-4e76-85af-ea69518b809e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # what do we have defined now?\n",
    "# # ADVx_TH, ADVy_TH, ADVr_TH, DFxE_TH, DFyE_TH, trWtopDF, # do the vertical convergence for KPP\n",
    "# # trWtopKPP = -(KPPg_TH)         # degC.m^3/s  # also defined at the faces\n",
    "\n",
    "# # top face:\n",
    "# # -ADVr_TH[iz,iy,ix]  # top is - in\n",
    "\n",
    "# # next face\n",
    "# # ADVr_TH[iz+1,iy,ix]  # bottom is + in \n",
    "\n",
    "# # surface top:\n",
    "# # zconv_top_heat[0]\n",
    "\n",
    "# # surface k = 1 face \n",
    "# # - swtop[1] at tTop[1]\n",
    "# # + swtop[1:nz-1]\n",
    "\n",
    "# # at k = 2 face\n",
    "# # \n",
    "\n",
    "\n",
    "# # surface can also be defined at the faces\n",
    "\n",
    "# def surface_contrib_JT(zconv_top_heat, swtop, rcp, fill_last=0.0):\n",
    "#     \"\"\"\n",
    "#     zconv_top_heat: (ny, nx)\n",
    "#     swtop:          (nz, ny, nx)\n",
    "#     rcp:            scalar\n",
    "#     fill_last:      value for bottom slice (k = nz-1), usually 0.0 or np.nan\n",
    "#     returns:\n",
    "#       JsurfT:       (nz, ny, nx)  # Sv / PSU\n",
    "#     \"\"\"\n",
    "#     nz, ny, nx = swtop.shape\n",
    "\n",
    "#     eT = zconv_top_heat.reshape(1, ny, nx)  # (1,ny,nx) for broadcast\n",
    "\n",
    "#     J = np.empty_like(swtop, dtype=float)\n",
    "\n",
    "#     # k = 0: (eT - fT[1]) / rcp / dT / dS * 1e-6\n",
    "#     J[0] = (eT[0] - swtop[1]) / rcp if np.ndim(binwidthT)==0 else \\\n",
    "#            (eT[0] - swtop[1]) / rcp\n",
    "\n",
    "#     # 1 .. nz-2: -(fT[k+1]-fT[k]) / rcp / dT / dS * 1e-6\n",
    "#     J[1:nz-1] = -(swtop[2:nz] - swtop[1:nz-1]) / rcp\n",
    "\n",
    "#     # bottom slice (k = nz-1): no k+1; choose your boundary convention\n",
    "#     J[-1] = fill_last\n",
    "#     return J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d590dc7c-09a7-4be4-ae0f-ba53bc087ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a version where we bin to center (ie same as before)\n",
    "# maybe we do this in a different side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "42b3fc49-8db8-4d92-86d2-9f7fbd581f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all the terms for iT_E -- define as x in\n",
    "G_terms_all = {}\n",
    "\n",
    "M_E = np.zeros((nTm1))\n",
    "G_DFh = np.zeros((nTm1))           # this will be reused for different array\n",
    "for i in range(nz):\n",
    "    M_E[iT_E[i]] += ADVx_TH[i,iy,ix]\n",
    "    G_DFh[iT_E[i]] += DFxE_TH[i,iy,ix]\n",
    "G_terms_all[\"M_East\"] = M_E  # done, add to array\n",
    "\n",
    "M_W = np.zeros((nTm1))\n",
    "for i in range(nz):\n",
    "    M_W[iT_W[i]] -= ADVx_TH[i,iy,ix+1]\n",
    "    G_DFh[iT_W[i]] -= DFxE_TH[i,iy,ix+1]\n",
    "G_terms_all[\"M_West\"] = M_W  # done, add to array\n",
    "\n",
    "\n",
    "M_N = np.zeros((nTm1))\n",
    "for i in range(nz):\n",
    "    M_N[iT_N[i]] -= ADVy_TH[i,iy+1,ix]\n",
    "    G_DFh[iT_N[i]] -= DFyE_TH[i,iy+1,ix]\n",
    "\n",
    "G_terms_all[\"M_North\"] = M_N\n",
    "\n",
    "M_S = np.zeros((nTm1))\n",
    "for i in range(nz):\n",
    "    M_S[iT_S[i]] += ADVy_TH[i,iy,ix]\n",
    "    G_DFh[iT_S[i]] += DFyE_TH[i,iy,ix]\n",
    "\n",
    "G_terms_all[\"M_South\"] = M_S\n",
    "G_terms_all[\"DFh\"] = G_DFh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ad0584ff-62f4-4d5c-94fc-fabf7b054e8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52517.78176319876\n"
     ]
    }
   ],
   "source": [
    "print(np.nansum(tmptend[:,iy,ix]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c56703ba-4661-4b34-b73b-c9e116f5ec19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# do the vertical terms\n",
    "\n",
    "G_KPPg = np.zeros((nTm1))\n",
    "G_DFr = np.zeros((nTm1))\n",
    "G_Advr = np.zeros((nTm1))\n",
    "\n",
    "# bin the terms at iT_T (top)\n",
    "for i in range(nz):\n",
    "    G_Advr[iT_T[i]] -= ADVr_TH[i,iy,ix]\n",
    "    G_KPPg[iT_T[i]] -= KPPg_TH[i,iy,ix]\n",
    "    G_DFr[iT_T[i]] += trWtopDF[i,iy,ix]\n",
    "\n",
    "# bin the bottom face\n",
    "for i in range(1,nz):\n",
    "    G_Advr[iT_T[i]] += ADVr_TH[i,iy,ix]\n",
    "    G_KPPg[iT_T[i]] += KPPg_TH[i,iy,ix]  # add at the bottom face\n",
    "    G_DFr[iT_T[i]] -= trWtopDF[i,iy,ix]\n",
    "\n",
    "G_terms_all[\"KPP\"] = G_KPPg\n",
    "G_terms_all[\"DFr\"] = G_DFr\n",
    "G_terms_all[\"ADVr\"] = G_Advr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3fb07a6f-6625-4834-835c-b3cb235ddc61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# one (j,i) column only, as a 1D column term\n",
    "G_surf = np.zeros((nTm1,), dtype=float)\n",
    "\n",
    "it = (iT_T)              # index in nTm1 to add to\n",
    "eT = float(zconv_top_heat[iy, ix])   # surface term for that column\n",
    "\n",
    "# add/subtract only at the target bin edge (no convergence)\n",
    "G_surf[it] += eT / myparms['rcp']\n",
    "G_surf[it + 1] -= eT / myparms['rcp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38530a34-5a51-4ffb-850b-7fed5b61ef6d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
