{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27694a4f-9cfe-4b0c-a1cb-4f5079cc86e9",
   "metadata": {},
   "source": [
    "## Goals:\n",
    "\n",
    "- load the G from layers for miniaste\n",
    "- create the G_advh from offline monthly avg.\n",
    "- load the gateways (make sure indices)\n",
    "- verify this way\n",
    "- now verify the M term"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "912489e7-fcf6-4012-a32f-de9cbadfe633",
   "metadata": {},
   "source": [
    "## setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "169a13ab-dd2d-4e9a-a35a-23906dbe35c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(450, 90)\n",
      "RAC2d (40500,)\n",
      "(100,)\n"
     ]
    }
   ],
   "source": [
    "# auto-reload edited modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys, os\n",
    "sys.path.insert(0, \"/home/mmurakami/crios_backups/an_helper_functions\")\n",
    "\n",
    "# run the script into the curre nt kernel (vars/functions become available)\n",
    "%run -i \"/home/mmurakami/crios_backups/an_helper_functions/prep_grid_aste_90.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "baac7f2d-ccf2-4ff4-ba90-3481d564a5ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "dirroot = \"/scratch3/atnguyen/aste_90x150x60/\"\n",
    "dirgrid = dirroot + \"GRID_real8/\"\n",
    "dirgridnb = dirroot + \"GRID_noblank/\"\n",
    "runstr= \"run_c68v_heffmosm3x_layers_lessmem1_viscAHp5em2_it0000_pk0000000001/\"\n",
    "layers_path = dirroot + runstr\n",
    "extL = \"LAYERS\"\n",
    "dirmask = dirroot + \"run_template/input_maskTransport/\"\n",
    "dirbudg = layers_path + \"diags/BUDG/\"\n",
    "dirdiags = dirbudg\n",
    "dirstate = layers_path + \"diags/STATE/\"\n",
    "dirlayers = layers_path + \"diags/LAYERS/\"\n",
    "dirtrsp = layers_path + \"diags/TRSP/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "19065de3-e6dc-4db4-9470-f7a99b51992f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# maybe we can dump a file to load the aste90 grid so I can have all the values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6744d4b2-1f86-451d-8360-43b94b017e58",
   "metadata": {},
   "source": [
    "## Make sure we have the bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b8fb0c9-bfff-4f03-acb0-7afca279db92",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"layers2TH\"\n",
    "boundsT = rdmds(layers_path + filename)\n",
    "binsTH_edges = boundsT.reshape(boundsT.shape[0])\n",
    "binsTH_centers = (binsTH_edges[:-1] + binsTH_edges[1:])/2\n",
    "nT = binsTH_edges.shape[0]-1\n",
    "\n",
    "filename = \"layers1SLT\"\n",
    "boundsS = rdmds(layers_path + filename)\n",
    "binsSLT_edges = boundsS.reshape(boundsS.shape[0])\n",
    "binsSLT_centers = (binsSLT_edges[:-1] + binsSLT_edges[1:])/2\n",
    "nS = binsSLT_edges.shape[0]-1\n",
    "\n",
    "binwidthT = binsTH_edges[1:] - binsTH_edges[:-1]\n",
    "binwidthS = binsSLT_edges[1:] - binsSLT_edges[:-1]\n",
    "\n",
    "binwidthT1 = (binwidthT[:-1] + binwidthT[1:])/2\n",
    "binwidthS1 = (binwidthS[:-1] + binwidthS[1:])/2\n",
    "\n",
    "binmidT = ((boundsT[:-1] + boundsT[1:])/2).reshape(nT)\n",
    "binmidS = ((boundsS[:-1] + boundsS[1:])/2).reshape(nT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f407976-abe0-469d-91ff-504d29cbf3a6",
   "metadata": {},
   "source": [
    "## Load the G_T and G_S terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ce652df-8ccb-48e0-b28a-03b4d4b9072c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need to also create the theta and salt bins for this area\n",
    "tsstr = np.array([\"0000000002\",\"0000000003\"])\n",
    "tsstr = np.array([\"0000000003\",\"0000000004\"])\n",
    "\n",
    "t2 = int(tsstr[1]) # for the offline version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "00af27d5-cb37-41ef-a8cb-525079dcff9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ffac=1e-6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f88f3b-1e98-4d5e-abe0-f3e9a43c45a8",
   "metadata": {},
   "source": [
    "## Create the ADVh terms from the salt and temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a3a27067-3153-4215-8bc6-af193861350e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'create_layers_totalSALT' from 'create_aste90_layers' (/home/mmurakami/crios_backups/ASTE_270/Pemberton_BarentsSpaper/2026_BarentsS/create_aste90_layers.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcreate_aste90_layers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m create_layers_totalTHETA,create_layers_totalSALT\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'create_layers_totalSALT' from 'create_aste90_layers' (/home/mmurakami/crios_backups/ASTE_270/Pemberton_BarentsSpaper/2026_BarentsS/create_aste90_layers.py)"
     ]
    }
   ],
   "source": [
    "from create_aste90_layers import create_layers_totalTHETA,create_layers_totalSALT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "74d6304b-2753-4129-8015-ad5d73593047",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mymsk' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m Msum, dF_Tnew \u001b[38;5;241m=\u001b[39m create_layers_totalTHETA(tsstr,mygrid,myparms,dirdiags,dirstate,layers_path,\u001b[43mmymsk\u001b[49m,nz,ny,nx,nfx,nfy)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'mymsk' is not defined"
     ]
    }
   ],
   "source": [
    "Msum, dF_Tnew = create_layers_totalTHETA(tsstr,mygrid,myparms,dirdiags,dirstate,layers_path,mymsk,nz,ny,nx,nfx,nfy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "335aab48-523d-4bbd-90f7-bedf368bb9d6",
   "metadata": {},
   "source": [
    "## verify these manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "0db74224-873f-4612-b117-5f8a2dc6fd52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _bincount_sum_with_nan(idx, vals, nout):\n",
    "    \"\"\"\n",
    "    NaN-aware per-bin sum:\n",
    "    if *all* entries in a bin are NaN, that bin returns NaN;\n",
    "    otherwise NaNs are ignored and finite values are summed.\n",
    "    \"\"\"\n",
    "    # track counts of non-nan contributions\n",
    "    finite = np.isfinite(vals)\n",
    "    sums   = np.bincount(idx[finite], vals[finite], minlength=nout).astype(float)\n",
    "    counts = np.bincount(idx[finite], None, minlength=nout).astype(float)\n",
    "    out = sums\n",
    "    out[counts == 0] = np.nan\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb10867-eef2-4914-bba5-a6f2b65421e3",
   "metadata": {},
   "source": [
    "## Create the M term from the gates\n",
    "\n",
    "We need to find the previous notebook where I marked the gates. Not sure what I called it.\n",
    "\n",
    "try_again_BarentsSwhole.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "1437b7b7-232d-4909-842a-4114150cf68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## I think the best way to do this is with the ADV_TH term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "21c59631-a00a-4b5d-b1d6-2aa534145160",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gates        265872.3371250672 m^3/s\n",
      "ADVh         265872.3371250672 m^3/s\n",
      "ADVr         -2.2253824948265377e-11 m^3/s\n",
      "DFh         106.12036325954855 m^3/s\n",
      "DFr         1.7803059958612301e-10 m^3/s\n",
      "surf         -646325.4887748167 m^3/s\n",
      "kpp         5.563456237066344e-12 m^3/s\n",
      "\n",
      "total volume tend RHS:  -380347.0312864898 m^3/s\n",
      "total volume tend LHS:  -380347.0312333998 m^3/s\n"
     ]
    }
   ],
   "source": [
    "labels = np.array([\"ADVh\",\"ADVr\",\"DFh\",\"DFr\",\"surf\",\"kpp\",\"tend\"])\n",
    "\n",
    "s = 0 \n",
    "print(\"gates       \",np.nansum(np.nansum(Msum,axis=0))/np.nansum(binwidthT1),\"m^3/s\")\n",
    "for i in range(6):\n",
    "    at = np.nansum(dF_Tnew[i]) / np.nansum(binwidthT1)\n",
    "    print(labels[i],\"       \",at,\"m^3/s\")\n",
    "    s += at\n",
    "print()\n",
    "print(\"total volume tend RHS: \",s,\"m^3/s\")\n",
    "print(\"total volume tend LHS: \",np.nansum(dF_Tnew[-1]/1.9131428585e3) / np.nansum(binwidthS1),\"m^3/s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c72912-1a71-482c-bded-21f64167f5ac",
   "metadata": {},
   "source": [
    "## Load the salt terms and the gates from SLT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "7e382142-1bee-4783-88d0-8e6c7e98e0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"budg3d_hflux_set2\"\n",
    "meta_budg3d_hflux_set2 = parsemeta(dirdiags + file_name + \".\" + tsstr[0] + \".meta\")\n",
    "fldlist = np.array(meta_budg3d_hflux_set2[\"fldList\"])\n",
    "varnames = np.array([\"ADVx_SLT\",\"ADVy_SLT\"])\n",
    "recs = np.array([])\n",
    "for var in varnames:\n",
    "    irec = np.where(fldlist == var)\n",
    "    recs = np.append(recs, irec[0][0])\n",
    "ADVx_SLT,its,meta = rdmds(os.path.join(dirdiags, file_name),t2,returnmeta=True,rec=recs[0])\n",
    "ADVy_SLT,its,meta = rdmds(os.path.join(dirdiags, file_name),t2,returnmeta=True,rec=recs[1])\n",
    "\n",
    "# now 3d zfluxes\n",
    "file_name = \"budg3d_zflux_set2\"\n",
    "meta_budg3d_zflux_set1 = parsemeta(dirdiags + file_name + \".\" + tsstr[0] + \".meta\")\n",
    "fldlist = np.array(meta_budg3d_zflux_set1[\"fldList\"])\n",
    "varnames = np.array([\"ADVr_SLT\"])\n",
    "recs = np.array([])\n",
    "for var in varnames:\n",
    "    irec = np.where(fldlist == var)\n",
    "    recs = np.append(recs, irec[0][0])\n",
    "ADVr_SLT,its,meta = rdmds(os.path.join(dirdiags, file_name),t2,returnmeta=True,rec=recs[0])\n",
    "ADVr_SLT = ADVr_SLT.reshape(nz,ny,nx)\n",
    "\n",
    "hf = mygrid['hFacC']\n",
    "\n",
    "ADV_hconv = calc_UV_conv_mod(nfx, nfy,get_aste_faces(ADVx_SLT.reshape(nz, ny, nx), nfx, nfy),get_aste_faces(ADVy_SLT.reshape(nz, ny, nx), nfx, nfy))\n",
    "ADV_hconv = ADV_hconv * hf   # degC·m^3/s at cell centers (matches: ff.DFh = ff.DFh .* hf)\n",
    "ADVhS = ADV_hconv\n",
    "\n",
    "trWtopADV = -(ADVr_TH)\n",
    "\n",
    "ADVrS = np.zeros((nz,ny,nx),dtype=float)\n",
    "ADVrS[:-1,:,:] = (trWtopADV[:-1] - trWtopADV[1:])  # this is not the way we did it in the original code but this is the way An has done it so we try"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "2cc58269-7ee5-4ffb-8c31-c5b2168c5cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- reshape to 3D ---\n",
    "ADVx_SLT = ADVx_SLT.reshape((nz, ny, nx))   # advective heat flux on x-faces\n",
    "ADVy_SLT = ADVy_SLT.reshape((nz, ny, nx))   # advective heat flux on y-faces\n",
    "SALT   = SALT.reshape((nz, ny, nx))     # cell-centered temperature\n",
    "\n",
    "eps = 1e-6  # to avoid divide-by-zero in very cold cells\n",
    "\n",
    "ADVx_vol = np.zeros_like(ADVx_SLT)\n",
    "mask_x   = np.isfinite(theta_x) & (np.abs(theta_x) > eps)\n",
    "ADVx_vol[mask_x] = ADVx_SLT[mask_x] #/ theta_x[mask_x]\n",
    "\n",
    "ADVy_vol = np.zeros_like(ADVy_TH)\n",
    "mask_y   = np.isfinite(theta_y) & (np.abs(theta_y) > eps)\n",
    "ADVy_vol[mask_y] = ADVy_SLT[mask_y] #/ theta_y[mask_y]\n",
    "\n",
    "# bolus\n",
    "ADVx_vol = np.zeros_like(ADVx_TH)\n",
    "mask_x   = np.isfinite(theta_x) & (np.abs(theta_x) > eps)\n",
    "ADVx_vol[mask_x] = (ADVx_SLT[mask_x]) #/ theta_x[mask_x]\n",
    "\n",
    "ADVy_vol = np.zeros_like(ADVy_TH)\n",
    "mask_y   = np.isfinite(theta_y) & (np.abs(theta_y) > eps)\n",
    "ADVy_vol[mask_y] = (ADVy_SLT[mask_y]) #/ theta_y[mask_y]\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 3. Build gateway transports using volume fluxes at the faces\n",
    "#    Sign convention: comments assume \"positive into basin\"\n",
    "# ------------------------------------------------------------------\n",
    "\n",
    "# ADVx_vol = ADVx_TH\n",
    "# ADVy_vol = ADVy_TH\n",
    "\n",
    "# ---- BSO ----\n",
    "ADV_west = np.zeros((nz, ny, nx))\n",
    "y_bso_all = np.array([], dtype=int)\n",
    "x_bso_all = np.array([], dtype=int)\n",
    "\n",
    "# horizontal faces (u-faces)\n",
    "for j, i in zip(y_bsoh, x_bsoh):\n",
    "    # flux through x-face at (j,i) mapped into cell (j,i)\n",
    "    ADV_west[:, j, i] += ADVx_vol[:, j, i]    # + into basin\n",
    "    y_bso_all = np.append(y_bso_all, j)\n",
    "    x_bso_all = np.append(x_bso_all, i)\n",
    "\n",
    "# vertical faces (v-faces)\n",
    "for j, i in zip(y_bsov, x_bsov):\n",
    "    # flux through y-face at (j,i) mapped into cell (j-1,i)\n",
    "    ADV_west[:, j-1, i] -= ADVy_vol[:, j, i]  # sign chosen so + into basin\n",
    "    y_bso_all = np.append(y_bso_all, j-1)\n",
    "    x_bso_all = np.append(x_bso_all, i)\n",
    "\n",
    "# ---- FJNZ ----\n",
    "ADV_FJNZ = np.zeros((nz, ny, nx))\n",
    "y_fjnz_all = np.array([], dtype=int)\n",
    "x_fjnz_all = np.array([], dtype=int)\n",
    "\n",
    "for j, i in zip(y_fjnzv, x_fjnzv):\n",
    "    # x-face at (j,i) mapped into (j, i-1), + into basin\n",
    "    ADV_FJNZ[:, j, i-1] -= ADVx_vol[:, j, i]\n",
    "    y_fjnz_all = np.append(y_fjnz_all, j)\n",
    "    x_fjnz_all = np.append(x_fjnz_all, i-1)\n",
    "\n",
    "# ---- SPFJ (NZ exit) ----\n",
    "ADV_SPFJ = np.zeros((nz, ny, nx))\n",
    "y_spfj_all = np.array([], dtype=int)\n",
    "x_spfj_all = np.array([], dtype=int)\n",
    "\n",
    "\n",
    "# # CHANGED\n",
    "for j,i in zip(y_spfjv2,x_spfjv2):\n",
    "    ADV_SPFJ[:, j-1, i] -= ADVy_vol[:, j, i]\n",
    "    y_spfj_all = np.append(y_spfj_all, j-1)\n",
    "    x_spfj_all = np.append(x_spfj_all, i)\n",
    "\n",
    "for j,i in zip(y_spfjh2,x_spfjh2):\n",
    "    ADV_SPFJ[:, j, i-1] -= ADVx_vol[:, j, i]\n",
    "    y_spfj_all = np.append(y_spfj_all, j)\n",
    "    x_spfj_all = np.append(x_spfj_all, i-1)\n",
    "    \n",
    "for j,i in zip(y_spfjb2,x_spfjb2):\n",
    "    ADV_SPFJ[:, j, i-1] -= ADVx_vol[:, j, i]\n",
    "    y_spfj_all = np.append(y_spfj_all, j)\n",
    "    x_spfj_all = np.append(x_spfj_all, i-1)\n",
    "    ADV_SPFJ[:, j-1, i] -= ADVy_vol[:, j, i]\n",
    "    y_spfj_all = np.append(y_spfj_all, j-1)\n",
    "    x_spfj_all = np.append(x_spfj_all, i)\n",
    "\n",
    "# ---- NZRU (small Russia gate) ----\n",
    "ADV_NZRU = np.zeros((nz, ny, nx))\n",
    "y_nzru_all = np.array([], dtype=int)\n",
    "x_nzru_all = np.array([], dtype=int)\n",
    "\n",
    "for j, i in zip(y_nzruv, x_nzruv):\n",
    "    ADV_NZRU[:, j, i-1] -= ADVx_vol[:, j, i]   # + into basin\n",
    "    y_nzru_all = np.append(y_nzru_all, j)\n",
    "    x_nzru_all = np.append(x_nzru_all, i-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "823a4cb6-5c27-450e-b95b-6e5f61173fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ADV_west_flat   = ADV_west.ravel()\n",
    "ADV_fjnz_flat   = ADV_FJNZ.ravel()\n",
    "ADV_spfj_flat   = ADV_SPFJ.ravel()\n",
    "ADV_nzru_flat   = ADV_NZRU.ravel()\n",
    "\n",
    "\n",
    "# per-bin sums with NaN-propagation\n",
    "ADVh_BSO = _bincount_sum_with_nan(idx_midS, ADV_west_flat[valid_midS], nTm1)\n",
    "ADVh_FJNZ = _bincount_sum_with_nan(idx_midS, ADV_fjnz_flat[valid_midS], nTm1)\n",
    "ADVh_SPFJ = _bincount_sum_with_nan(idx_midS, ADV_spfj_flat[valid_midS], nTm1)\n",
    "ADVh_NZRU = _bincount_sum_with_nan(idx_midS, ADV_nzru_flat[valid_midS], nTm1)\n",
    "\n",
    "\n",
    "# edge-based G (m^3/s): divide by edge binwidths\n",
    "# this is not correct because we want to divide by Face T\n",
    "G_BSO = ADVh_BSO / binwidthS1\n",
    "G_FJNZ = ADVh_FJNZ / binwidthS1\n",
    "G_SPFJ = ADVh_SPFJ / binwidthS1\n",
    "G_NZRU = ADVh_NZRU / binwidthS1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e4bf599b-4208-49eb-8c16-9e60477fc5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the other terms (all)\n",
    "\n",
    "# cool, do the same for diff\n",
    "\n",
    "\n",
    "## do the advective convergence\n",
    "file_name = \"budg3d_hflux_set2\"\n",
    "meta_budg3d_hflux_set2 = parsemeta(dirdiags + file_name + \".\" + tsstr[0] + \".meta\")\n",
    "fldlist = np.array(meta_budg3d_hflux_set2[\"fldList\"])\n",
    "varnames = np.array([\"DFxE_SLT\",\"DFyE_SLT\"])\n",
    "recs = np.array([])\n",
    "for var in varnames:\n",
    "    irec = np.where(fldlist == var)\n",
    "    recs = np.append(recs, irec[0][0])\n",
    "DFxE_SLT,its,meta = rdmds(os.path.join(dirdiags, file_name),t2,returnmeta=True,rec=recs[0])\n",
    "DFyE_SLT,its,meta = rdmds(os.path.join(dirdiags, file_name),t2,returnmeta=True,rec=recs[1])\n",
    "\n",
    "\n",
    "# now 3d zfluxes\n",
    "file_name = \"budg3d_zflux_set2\"\n",
    "meta_budg3d_zflux_set2 = parsemeta(dirdiags + file_name + \".\" + tsstr[0] + \".meta\")\n",
    "fldlist = np.array(meta_budg3d_zflux_set2[\"fldList\"])\n",
    "varnames = np.array([\"DFrE_SLT\",\"DFrI_SLT\"])\n",
    "recs = np.array([])\n",
    "for var in varnames:\n",
    "    irec = np.where(fldlist == var)\n",
    "    recs = np.append(recs, irec[0][0])\n",
    "DFrE_SLT,its,meta = rdmds(os.path.join(dirdiags, file_name),t2,returnmeta=True,rec=recs[0])\n",
    "DFrI_SLT,its,meta = rdmds(os.path.join(dirdiags, file_name),t2,returnmeta=True,rec=recs[1])\n",
    "DFrE_SLT = DFrE_SLT.reshape(nz,ny,nx)\n",
    "DFrI_SLT = DFrI_SLT.reshape(nz,ny,nx)\n",
    "\n",
    "DF_hconv = calc_UV_conv_mod(nfx, nfy,get_aste_faces(DFxE_SLT.reshape(nz, ny, nx), nfx, nfy),get_aste_faces(DFyE_SLT.reshape(nz, ny, nx), nfx, nfy))\n",
    "DF_hconv = DF_hconv * hf   # degC·m^3/s at cell centers (matches: ff.DFh = ff.DFh .* hf)\n",
    "DFhS = DF_hconv\n",
    "\n",
    "trWtopDF = -(DFrE_SLT+DFrI_SLT)\n",
    "\n",
    "DFrS = np.zeros((nz,ny,nx),dtype=float)\n",
    "DFrS[:-1,:,:] = (trWtopDF[:-1] - trWtopDF[1:])\n",
    "\n",
    "# load the surface terms\n",
    "# read fluxes\n",
    "file_name = 'budg2d_zflux_set1'\n",
    "meta_budg2d_zflux_set1 = parsemeta(dirdiags + file_name + \".\" + tsstr[0] + \".meta\")\n",
    "fldlist = np.array(meta_budg2d_zflux_set1[\"fldList\"])\n",
    "varnames = np.array([\"oceSPflx\",\"SFLUX\"])\n",
    "recs = np.array([])\n",
    "for var in varnames:\n",
    "    irec = np.where(fldlist == var)\n",
    "    recs = np.append(recs, irec[0][0])\n",
    "oceSPflx,its,meta = rdmds(os.path.join(dirdiags, file_name),t2,returnmeta=True,rec=recs[0])\n",
    "SFLUX,its,meta = rdmds(os.path.join(dirdiags, file_name),t2,returnmeta=True,rec=recs[1])\n",
    "oceSPflx = oceSPflx.reshape(ny,nx)\n",
    "SFLUX = SFLUX.reshape(ny,nx)\n",
    "\n",
    "# read relax and salt mass\n",
    "file_name = \"budg2d_zflux_set2\"\n",
    "meta_budg2d_zflux_set2 = parsemeta(dirdiags + file_name + \".\" + tsstr[0] + \".meta\")\n",
    "fldlist = np.array(meta_budg2d_zflux_set2[\"fldList\"])\n",
    "varnames = np.array([\"oceSflux\",\"WSLTMASS\"])\n",
    "recs = np.array([])\n",
    "for var in varnames:\n",
    "    irec = np.where(fldlist == var)\n",
    "    if len(irec[0]) > 0:\n",
    "        recs = np.append(recs, irec[0][0])\n",
    "oceSflux,its,meta = rdmds(os.path.join(dirdiags, file_name),t2,returnmeta=True,rec=recs[0])\n",
    "WSLTMASS,its,meta = rdmds(os.path.join(dirdiags, file_name),t2,returnmeta=True,rec=recs[1])\n",
    "oceSflux = oceSflux.reshape(ny,nx)\n",
    "WSLTMASS = WSLTMASS.reshape(ny,nx)\n",
    "\n",
    "# read kpp tend and from 3d zflux\n",
    "file_name = \"budg3d_kpptend_set1\"\n",
    "meta_budg3d_kpptend_set1 = parsemeta(dirdiags + file_name + \".\" + tsstr[0] + \".meta\")\n",
    "fldlist = np.array(meta_budg3d_kpptend_set1[\"fldList\"])\n",
    "varnames = np.array([\"oceSPtnd\",\"KPPg_SLT\"])\n",
    "recs = np.array([])\n",
    "for var in varnames:\n",
    "    irec = np.where(fldlist == var)\n",
    "    if len(irec[0]) > 0:\n",
    "        recs = np.append(recs, irec[0][0])\n",
    "oceSPtnd,its,meta = rdmds(os.path.join(dirdiags, file_name),t2,returnmeta=True,rec=recs[0])\n",
    "KPPg_SLT,its,meta = rdmds(os.path.join(dirdiags, file_name),t2,returnmeta=True,rec=recs[1])\n",
    "oceSPtnd = oceSPtnd.reshape(nz,ny,nx)\n",
    "KPPg_SLT = KPPg_SLT.reshape(nz,ny,nx)\n",
    "\n",
    "RAC3 = np.tile(RAC[np.newaxis,:,:],(nz,1,1))\n",
    "sptop = mk3D_mod(oceSPflx,oceSPtnd) - np.cumsum(oceSPtnd, axis=0)        # we include this in our zconv_top term\n",
    "sptop = sptop * RAC3        # g/s\n",
    "\n",
    "zconv_top_salt = (SFLUX + oceSPflx) * RAC               # g/s\n",
    "\n",
    "def surface_contrib_JT(zconv_top_salt, sptop, rho, fill_last=0.0):\n",
    "    \"\"\"\n",
    "    zconv_top_heat: (ny, nx)\n",
    "    swtop:          (nz, ny, nx)\n",
    "    rcp:            scalar\n",
    "    fill_last:      value for bottom slice (k = nz-1), usually 0.0 or np.nan\n",
    "    returns:\n",
    "      JsurfT:       (nz, ny, nx)  # Sv / PSU\n",
    "    \"\"\"\n",
    "    nz, ny, nx = sptop.shape\n",
    "\n",
    "    eS = zconv_top_salt.reshape(1, ny, nx)  # (1,ny,nx) for broadcast\n",
    "\n",
    "    J = np.empty_like(sptop, dtype=float)\n",
    "\n",
    "    # k = 0: (eT - fT[1]) / rcp / dT / dS * 1e-6\n",
    "    J[0] = (eS[0] - sptop[1]) / rho if np.ndim(binwidthS)==0 else \\\n",
    "           (eS[0] - sptop[1]) / rho\n",
    "\n",
    "    # 1 .. nz-2: -(fT[k+1]-fT[k]) / rcp / dT / dS * 1e-6\n",
    "    J[1:nz] = -(sptop[1:nz] - sptop[0:nz-1]) / rho\n",
    "\n",
    "    # bottom slice (k = nz-1): no k+1; choose your boundary convention\n",
    "    J[-1] = fill_last\n",
    "    return J\n",
    "\n",
    "Ft_surftest = surface_contrib_JT(zconv_top_salt,sptop,myparms['rhoconst'])    # this is in PSU.m^3/s\n",
    "\n",
    "# do the vertical convergence for KPP\n",
    "trWtopKPP = -(KPPg_SLT)         # PSU.m^3/s\n",
    "\n",
    "tmpkpp = np.full((nz,ny,nx),np.nan)\n",
    "tmpkpp[:-1,:,:] = trWtopKPP[:-1] - trWtopKPP[1:]\n",
    "\n",
    "file_name = 'budg3d_snap_set2'\n",
    "meta_budg3d_snap_set2 = parsemeta(dirdiags + file_name + \".\" + tsstr[0] + \".meta\")\n",
    "fldlist = np.array(meta_budg3d_snap_set2[\"fldList\"])\n",
    "varnames = np.array([\"SALTDR\"])\n",
    "recs = np.array([])\n",
    "for var in varnames:\n",
    "    irec = np.where(fldlist == var)\n",
    "    recs = np.append(recs, irec[0][0])\n",
    "\n",
    "\n",
    "SALTDR = np.full((len(tsstr),nz,ny,nx),np.nan)\n",
    "for i in range(len(tsstr)):\n",
    "    thisSALTDR,its,meta = rdmds(os.path.join(dirdiags, file_name),int(tsstr[i]),returnmeta=True,rec=recs[0])\n",
    "    thisSALTDR = thisSALTDR.reshape(nz,ny,nx)\n",
    "    SALTDR[i] = thisSALTDR\n",
    "\n",
    "SALTDR =  (SALTDR[1, :, :,:] - SALTDR[0, :,:, :]) / 1    # PSU.m/s\n",
    "#print(np.nansum(SALTDR),dt)\n",
    "\n",
    "tmptend = (SALTDR - 0) * mk3D_mod(RAC,SALTDR)    # PSU.m/s * m^2 = PSU.m^3/s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "2bda5cde-3fca-4a3d-8a6f-8e761ce5cf60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# redefine all the terms as a list from how we did before\n",
    "\n",
    "# define the ADVh total for this mymsk2\n",
    "G_S_offline_new = np.zeros((7, nS-1))\n",
    "dF_Snew = np.zeros((7, nS-1))\n",
    "Lijnew = np.zeros((7, nS-1), dtype=int)\n",
    "\n",
    "# also mask these by mymsk3\n",
    "# flatten the 3D arrays along all dimensions, as MATLAB’s tmp(:) does\n",
    "S_flat    = np.ravel(SALT*hf* mymsk3d, order='F')\n",
    "ADVh_flat = np.ravel(ADVhS*hf* mymsk3d,  order='F')\n",
    "ADVr_flat = np.ravel(ADVrS*hf* mymsk3d,  order='F')\n",
    "DFh_flat = np.ravel(DFhS*hf* mymsk3d,  order='F')\n",
    "DFr_flat = np.ravel(DFrS*hf* mymsk3d,  order='F')\n",
    "surf_flat = np.ravel(Ft_surftest*hf* mymsk3d,  order='F')\n",
    "kpp_flat = np.ravel(tmpkpp*hf* mymsk3d,  order='F')\n",
    "tend_flat = np.ravel(tmptend*hf* mymsk3d,  order='F')\n",
    "\n",
    "for i in range(nT-1):\n",
    "    # MATLAB: ij = find(tmp(:) >= bbb.binmidT(i) & tmp(:) < bbb.binmidT(i+1))\n",
    "    ij = np.where((S_flat >= binmidS[i]) & (S_flat < binmidS[i + 1]))[0]\n",
    "    Lijnew[0, i] = len(ij)\n",
    "\n",
    "    if len(ij) > 0:\n",
    "        # MATLAB: dF_Tnew(4,i)=sum(ff.advh(ij)); dF_Tnew(5,i)=sum(ff.advr(ij));\n",
    "        dF_Snew[0, i] = np.nansum(ADVh_flat[ij])\n",
    "        dF_Snew[1, i] = np.nansum(ADVr_flat[ij])\n",
    "        dF_Snew[2, i] = np.nansum(DFh_flat[ij])\n",
    "        dF_Snew[3, i] = np.nansum(DFr_flat[ij])\n",
    "        dF_Snew[4, i] = np.nansum(surf_flat[ij])\n",
    "        dF_Snew[5, i] = np.nansum(kpp_flat[ij])\n",
    "        dF_Snew[6, i] = np.nansum(tend_flat[ij])\n",
    "\n",
    "# MATLAB: G_T_offline_new = dF_Tnew ./ repmat(bbb.binwidthT1,[6 1])\n",
    "G_S_offline_new = dF_Snew / binwidthS1[None, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "2afa686b-eb32-4226-9092-397c282348c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-4392889.650053502\n",
      "\n",
      "-104967.49456513517\n",
      "-104967.49456513507\n"
     ]
    }
   ],
   "source": [
    "print(np.nansum(ADVhS*mymsk3d))  # but this is in degC.m^3/s\n",
    "print()\n",
    "print(np.nansum(dF_Snew[0]) / np.nansum(binwidthT1))\n",
    "print(np.nansum((ADVh_BSO + ADVh_FJNZ + ADVh_SPFJ + ADVh_NZRU)) / np.nansum(binwidthT1))  # in m^3/s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "d31d2858-70ae-4fc8-a2c2-28eaaf30a477",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gates        -111565.45142993073 m^3/s\n",
      "ADVh         -111565.45142993085 m^3/s\n",
      "ADVr         1.47828980097695e-12 m^3/s\n",
      "DFh         30.725026611431016 m^3/s\n",
      "DFr         -4.157690065247672e-12 m^3/s\n",
      "surf         -7434.17458396522 m^3/s\n",
      "kpp         -1.8478622512211875e-13 m^3/s\n",
      "\n",
      "total volume tend RHS:  -118968.90098728464 m^3/s\n",
      "total volume tend LHS:  -118968.90098808928 m^3/s\n"
     ]
    }
   ],
   "source": [
    "s = 0 \n",
    "print(\"gates       \",np.nansum((ADVh_BSO + ADVh_FJNZ + ADVh_SPFJ + ADVh_NZRU))/np.nansum(binwidthS1),\"m^3/s\")\n",
    "for i in range(6):\n",
    "    at = np.nansum(dF_Snew[i]) / np.nansum(binwidthS1)\n",
    "    print(labels[i],\"       \",at,\"m^3/s\")\n",
    "    s += at\n",
    "print()\n",
    "print(\"total volume tend RHS: \",s,\"m^3/s\")\n",
    "print(\"total volume tend LHS: \",np.nansum(dF_Snew[-1]/1.8e3) / np.nansum(binwidthS1),\"m^3/s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "924c8770-c4d1-499e-bdfc-b3eaf1c0dc83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/scratch3/atnguyen/aste_90x150x60/run_c68v_heffmosm3x_layers_lessmem1_viscAHp5em2_it0000_pk0000000001/diags/BUDG/'"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# great, now we can wrap all of this for tsstr2--5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc3e1f12-acee-464e-bafd-ecf7d622f332",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
