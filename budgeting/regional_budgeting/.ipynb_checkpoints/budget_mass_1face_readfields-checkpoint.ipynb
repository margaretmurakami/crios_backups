{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "620a75ab-619e-484c-a18b-2fe993025c7e",
   "metadata": {},
   "source": [
    "### Packages and paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "245af2c3-f1cd-4198-bcc7-65bec32eed6a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'ts2dte'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 31\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmk3D_mod\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mk3D_mod\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01maste_helper_funcs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m---> 31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mts2dte\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ts2dte\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'ts2dte'"
     ]
    }
   ],
   "source": [
    "# packages and plot parameters\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "from matplotlib.colors import TwoSlopeNorm\n",
    "from scipy.io import loadmat\n",
    "import numpy.ma as ma\n",
    "import glob\n",
    "import os\n",
    "import re\n",
    "from operator import mul\n",
    "import sys\n",
    "import xarray as xr\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (10,4)\n",
    "\n",
    "sys.path.append(\"/home/mmurakami/MITgcm/MITgcm_c68r/MITgcm-checkpoint68r/utils/python/MITgcmutils/MITgcmutils/\") # go to parent dir\n",
    "from mds import *\n",
    "\n",
    "# add rdmds reading functions to path\n",
    "# sys.path.append(\"/home/mmurakami/jupyterfiles/\") # go to parent dir\n",
    "\n",
    "\n",
    "sys.path.append(\"/home/mmurakami/crios_backups/an_helper_functions/\")\n",
    "# add personal functions to path test\n",
    "from read_binary import *\n",
    "from calc_UV_conv_1face import calc_UV_conv_1face\n",
    "from calc_mskmean_T_mod import calc_mskmean_T_mod\n",
    "from mk3D_mod import mk3D_mod\n",
    "from aste_helper_funcs import *\n",
    "from ts2dte import ts2dte"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be3291f8-f10b-4112-8a44-c21e47899cda",
   "metadata": {},
   "source": [
    "### Define relevant functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d7cedf-3c7f-45e4-bfef-250235b1aded",
   "metadata": {},
   "source": [
    "### Set up the files and grid, read files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c854d168-d5cb-4e86-b4bd-cb233828f70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Lab sea setup\n",
    "# # set the grid\n",
    "# nx=20\n",
    "# ny=16\n",
    "# nz=23\n",
    "\n",
    "# pt = np.array([[8,11,4],\n",
    "#                [10,9,0],\n",
    "#                [12,7,0],\n",
    "#                [18,1,0]])\n",
    "\n",
    "# dirrun = \"/scratch2/atnguyen/labsea/layers/run_c68r_layers_03Jun2023_noOL_10d/\"\n",
    "# dirIn = dirrun + \"diags/BUDG/\"\n",
    "# dirGrid = \"/scratch2/atnguyen/labsea/GRID_r8/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c8b195-5e4d-4deb-9510-4eca43f1f7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dirroot = \"/scratch2/atnguyen/aste_270x450x180/\"\n",
    "dirrun = \"/scratch/atnguyen/aste_270x450x180/OFFICIAL_ASTE_R1_Sep2019/\"\n",
    "dirIn = dirrun + \"diags/BUDG/\"\n",
    "dirDiags = dirrun + \"diags/\"\n",
    "dirState = dirDiags + \"STATE/\"\n",
    "dirGrid = dirroot + \"GRID_real8/\"\n",
    "dirgridnb = dirroot + \"GRID_noblank/\"\n",
    "dirgridw = dirroot + \"GRID_wet/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3596f035-81f6-476c-b923-ae9d521b4f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigaste = True\n",
    "\n",
    "if bigaste:\n",
    "    nx = 270\n",
    "    ncut1 = 450\n",
    "    ncut2 = 180\n",
    "else:\n",
    "    nx = 90\n",
    "    ncut1 = 150\n",
    "    ncut2 = 60\n",
    "    \n",
    "ny = 2*ncut1+nx+ncut2\n",
    "nz = 50\n",
    "nfx = np.array([nx, 0 , nx, ncut2 ,ncut1])\n",
    "nfy = np.array([ncut1, 0 , nx, nx, nx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be009e9e-3a51-435f-ae98-c1de35761d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save myParms from An hard-coding\n",
    "save_budg_3d = 0\n",
    "save_budg_2d = 1\n",
    "save_budg_scalar = 0\n",
    "save_budg_lev = 0\n",
    "\n",
    "strbudg = 'Mass'\n",
    "kBudget = 1\n",
    "test3d = True\n",
    "plot_fig = 1\n",
    "# kz = [[1, 5], [6, 10], [11, 19], [20, 23]]\n",
    "\n",
    "myparms = {\n",
    "    'yearFirst': 1979,\n",
    "    'yearLast': 1979,\n",
    "    'yearInAv': [1979, 1979],\n",
    "    'timeStep': 3600,\n",
    "    'iceModel': 1,\n",
    "    'useRFWF': 1,\n",
    "    'useNLFS': 4,\n",
    "    'rStar': 2,\n",
    "    'rhoconst': 1029,\n",
    "    'rcp': 1029 * 3994,\n",
    "    'rhoi': 910,\n",
    "    'rhosn': 330,\n",
    "    'flami': 334000,\n",
    "    'flamb': 2500000,\n",
    "    'SIsal0': 4,\n",
    "    'diagsAreMonthly': 0,\n",
    "    'diagsAreAnnual': 0,\n",
    "    'recInAve': [1, 2],\n",
    "    'SaltPlumeHeatFlux': 0,  # Not sure what this is\n",
    "    'conserveTr': 0\n",
    "}\n",
    "\n",
    "deltaTime = myparms['timeStep']\n",
    "dt = 86400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2400ca-7619-4964-aed5-be1303121e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get time-steps:\n",
    "flist = [f for f in os.listdir(dirIn) if f.startswith('budg2d_snap_set1.') and f.endswith('.data')]\n",
    "idot = flist[0].index('.')\n",
    "idot = [idot+1, flist[0][idot+1:].index('.')+idot+1]\n",
    "idot = np.asarray(idot,dtype=int)\n",
    "\n",
    "mygrid = {\n",
    "    'dirGrid': dirGrid,\n",
    "    'nFaces': 1,\n",
    "    'fileFormat': 'compact',\n",
    "    'memoryLimit': 2,\n",
    "    'ioSize': [nx*ny, 1],\n",
    "    'facesSize': [ny, nx],\n",
    "    'facesExpand': [ny, nx],\n",
    "    'missVal': 0,\n",
    "}\n",
    "\n",
    "fldstr2d = ['XC','YC','XG','YG','RAC','Depth','DXG','DYG','DXC','DYC']\n",
    "fldstr3d = ['hFacC','hFacW','hFacS','mskC','mskS','mskW']\n",
    "fldstr3dp = ['hFacC','hFacW','hFacS','maskCtrlC','maskCtrlS','maskCtrlW']\n",
    "fldstr1d = ['RC','RF','DRC','DRF']\n",
    "\n",
    "for fld in fldstr1d:\n",
    "    mygrid[fld] = np.squeeze(rdmds(os.path.join(dirGrid, fld)))\n",
    "\n",
    "for fld in fldstr3d:\n",
    "    temp = rdmds(os.path.join(dirGrid, fldstr3dp[fldstr3d.index(fld)]))\n",
    "    mygrid[fld] = temp.reshape(nz, ny, nx)\n",
    "\n",
    "for fld in fldstr2d:\n",
    "    temp = rdmds(os.path.join(dirGrid, fld))\n",
    "    mygrid[fld] = temp.reshape(ny, nx)\n",
    "\n",
    "mygrid['mskC'][mygrid['mskC'] == 0] = np.nan\n",
    "\n",
    "areaW, areaS, Vol = [], [], []\n",
    "for k in range(nz):\n",
    "    areaW.append(mygrid['DYG'] * mygrid['DRF'][k])\n",
    "    areaS.append(mygrid['DXG'] * mygrid['DRF'][k])\n",
    "    Vol.append(mygrid['RAC'] * mygrid['DRF'][k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd463b63-6243-4bf2-b8b7-257c086526be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# block out obcs\n",
    "# np tile I think operates the same as repmat in MATLAB\n",
    "RAC = mygrid['RAC']\n",
    "RAC3 = np.tile(RAC,(nz,1,1))\n",
    "\n",
    "hfC = mygrid['hFacC']\n",
    "DD = mygrid['Depth']\n",
    "dxg = mygrid['DXG']\n",
    "dyg = mygrid['DYG']\n",
    "dxg3d = np.tile(dxg,(nz,1,1))\n",
    "dyg3d = np.tile(dyg,(nz,1,1))\n",
    "\n",
    "print(mygrid['DRF'].shape,np.zeros((nz, ny, nx)).shape)\n",
    "drf3d = mk3D_mod(mygrid['DRF'], np.zeros((nz, ny, nx)))\n",
    "DD3d = mk3D_mod(DD,np.zeros((nz, ny, nx)))\n",
    "\n",
    "hfC[hfC == 0] = np.nan\n",
    "hfC1 = hfC[0, :, :]\n",
    "hfC1[hfC1 == 0] = np.nan\n",
    "\n",
    "RACg = RAC * hfC1\n",
    "hfC1p = np.copy(hfC1)\n",
    "\n",
    "hfC1p[:, nx-1] = np.nan\n",
    "hfC1p[ny-1,:] = np.nan\n",
    "RACgp = RAC * hfC1p"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cad5a2f-55fb-49e0-b532-835468b25d59",
   "metadata": {},
   "source": [
    "### Select a basin if we want to do that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e99119e-dc89-49f4-b6c9-dab8bab48853",
   "metadata": {},
   "outputs": [],
   "source": [
    "mygrid['hFacC'][mygrid['hFacC'] > 0] = 1\n",
    "mygrid['hFacC'][mygrid['hFacC'] == 0] = np.nan\n",
    "hf1 = mygrid['hFacC'][0] # top layer in z\n",
    "\n",
    "print(\"hf1\",hf1.shape)\n",
    "\n",
    "hf1 = get_aste_tracer(hf1, nfx, nfy)\n",
    "# check with hardcoding on this for mini or big aste\n",
    "if nx == 90:\n",
    "    hf1[:,281,:] = np.nan\n",
    "    hf1[:,7,:] = np.nan\n",
    "    hf1[:,86,122] = np.nan\n",
    "elif nx == 270:\n",
    "    hf1[:,844,:] = np.nan\n",
    "    hf1[:,23,:] = np.nan\n",
    "    hf1[:,365,260:261] = np.nan\n",
    "\n",
    "hf1 = aste_tracer2compact(hf1,nfx,nfy)\n",
    "hf = mygrid[\"hFacC\"]\n",
    "hf = hf * np.tile(hf1,(nz, 1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a5e6110-3226-4056-a752-00620029d088",
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy basin listing from lookat_layers\n",
    "fileprefix = \"/scratch/pillarh/aste_270x450x180/\"\n",
    "extBasin='run_template/input_maskTransport/'\n",
    "filename = fileprefix + extBasin + \"GATE_transports_v3_osnap.mat\"\n",
    "if nx == 270:\n",
    "    inf = loadmat(filename)\n",
    "    mskBasin = (inf[\"mskBasin\"])\n",
    "\n",
    "mskBasin = mskBasin.T               # python adjustment\n",
    "\n",
    "# this is now different syntax than the other file\n",
    "strb=np.array(['CanadaB','ChukchiS','MakarovB','AmundsenB','NansenB','BeringS','BarentsS','GINs','CAA',\n",
    "               'SPG','LabSea','NPac','NAtlantic','AtlS30'])\n",
    "\n",
    "mskBasin[mskBasin==50] =6\n",
    "mskBasin[mskBasin==200]=7\n",
    "mskBasin[mskBasin==300]=8\n",
    "mskBasin[mskBasin==400]=9\n",
    "mskBasin[mskBasin==500]=9\n",
    "mskBasin[mskBasin==600]=10\n",
    "mskBasin[mskBasin==700]=11\n",
    "mskBasin[mskBasin==-1]=12\n",
    "mskBasin[mskBasin==-100]=13\n",
    "latNA = 30\n",
    "lonNA = -82\n",
    "condition_13 = (mskBasin == 0) & (mygrid['YC'] > latNA) & (mygrid['XC'] > lonNA) & (hf1.reshape((ny,nx)) > 0)\n",
    "mskBasin[condition_13] = 13\n",
    "condition_14 = (mskBasin == 0) & (hf1.reshape((ny,nx)) > 0)\n",
    "mskBasin[condition_14] = 14\n",
    "\n",
    "mskBasin = mskBasin * hf1\n",
    "mskBasin = mskBasin[0,:,:]   # change indexing for  python\n",
    "mskBasin -= 1\n",
    "\n",
    "# create mskBasin3D to also add to the dataset\n",
    "mskBasin3D = np.tile(mskBasin[np.newaxis,:,:],(nz,1,1))\n",
    "mskBasin3D.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fdea8c7-7a23-4772-a7f6-cfa68789b40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "wetmask = mygrid['hFacC']\n",
    "wetmask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ef4cc0-9058-4284-93fc-2240f8ba9927",
   "metadata": {},
   "outputs": [],
   "source": [
    "dims = (\"z\",\"compact_x\",\"compact_y\")\n",
    "coords = {\"z\" : np.arange(0,50,1),\n",
    "          \"compact_x\" : np.arange(0,1350,1),\n",
    "          \"compact_y\" : np.arange(0,270,1)}\n",
    "\n",
    "attrsBasin = {'title' : 'CanadaB: 0, ChukchiS: 1, MakarovB: 2, AmundsenB: 3, NansenB: 4, BeringS: 5, BarentsS: 6, GINs: 7, CAA: 8, SPG: 9, LabSea: 10, NPac: 11, NAtlantic: 12, AtlS30: 13',\n",
    "              'standard_name' : 'Basins labeled',\n",
    "             'units' : 'degree_c'}\n",
    "\n",
    "attrsWet= {'title' : 'model wet points in compact form',\n",
    "         'standard_name' : '1= wet, 0=dry',\n",
    "         'units' : 'boolean'}\n",
    "\n",
    "# add mskBasin and wetmask to the xarray for the dataset\n",
    "mskBasin_3D = xr.DataArray(data = mskBasin*wetmask,\n",
    "                    dims = dims,\n",
    "                    coords = coords,\n",
    "                    attrs = attrsBasin)\n",
    "\n",
    "mskBasin_2D = xr.DataArray(data = mskBasin*wetmask[0,:,:],\n",
    "                    dims = dims[1:],\n",
    "                    coords = [coords[\"compact_x\"],coords[\"compact_y\"]],\n",
    "                    attrs = attrsBasin)\n",
    "\n",
    "wetmask_xr = xr.DataArray(data = wetmask,\n",
    "                    dims = dims,\n",
    "                    coords = coords,\n",
    "                    attrs = attrsWet)\n",
    "\n",
    "\n",
    "ds = xr.Dataset()\n",
    "ds['mskBasin_3D'] = mskBasin_3D\n",
    "ds['mskBasin_2D'] = mskBasin_2D\n",
    "ds['wetmask'] = wetmask_xr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f714f42-438f-455c-975c-10405b2c8025",
   "metadata": {},
   "source": [
    "### Get the time steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d61a78-e4a8-4c7e-998c-7a8e9273c7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use ts2dte to get december 2014\n",
    "# first make an array of filenames\n",
    "dt = 600\n",
    "startyr = 2002\n",
    "endyr = 2019\n",
    "\n",
    "days_reg = np.array([31,28,31,30,31,30,31,31,30,31,30,31])\n",
    "days_leap = np.array([31,29,31,30,31,30,31,31,30,31,30,31])\n",
    "days_reg = days_reg*24*3600/dt\n",
    "days_leap = days_leap*24*3600/dt\n",
    "\n",
    "years = np.arange(startyr,endyr,1)\n",
    "\n",
    "# make an array of all the filenames before cumsum\n",
    "fnames = np.array([],dtype=int)\n",
    "\n",
    "for year in years:\n",
    "    if is_leap(year):\n",
    "        fnames = np.append(fnames,days_leap)\n",
    "    else:\n",
    "        fnames = np.append(fnames,days_reg)\n",
    "fnames = np.cumsum(fnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aabf6e2-ef63-4c52-81ab-7a671bdf34bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now get this specific year, we want December 2014\n",
    "# what if we want\n",
    "months = np.arange(1,13,1)   # all the months of 2014, we also want the first month of 2015 so we can do tendency for 12/2014\n",
    "year = 2014\n",
    "tsstrs = np.array([])\n",
    "f_toread = np.array([],dtype=int)\n",
    "for inf in fnames:\n",
    "    thisfile = ts2dte(inf,deltat=600,startyr=2002,startmo=1,startdy=1)\n",
    "    if thisfile.year == year and thisfile.month in months: \n",
    "        #print(thisfile)  # this would be used as the second time step for the month of November, not what we want\n",
    "        f_toread = np.append(f_toread,int(inf))\n",
    "\n",
    "t_day = f_toread.astype(str)\n",
    "tsstr = np.array([str(item).zfill(10) for item in t_day])\n",
    "\n",
    "# we also want month 1 of 2015\n",
    "months = 1\n",
    "year = 2015\n",
    "f_toread = np.array([],dtype=int)\n",
    "for inf in fnames:\n",
    "    thisfile = ts2dte(inf,deltat=600,startyr=2002,startmo=1,startdy=1)\n",
    "    if thisfile.year == year and thisfile.month == months: \n",
    "        #print(thisfile)  # this would be used as the second time step for the month of November, not what we want\n",
    "        f_toread = np.append(f_toread,int(inf))\n",
    "\n",
    "t_day = f_toread.astype(str)\n",
    "t_day = np.array([str(item).zfill(10) for item in t_day])\n",
    "tsstr = np.append(tsstr,t_day)\n",
    "\n",
    "print(tsstr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3c6c4b-c5ba-45b3-af08-c0329e4b7fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the basin we want\n",
    "iB = 6\n",
    "myMask = mskBasin.copy()\n",
    "myMask[myMask != iB] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50779cec-c0dc-43be-a510-b7076950d3fd",
   "metadata": {},
   "source": [
    "### Isolate the volumes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da12bacf-aab5-4a73-9903-7203d75f7ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code to isolate one set of volumes\n",
    "# file_name = 'budg2d_snap_set1'\n",
    "# meta_budg2d_snap_set1 = parsemeta(dirIn + file_name + \".\" + tsstr + \".meta\")\n",
    "\n",
    "# # try to read this with rec\n",
    "# fldlist = np.array(meta_budg2d_snap_set1['fldList'])\n",
    "# varnames = np.array(['ETAN','SIheff','SIhsnow'])\n",
    "# recs = np.array([])\n",
    "# for var in varnames:\n",
    "#     irec = np.where(fldlist == var)\n",
    "#     recs = np.append(recs, irec[0][0])\n",
    "\n",
    "# # make sure order we write the variables is the same as the order in varnames, else we read the wrong thing\n",
    "# ETAN,its,meta = rdmds(os.path.join(dirIn, file_name),int(tsstr),returnmeta=True,rec=recs[0])\n",
    "# SIheff,its,meta = rdmds(os.path.join(dirIn, file_name),int(tsstr),returnmeta=True,rec=recs[1])\n",
    "# SIhsnow,its,meta = rdmds(os.path.join(dirIn, file_name),int(tsstr),returnmeta=True,rec=recs[2])\n",
    "\n",
    "# ETAN =  ETAN[:, :]\n",
    "# SIheff =  SIheff[:, :]\n",
    "# SIhsnow = SIhsnow[:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0eefccd-4ac0-428d-82a0-62367589551e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # select by basin\n",
    "\n",
    "\n",
    "# # select by existing basin in mskBasin\n",
    "# ETAN2 = np.reshape(ETAN2,(ny,nx)) * myMask\n",
    "# ETAN1 = np.reshape(ETAN1,(ny,nx)) * myMask\n",
    "# PHIBOT2 = np.reshape(PHIBOT2,(ny,nx)) * myMask\n",
    "# PHIBOT1 = np.reshape(PHIBOT1,(ny,nx)) * myMask\n",
    "# SIheff2 = np.reshape(SIheff2,(ny,nx)) * myMask\n",
    "# SIheff1 = np.reshape(SIheff1,(ny,nx)) * myMask\n",
    "# SIhsnow2 = np.reshape(SIhsnow2,(ny,nx)) * myMask\n",
    "# SIhsnow1 = np.reshape(SIhsnow1,(ny,nx)) * myMask\n",
    "\n",
    "# # now we can multiply based on the mskBasin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08718b0-f5ee-4a15-a6bb-7c6b44cd7a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def make_volume(ETAN, myparms,RAC,mygrid,hfC,DD):\n",
    "#     tmptend = np.zeros((nz, ny, nx))\n",
    "#     if myparms['useNLFS'] < 2 or myparms['rStar'] == 0:        # not this time\n",
    "#         tmptend[0,:, :] = ETAN * myparms['rhoconst'] * RAC\n",
    "#         if myparms['useRFWF'] == 0:\n",
    "#             tmptend[0, :, :] = np.zeros((ny, nx))\n",
    "#     else:    # 4/22 look at this one\n",
    "#         if myparms['useRFWF'] != 0:                                 # we are using this  # check if tmp1 is the same as drf3d!!\n",
    "#             tmp1 = mk3D_mod(mygrid['DRF'],hfC) * hfC\n",
    "#             tmp2 = tmp1/mk3D_mod(DD,tmp1)\n",
    "#         else:\n",
    "#             tmp2 = drf3d / mk3D_mod(DD, tmp1)\n",
    "            \n",
    "#         tmptend = tmp2 * mk3D_mod(ETAN, tmp2) * mk3D_mod(RAC, hfC)  # in this line we removed rhoconst to just return volume\n",
    "        \n",
    "#     return tmptend\n",
    "\n",
    "# vol_O_t2 = make_volume(ETAN2, myparms, RAC, mygrid, hfC,DD)\n",
    "# vol_O_t1 = make_volume(ETAN1, myparms, RAC, mygrid, hfC,DD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcca8ac3-a1ab-45c5-8184-7339bd0d0448",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # we can similarly get the volume of ice and snow if we do not multiply by volume\n",
    "# vol_I_t2 = (SIheff2 + SIhsnow2) * RAC\n",
    "# vol_I_t1 = (SIheff1 + SIhsnow1) * RAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c77a6e-0fab-4d91-bd96-1854c6a06410",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # lets test to see if this is the same as the following\n",
    "# testtmp = (vol_O_t2*myparms[\"rhoconst\"] - vol_O_t1*myparms[\"rhoconst\"])/dt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "831e8085-8550-45d4-8007-6517a1a1a162",
   "metadata": {},
   "source": [
    "### Ocean and Ice tendency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224a5521-ba9a-42d5-b8bf-14bbc863536c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ocean and ice\n",
    "AB_gT=0\n",
    "debug = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff01072b-c8b3-4626-96ab-5db059797942",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try to create a multidimensional array with each of the months averages\n",
    "# first create an array of shape tsstr,nz,ny,nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9309d5f1-883a-428d-9c4a-d675b65b3360",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "file_name = 'budg2d_snap_set1'\n",
    "\n",
    "# assuming all files are structured the same\n",
    "meta_budg2d_snap_set1 = parsemeta(dirIn + file_name + \".\" + tsstr[0]+ \".meta\")\n",
    "# try to read this with rec\n",
    "fldlist = np.array(meta_budg2d_snap_set1['fldList'])\n",
    "varnames = np.array(['ETAN','SIheff','SIhsnow'])\n",
    "recs = np.array([])\n",
    "for var in varnames:\n",
    "    irec = np.where(fldlist == var)\n",
    "    recs = np.append(recs, irec[0][0])\n",
    "\n",
    "# set for all months\n",
    "tend = np.zeros((len(tsstr)-1,nz, ny, nx))\n",
    "print(tend.shape)\n",
    "\n",
    "for t in range(len(tsstr)-1):\n",
    "    t1 = tsstr[t]\n",
    "    t2 = tsstr[t+1]\n",
    "    read = [int(t1),int(t2)]\n",
    "\n",
    "    # make sure order we write the variables is the same as the order in varnames, else we read the wrong thing\n",
    "    ETAN,its,meta = rdmds(os.path.join(dirIn, file_name),read,returnmeta=True,rec=recs[0])\n",
    "    SIheff,its,meta = rdmds(os.path.join(dirIn, file_name),read,returnmeta=True,rec=recs[1])\n",
    "    SIhsnow,its,meta = rdmds(os.path.join(dirIn, file_name),read,returnmeta=True,rec=recs[2])\n",
    "\n",
    "    # do differencing\n",
    "    dETAN_dt =  (ETAN[1, :, :] - ETAN[0, :, :]) / dt  # change naming to dEtan_dt  m/s\n",
    "    dSIheff_dt =  (SIheff[1, :, :] - SIheff[0, :, :]) / dt\n",
    "    dSIhsnow_dt = (SIhsnow[1, :, :] - SIhsnow[0, :, :]) / dt\n",
    "\n",
    "    # choose by basin\n",
    "    # select by existing basin in mskBasin\n",
    "    dETAN_dt = np.reshape(dETAN_dt,(ny,nx)) * myMask\n",
    "    dSIheff_dt = np.reshape(dSIheff_dt,(ny,nx)) * myMask\n",
    "    dSIhsnow_dt = np.reshape(dSIhsnow_dt,(ny,nx)) * myMask\n",
    "\n",
    "    # ocean\n",
    "    if debug:\n",
    "        print(read,its[0],its[1]) # these iteration numbers should be the same as read\n",
    "\n",
    "    # 3D, with rStar:\n",
    "    tmptend = np.zeros((nz, ny, nx))\n",
    "    if myparms['useNLFS'] < 2 or myparms['rStar'] == 0:        # not this time\n",
    "        tmptend[0,:, :] = dETAN_dt * myparms['rhoconst'] * RAC\n",
    "        if myparms['useRFWF'] == 0:\n",
    "            tmptend[0, :, :] = np.zeros((ny, nx))\n",
    "    else:    # 4/22 look at this one\n",
    "        if myparms['useRFWF'] != 0:                                 # we are using this  # check if tmp1 is the same as drf3d!!\n",
    "            tmp1 = mk3D_mod(mygrid['DRF'],hfC) * hfC\n",
    "            tmp2 = tmp1/mk3D_mod(DD,tmp1)\n",
    "        else:\n",
    "            tmp2 = drf3d / mk3D_mod(DD, tmp1)\n",
    "            \n",
    "        tmptend = tmp2 * mk3D_mod(dETAN_dt, tmp2) * myparms['rhoconst'] * mk3D_mod(RAC, hfC)\n",
    "\n",
    "    tend[t,:,:,:] = tmptend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e917bcb-b190-435d-92ba-d87c619dfdd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize = (5,5))\n",
    "num_plots = tend.shape[0]\n",
    "rows = 2\n",
    "cols = 6\n",
    "fig,axes = plt.subplots(rows,cols,sharex=True, sharey=True,figsize=(20,8))\n",
    "if num_plots>1:\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "for i in range(tend.shape[0]):\n",
    "    ax = axes[i]\n",
    "\n",
    "    # add volume distribution\n",
    "    title = \"surface ten \" + str(i+1)+\"/2014\"\n",
    "    cb = ax.pcolormesh(get_aste_tracer(tend[i,0,:,:],nfx,nfy)[0])\n",
    "    \n",
    "    # labels\n",
    "    fig.colorbar(cb)\n",
    "    ax.set_title(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9970f2a-2299-47d6-b49f-fc241d80d735",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if we want to look at the theta and salt for binning in this file, we want thetadr and saltdr budg3d_snap_set2 divided by drf\n",
    "# at each snap, we get a TS distribution with volume\n",
    "# at each snap, we also get a TS distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61867ff7-5261-479d-8f25-817ec34b7794",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is wrong rewrite\n",
    "# An has written nansum(tmptend, axis=3) but this is her z axis; I think we want axis = 0\n",
    "budgO = {'fluxes': {'tend': tmptend}}\n",
    "budgO['tend'] = np.nansum(tmptend,axis=0)\n",
    "budgI = {'tend': (SIheff * myparms['rhoi'] + SIhsnow * myparms['rhosn']) * RAC}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3197450-e474-4ad6-814e-6d7d4cba310c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# budgI = {'tend': (SIheff * myparms['rhoi'] + SIhsnow * myparms['rhosn']) * RAC}\n",
    "budgOI = {}\n",
    "budgOI['tend'] = budgO['tend'] + budgI['tend']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb06f3af-1d6f-4887-ae92-928100244e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check to see if it is the same as the volume calc\n",
    "np.nansum(testtmp-tmptend) # mama we did it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "026643f4-310d-436d-bdd4-bffa8e133b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clear memory\n",
    "del ETAN, PHIBOT, SIheff, SIhsnow, tmptend"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df3ea0be-da60-4973-aa55-402926d1047c",
   "metadata": {},
   "source": [
    "### Vertical convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd10629b-4fed-4222-a66b-0e50903b58d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rewrite with only reading in these lines, be sure to compare\n",
    "meta_budg2d_zflux_set1= parsemeta(dirIn + \"budg2d_zflux_set1\" + '.' + tsstr + '.meta')\n",
    "fldlist = np.array(meta_budg2d_zflux_set1['fldList'])\n",
    "varnames = np.array(['oceFWflx','SIatmFW'])\n",
    "recs = np.array([])\n",
    "for var in varnames:\n",
    "    irec = np.where(fldlist == var)\n",
    "    recs = np.append(recs, irec[0][0])\n",
    "oceFWflx,its,meta = rdmds(dirIn + \"budg2d_zflux_set1\", t2,returnmeta=True,rec = recs[0])\n",
    "SIatmFW,its,meta = rdmds(dirIn + \"budg2d_zflux_set1\", t2,returnmeta=True,rec = recs[1])\n",
    "\n",
    "# read WVELMASS\n",
    "meta_budg3d_zflux_set2= parsemeta(dirIn + \"budg3d_zflux_set2\" + '.' + tsstr + '.meta')\n",
    "fldlist = np.array(meta_budg3d_zflux_set2['fldList'])\n",
    "varnames = np.array(['WVELMASS'])\n",
    "recs = np.array([])\n",
    "for var in varnames:\n",
    "    irec = np.where(fldlist == var)\n",
    "    recs = np.append(recs, irec[0][0])\n",
    "WVELMASS,its,meta = rdmds(dirIn + \"budg3d_zflux_set2\", t2,returnmeta=True,rec = recs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e49bf339-9472-4ffd-9d48-a8b44d7e512b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform calculations\n",
    "budgO[\"zconv\"] = oceFWflx\n",
    "budgI[\"zconv\"] = SIatmFW - oceFWflx\n",
    "\n",
    "if not myparms[\"useRFWF\"]:\n",
    "    budgO[\"zconv\"] = 0 * budgO[\"zconv\"]\n",
    "\n",
    "trWtop = -WVELMASS * myparms[\"rhoconst\"]\n",
    "print(trWtop.shape)\n",
    "\n",
    "# indexing seems fishy here - rewrite\n",
    "if myparms[\"useNLFS\"] < 2 or myparms[\"rStar\"] == 0:\n",
    "    trWtop[0, :, :] = oceFWflx\n",
    "    if not myparms[\"useRFWF\"]:\n",
    "        trWtop[0,:, :] = -WVELMASS[0,:, :] * myparms[\"rhoconst\"]\n",
    "\n",
    "# same size trWtop and TrWbot\n",
    "trWbot = np.zeros_like(trWtop)\n",
    "trWbot[:-1,:, :] = trWtop[1:,:, :]\n",
    "\n",
    "#budgO[\"fluxes\"] = {}\n",
    "budgO[\"fluxes\"][\"trWtop\"] = trWtop * RAC3\n",
    "budgO[\"fluxes\"][\"trWbot\"] = trWbot * RAC3\n",
    "budgO[\"fluxes\"][\"zconv\"] = budgO[\"fluxes\"][\"trWtop\"] - budgO[\"fluxes\"][\"trWbot\"]\n",
    "\n",
    "# changed axis here to 0 because we're looking at z\n",
    "if myparms[\"useNLFS\"] < 2 or (myparms[\"rStar\"] == 0 and not myparms[\"useRFWF\"]):\n",
    "    budgO[\"zconv\"] += np.sum(trWtop - trWbot, axis=0)\n",
    "\n",
    "budgI[\"fluxes\"] = {}\n",
    "budgI[\"fluxes\"][\"trWtop\"] = -RAC * (budgI[\"zconv\"] + budgO[\"zconv\"])\n",
    "budgI[\"fluxes\"][\"trWbot\"] = -RAC * budgO[\"zconv\"]\n",
    "\n",
    "budgO[\"zconv\"] = RAC * budgO[\"zconv\"]\n",
    "budgI[\"zconv\"] = RAC * budgI[\"zconv\"]\n",
    "budgOI[\"zconv\"] = budgO[\"zconv\"] + budgI[\"zconv\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd31b81d-10b3-439a-a7e4-53fcd23c8b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clear memory\n",
    "del oceFWflx, SIatmFW, WVELMASS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfede2ff-1a8d-4516-96a1-65ca421d4b13",
   "metadata": {},
   "source": [
    "### Horizontal convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eebb68a2-ec02-41af-901a-72dfe25146a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read U and V mass\n",
    "meta_budg3d_hflux_set2= parsemeta(dirIn + \"budg3d_hflux_set2\" + '.' + tsstr + '.meta')\n",
    "fldlist = np.array(meta_budg3d_hflux_set2['fldList'])\n",
    "varnames = np.array(['UVELMASS','VVELMASS'])\n",
    "recs = np.array([])\n",
    "for var in varnames:\n",
    "    irec = np.where(fldlist == var)\n",
    "    recs = np.append(recs, irec[0][0])\n",
    "UVELMASS,its,meta = rdmds(dirIn + \"budg3d_hflux_set2\", t2,returnmeta=True,rec = recs[0])\n",
    "VVELMASS,its,meta = rdmds(dirIn + \"budg3d_hflux_set2\", t2,returnmeta=True,rec = recs[1])\n",
    "\n",
    "# read advective\n",
    "meta_budg2d_hflux_set1= parsemeta(dirIn + \"budg2d_hflux_set1\" + '.' + tsstr + '.meta')\n",
    "fldlist = np.array(meta_budg2d_hflux_set1['fldList'])\n",
    "varnames = np.array(['ADVxHEFF','ADVyHEFF','ADVxSNOW','ADVySNOW'])\n",
    "recs = np.array([])\n",
    "for var in varnames:\n",
    "    irec = np.where(fldlist == var)\n",
    "    recs = np.append(recs, irec[0][0])\n",
    "ADVxHEFF,its,meta = rdmds(dirIn + \"budg2d_hflux_set1\", t2,returnmeta=True,rec = recs[0])\n",
    "ADVyHEFF,its,meta = rdmds(dirIn + \"budg2d_hflux_set1\", t2,returnmeta=True,rec = recs[1])\n",
    "ADVxSNOW,its,meta = rdmds(dirIn + \"budg2d_hflux_set1\", t2,returnmeta=True,rec = recs[2])\n",
    "ADVySNOW,its,meta = rdmds(dirIn + \"budg2d_hflux_set1\", t2,returnmeta=True,rec = recs[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "518a8bb1-66c5-430c-b149-a5b7ed61c507",
   "metadata": {},
   "outputs": [],
   "source": [
    "# THERE IS NO DFXEHEFF OR DFYEHEFF! This has not been handled in this notebook\n",
    "# Calculations for ocean\n",
    "tmpUo = myparms['rhoconst'] * dyg3d * drf3d * UVELMASS    # kg/m^3 * m (len of western edge), * m * m/s = kg/s\n",
    "tmpVo = myparms['rhoconst'] * dxg3d * drf3d * VVELMASS\n",
    "\n",
    "tmpUi = myparms['rhoi'] * ADVxHEFF + myparms['rhosn'] * ADVxSNOW\n",
    "tmpVi = myparms['rhoi'] * ADVyHEFF + myparms['rhosn'] * ADVySNOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba31d5ad-1f92-44ed-afd2-e6466b8b5a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# budgO = {}\n",
    "#budgO['fluxes'] = {}\n",
    "budgO['fluxes']['hconv'] = calc_UV_conv_1face(tmpUo, tmpVo)\n",
    "budgO['hconv'] = calc_UV_conv_1face(np.nansum(tmpUo, axis=0), np.nansum(tmpVo, axis=0))\n",
    "\n",
    "# budgI = {}\n",
    "budgI['hconv'] = calc_UV_conv_1face(tmpUi, tmpVi)\n",
    "\n",
    "# Calculations for ocean+ice system\n",
    "# budgOI = {}\n",
    "budgOI['hconv'] = budgO['hconv'] + budgI['hconv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8276e93-fbeb-4df7-8631-80d894bd43ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clear memory\n",
    "del UVELMASS,VVELMASS,ADVxHEFF,ADVyHEFF,ADVxSNOW,ADVySNOW,tmpUo,tmpVo,tmpUi,tmpVi,trWtop,trWbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea4d8f0-bca3-43ab-a56a-ebc6eaeb0b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional Check 1 - uncomment\n",
    "# fig = plt.figure()\n",
    "# ax = plt.subplot(221)\n",
    "# pcm = ax.pcolormesh(tmpUo[0])\n",
    "# fig.colorbar(pcm, ax=ax,cmap=\"jet\")\n",
    "# ax = plt.subplot(222)\n",
    "# pcm = ax.pcolormesh(tmpUo[10])\n",
    "# fig.colorbar(pcm, ax=ax,cmap=\"jet\")\n",
    "# ax = plt.subplot(223)\n",
    "# pcm = ax.pcolormesh(tmpVo[0])\n",
    "# fig.colorbar(pcm, ax=ax,cmap=\"jet\")\n",
    "# ax = plt.subplot(224)\n",
    "# pcm = ax.pcolormesh(tmpVo[10])\n",
    "# fig.colorbar(pcm, ax=ax,cmap=\"jet\")\n",
    "\n",
    "# Optional Check 2\n",
    "# fig = plt.figure()\n",
    "# ax = plt.subplot(141)\n",
    "# pcm = ax.pcolormesh(budgO[\"fluxes\"][\"tend\"][0,:,:])\n",
    "# fig.colorbar(pcm, ax=ax)\n",
    "# ax = plt.subplot(142)\n",
    "# pcm = ax.pcolormesh(budgO[\"fluxes\"][\"zconv\"][0,:,:])\n",
    "# fig.colorbar(pcm, ax=ax)\n",
    "# ax = plt.subplot(143)\n",
    "# pcm = ax.pcolormesh(budgO[\"fluxes\"][\"hconv\"][0,:,:])\n",
    "# fig.colorbar(pcm, ax=ax)\n",
    "# ax = plt.subplot(144)\n",
    "# pcm = ax.pcolormesh(budgO[\"fluxes\"][\"tend\"][0,:,:] - budgO[\"fluxes\"][\"zconv\"][0,:,:] - budgO[\"fluxes\"][\"hconv\"][0,:,:])\n",
    "# fig.colorbar(pcm, ax=ax)\n",
    "\n",
    "# Optional Check 3 - resid should be small, hconv and zconv should be similar, last line should have virtually matching nums\n",
    "# resid = budgO[\"fluxes\"][\"tend\"][:,:,:] - budgO[\"fluxes\"][\"zconv\"][:,:,:] - budgO[\"fluxes\"][\"hconv\"][:,:,:]\n",
    "# print(np.nansum(resid))\n",
    "# print(budgO[\"fluxes\"][\"tend\"][9,14,0],budgO[\"fluxes\"][\"hconv\"][9,14,0],budgO[\"fluxes\"][\"zconv\"][9,14,0],resid[9,14,0])\n",
    "# print(budgO[\"fluxes\"][\"tend\"][9,14,0]-budgO[\"fluxes\"][\"hconv\"][9,14,0]-budgO[\"fluxes\"][\"zconv\"][9,14,0],resid[9,14,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ffc1294-2824-4d54-8730-87ec0c044f92",
   "metadata": {},
   "source": [
    "### Complete list of output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f26f1e9-d7f9-4af5-a48e-c8214c27c0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculations for budgOI\n",
    "\n",
    "# this might have wrong indexing\n",
    "a = budgOI['tend'] * hfC1p\n",
    "b = budgOI['hconv'] * hfC1p\n",
    "c = budgOI['zconv'] * hfC1p\n",
    "budgetOI = np.zeros(3)\n",
    "budgetOI[0] = np.nansum(a) / np.nansum(RACgp)\n",
    "budgetOI[1] = np.nansum(b) / np.nansum(RACgp)\n",
    "budgetOI[2] = np.nansum(c) / np.nansum(RACgp)\n",
    "print(f\"{budgetOI[0] - budgetOI[1] - budgetOI[2]:.4e}\", end=' ')\n",
    "print()\n",
    "\n",
    "# Calculations for budgI\n",
    "a = budgI['tend'] * hfC1p\n",
    "b = budgI['hconv'] * hfC1p\n",
    "c = budgI['zconv'] * hfC1p\n",
    "budgetI = np.zeros(3)\n",
    "budgetI[0] = np.nansum(a) / np.nansum(RACgp)\n",
    "budgetI[1] = np.nansum(b) / np.nansum(RACgp)\n",
    "budgetI[2] = np.nansum(c) / np.nansum(RACgp)\n",
    "print(f\"{budgetI[0] - budgetI[1] - budgetI[2]:.4e}\", end=' ')\n",
    "print(f\"{(budgetI[0] - budgetI[1] - budgetI[2])/budgetI[0]:.4e}\", end=' ')\n",
    "\n",
    "print()\n",
    "\n",
    "# Calculations for budgO\n",
    "a = budgO['tend'] * hfC1p\n",
    "b = budgO['hconv'] * hfC1p\n",
    "c = budgO['zconv'] * hfC1p\n",
    "budgetO = np.zeros(3)\n",
    "budgetO[0] = np.nansum(a) / np.nansum(RACgp)\n",
    "budgetO[1] = np.nansum(b) / np.nansum(RACgp)\n",
    "budgetO[2] = np.nansum(c) / np.nansum(RACgp)\n",
    "print(f\"{budgetO[0] - budgetO[1] - budgetO[2]:.4e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d76e296-8be9-46ad-859c-81504b2f8a39",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Start creating diags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60b99ab-60eb-4f76-8d37-ae1719251fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # This is for basins, I don't think we need this\n",
    "listDiags = ['glo_vol_ocn', 'glo_vol_tot', 'glo_vol_ice']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "633894b6-6931-46a8-b2bb-fad1d704e2b8",
   "metadata": {},
   "source": [
    "#### I think we should be calculaating m^3/s so that will be done here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5096164-70bb-471c-a22f-40efd4bdd0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# global sum \n",
    "# Calculations\n",
    "tmp1,a = calc_mskmean_T_mod(budgOI, hfC1p, RACgp,'extensive')\n",
    "glo_vol_tot = [tmp1['tend'], tmp1['hconv'], tmp1['zconv']]\n",
    "\n",
    "tmp1,a = calc_mskmean_T_mod(budgO, hfC1p, RACgp,'extensive')\n",
    "glo_vol_ocn = [tmp1['tend'], tmp1['hconv'], tmp1['zconv']]\n",
    "\n",
    "tmp1,a = calc_mskmean_T_mod(budgI, hfC1p, RACgp,'extensive')\n",
    "glo_vol_ice = [tmp1['tend'], tmp1['hconv'], tmp1['zconv']]  # see /home/atnguyen/matlab/gcmfaces/gcmfaces_diags/diags_select.m\n",
    "\n",
    "# Package results\n",
    "onediag = {}\n",
    "onediag['listTimes'] = myparms['yearFirst'] + t1 * myparms['timeStep'] / 86400 / 365.25\n",
    "onediag['listSteps'] = t2\n",
    "\n",
    "for jj in listDiags:\n",
    "    onediag[jj] = eval(jj)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9eadfa8-3f70-4f63-98e1-fb11d9fa02d6",
   "metadata": {},
   "source": [
    "### I'm going to skip the budglev stuff because I don't know what this is or where it's being set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e30571b-8dc2-4c26-aa94-08ebd972781e",
   "metadata": {},
   "outputs": [],
   "source": [
    "figpath = \"/scratch2/mmurakami/aste_270x450x180/run_c67w_layers_budget_nlayersorig_advdiffsplit_FULLYfixedXX_checkedwithAN_it0062_nS112_nT112_pk0000631152/\"\n",
    "# Figure 1 - made better\n",
    "fig,axs = plt.subplots(2,2,figsize = (9.5,8.5),sharex = True,sharey = True)\n",
    "plt.suptitle(\"Tend-HConv-Zconv at ix,iy Grid Coordinates\")\n",
    "fig.supxlabel(\"Net Mass\")\n",
    "fig.supylabel(\"Model Depth Level\")\n",
    "\n",
    "for n, ax in enumerate(axs.flatten(),start = 1):\n",
    "    ix, iy, k = pt[n-1]\n",
    "    aa[:, n-1] = budgO['fluxes']['tend'][:, iy, ix] - budgO['fluxes']['hconv'][:, iy, ix] - budgO['fluxes']['zconv'][:, iy, ix]\n",
    "\n",
    "    ax.plot(aa[:, n-1], -np.arange(1, nz+1), '.-')\n",
    "    ax.grid()\n",
    "    ax.set_title(f\"[ix,iy]=[{iy},{ix}]; {100 * np.nanmax(np.abs(aa[:, n-1]))/np.nanmax(np.abs(budgO['fluxes']['zconv'][:,iy, ix]))}%\")\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(figpath + \"MassBudg_percent.png\",dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c248cfc0-8af8-4c39-b57c-70752b57a7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 1\n",
    "plt.figure(1, figsize=(9.5, 8.5))\n",
    "aa = np.zeros((nz, 4))\n",
    "plt.suptitle(\"Depth-\")\n",
    "\n",
    "# four figures labeled n\n",
    "for n in range(1, 5):\n",
    "    ix, iy, k = pt[n-1]\n",
    "    aa[:, n-1] = budgO['fluxes']['tend'][:, iy, ix] - budgO['fluxes']['hconv'][:, iy, ix] - budgO['fluxes']['zconv'][:, iy, ix]\n",
    "    #aa[:, n-1] = budgO['tend'][iy, ix] - budgO['hconv'][0,iy, ix] - budgO['zconv'][iy, ix]\n",
    "\n",
    "    plt.subplot(2, 2, n)\n",
    "    plt.plot(aa[:, n-1], -np.arange(1, nz+1), '.-')\n",
    "    plt.grid()\n",
    "    #plt.xlabel(f\"net budg{strbudg[0]}o\")\n",
    "    plt.xlabel(\"Net Mass\")\n",
    "    plt.ylabel(\"Model Depth Level\")\n",
    "    plt.title(f\"[ix,iy]=[{iy},{ix}]; {100 * np.nanmax(np.abs(aa[:, n-1]))/np.nanmax(np.abs(budgO['fluxes']['zconv'][:,iy, ix]))}%\")\n",
    "        \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d96c0a-7a6d-49db-8ab0-c91ab7cd6b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 2\n",
    "a = budgO['fluxes']['tend'] * np.tile(hfC1p[np.newaxis,:, :], (nz, 1, 1))\n",
    "b = budgO['fluxes']['hconv'] * np.tile(hfC1p[np.newaxis,:, :], (nz, 1, 1))\n",
    "c = budgO['fluxes']['zconv'] * np.tile(hfC1p[np.newaxis,:, :], (nz, 1, 1))\n",
    "\n",
    "a[np.isnan(a)] = 0\n",
    "b[np.isnan(b)] = 0\n",
    "c[np.isnan(c)] = 0\n",
    "\n",
    "klev = [1, 2, 15]\n",
    "fig, axes = plt.subplots(3, 4, figsize=(14, 9))\n",
    "\n",
    "for idx, k1 in enumerate(klev):\n",
    "    str_k = f\"; k={k1}\"\n",
    "    for j, (data, title) in enumerate([(a, 'tend'), (b, 'hconv'), (c, 'zconv'), (a-b-c, 'tend-hconv-zconv')]):\n",
    "        ax = axes[idx, j]\n",
    "        pcm = ax.pcolormesh(data[k1-1,:, :], cmap='seismic', vmin=-0.99*abs(data[k1-1,:, :].max()), vmax=0.99*abs(data[k1-1,:, :].max()))\n",
    "        fig.colorbar(pcm, ax=ax)\n",
    "        ax.set_title(f\"{strbudg} {title} {str_k}\")\n",
    "\n",
    "plt.tight_layout()\n",
    "# plt.savefig(f\"{dirOut}{strbudg}_budget2_{t2:010}.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f28257-4918-4e29-883a-756d6f9a4ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = budgO['tend'] * hfC1p\n",
    "d = budgI['tend'] * hfC1p\n",
    "#b = budgO['hconv'].reshape(16,20) * hfC1p\n",
    "#f = budgI['hconv'].reshape(16,20) * hfC1p\n",
    "\n",
    "b = budgO['hconv'] * hfC1p\n",
    "f = budgI['hconv'] * hfC1p\n",
    "c = budgO['zconv'] * hfC1p\n",
    "g = budgI['zconv'] * hfC1p\n",
    "\n",
    "a[np.isnan(a)] = 0\n",
    "b[np.isnan(b)] = 0\n",
    "c[np.isnan(c)] = 0\n",
    "d[np.isnan(d)] = 0\n",
    "f[np.isnan(f)] = 0\n",
    "g[np.isnan(g)] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149ed6de-050c-498d-b523-acea4f2c09c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ix = np.arange(nx)\n",
    "iy = np.arange(ny)\n",
    "# 0 is the surface\n",
    "k = 0\n",
    "\n",
    "fig, axes = plt.subplots(2, 4, figsize=(14, 9))\n",
    "str_k = f\"; k={k+1}\"\n",
    "\n",
    "for j, (data, title_prefix, title_suffix) in enumerate([(a, 'ocn', 'tend, all z'), \n",
    "                                                        (b, 'ocn', 'hconv, all z'), \n",
    "                                                        (c, 'ocn', 'zconv, all z'),\n",
    "                                                        (a-b-c, 'ocean', 'tend-hconv-zconv, all z'),\n",
    "                                                        (d, 'ice', 'tend'),\n",
    "                                                        (f, 'ice', 'hconv'),\n",
    "                                                        (g, 'ice', 'zconv'),\n",
    "                                                        (d-f-g, 'ice', 'tend-hconv-zconv')]):\n",
    "\n",
    "    if len(data.shape) > 2:\n",
    "        ax = axes[j//4, j%4]\n",
    "        pcm = ax.pcolormesh(ix, iy, data[k,:,:], cmap='seismic', vmin=-0.99*np.nanmax(abs(data)), vmax=0.99*np.nanmax(abs(data)))\n",
    "        fig.colorbar(pcm, ax=ax)\n",
    "        ax.grid()\n",
    "        ax.set_title(f\"{title_prefix} {strbudg} {title_suffix} {str_k}\")\n",
    "    else:\n",
    "        ax = axes[j//4, j%4]\n",
    "        pcm = ax.pcolormesh(ix, iy, data[:,:], cmap='seismic', vmin=-0.99*np.nanmax(abs(data)), vmax=0.99*np.nanmax(abs(data)))\n",
    "        fig.colorbar(pcm, ax=ax)\n",
    "        ax.grid()\n",
    "        ax.set_title(f\"{title_prefix} {strbudg} {title_suffix} {str_k}\")\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(figpath + \"massbudg_allz_mapped\",dpi = 300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f100523b-f1f6-46dc-83fd-832f9528278c",
   "metadata": {},
   "source": [
    "## Make an example figure for presentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232fef1a-3e17-444a-8e01-9d78b422e4cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(5,5))\n",
    "plt.rcParams.update({'font.size': 16})\n",
    "#plt.title(\"Tend-HConv-Zconv at ix,iy Grid Coordinates\")\n",
    "plt.xlabel(\"Net Mass\")\n",
    "plt.ylabel(\"Model Depth Level\")\n",
    "\n",
    "ix,iy,k = pt[-1]\n",
    "aa[:, -1] = budgO['fluxes']['tend'][:, iy, ix] - budgO['fluxes']['hconv'][:, iy, ix] - budgO['fluxes']['zconv'][:, iy, ix]\n",
    "plt.plot(aa[:, -1], -np.arange(1, nz+1), '.-')\n",
    "plt.grid()\n",
    "#plt.title(f\"[ix,iy]=[{iy},{ix}]; {100 * np.nanmax(np.abs(aa[:, n-1]))/np.nanmax(np.abs(budgO['fluxes']['zconv'][:,iy, ix]))}%\")\n",
    "plt.title(\"Residual: \" + f\"{100 * np.nanmax(np.abs(aa[:, n-1]))/np.nanmax(np.abs(budgO['fluxes']['zconv'][:,iy, ix]))}%\")\n",
    "\n",
    "plt.savefig(figpath + \"sample_massbudget_percent.png\",dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c08c36-eb41-4b96-9bd2-2263122cc126",
   "metadata": {},
   "outputs": [],
   "source": [
    "ix = np.arange(nx)\n",
    "iy = np.arange(ny)\n",
    "# 0 is the surface\n",
    "k = 0\n",
    "plt.rcParams.update({'font.size': 14})\n",
    "plt.rcParams['axes.titley'] = 1.0    # y is in axes-relative coordinates.\n",
    "plt.rcParams['axes.titlepad'] = 18  # pad is in points...\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(1, 4, figsize=(14, 5),sharex = True,sharey=True)\n",
    "str_k = f\"; k={k+1}\"\n",
    "\n",
    "i = 0\n",
    "for j, (data, title_prefix, title_suffix) in enumerate([(a, 'ocn', 'tend, all z'), \n",
    "                                                        (b, 'ocn', 'hconv, all z'), \n",
    "                                                        (c, 'ocn', 'zconv, all z'),\n",
    "                                                        (a-b-c, 'ocean', 'tend-hconv-zconv, all z')]):\n",
    "\n",
    "    if len(data.shape) > 2:\n",
    "        ax = axes[j%4]\n",
    "        pcm = ax.pcolormesh(ix, iy, data[k,:,:], cmap='seismic', vmin=-0.99*np.nanmax(abs(data)), vmax=0.99*np.nanmax(abs(data)))\n",
    "        ax.grid()\n",
    "        ax.set_title(f\"{title_suffix} {str_k}\")\n",
    "        if i == 3:\n",
    "            fig.colorbar(pcm, ax=ax,label=\"kg/s\")\n",
    "        else:\n",
    "            fig.colorbar(pcm, ax=ax)\n",
    "    else:\n",
    "        ax = axes[j%4]\n",
    "        pcm = ax.pcolormesh(ix, iy, data[:,:], cmap='seismic', vmin=-0.99*np.nanmax(abs(data)), vmax=0.99*np.nanmax(abs(data)))\n",
    "        fig.colorbar(pcm, ax=ax)\n",
    "        ax.grid()\n",
    "        ax.set_title(f\"{title_suffix} {str_k}\")\n",
    "    i += 1\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "#plt.suptitle(\"Ocean Mass Convergences\")\n",
    "plt.savefig(figpath + \"massbudg_allz_mapped\",dpi = 300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf307737-c322-4245-97fc-e9eb6e903faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "figpath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a1b957-8f31-47ee-b4c4-2ca4cd65414e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
